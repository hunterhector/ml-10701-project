Improving Japanese Zero Pronoun Resolution by Global Word Sense Disambiguation Daisuke Kawahara and Sadao Kurohashi Graduate School of Information Science and Technology, University of Tokyo {kawahara,kuro}@kc.t.u-tokyo.ac.jp Abstract This paper proposes unsupervised word sense disambiguation based on automatically constructed case frames and its incorporation into our zero pronoun resolution system.
The word sense disambiguation is applied to verbs and nouns.
We consider that case frames define verb senses and semantic features in a thesaurus define noun senses, respectively, and perform sense disambiguation by selecting them based on case analysis.
In addition, according to the one sense per discourse heuristic, the word sense disambiguation results are cached and applied globally to the subsequent words.
We integrated this global word sense disambiguation into our zero pronoun resolution system, and conducted experiments of zero pronoun resolution on two different domain corpora.
Both of the experimental results indicated the effectiveness of our approach.
1 Introduction
For a long time, parsing has been a central issue for the area of natural language analyses.
In recent years, its accuracy has improved to over 90%, and it became the fundamental technology that is applied to a lot of NLP applications, such as question answering, text summarization, and machine translation.
Accordingly, anaphora resolution, which is positioned as the next step of parsing, has been studied actively (Ng and Cardie, 2002; Yang et al., 2003; Iida et al., 2003; Isozaki and Hirao, 2003; Kawahara and Kurohashi, 2004).
Its performance, however, is not satisfactory enough to benefit the NLP applications.
We investigated errors of our Japanese zero pronoun resolution system (Kawahara and Kurohashi, 2004), and found that word sense ambiguity causes a major part of errors.
Our zero pronoun resolution system utilizesthegeneral-purposethesaurusNihongo Goi Taikei (Ikehara et al., 1997) (hereafter, NTT thesaurus) to do matching of example words.
In this thesaurus, one or more semantic features are given to each word, and similarity between words can be calculated by comparing closeness of their semantic features in the thesaurus tree (Appendix A).
Multiple semantic features for a word, i.e. word sense ambiguity, cause incorrect matching, and furthermore deteriorate accuracy of the zero pronoun resolution system.
For instance, in the thesaurus, “gobou” (burdock/priest/temple) has four semantic features: <crop>, <vegetable>, <priest> and <temple>∗.
If <priest> is used for “gobou” in a cooking domain text, though “gobou” means ‘burdock’ (a genus of coarse biennial herbs) in its context, “gobou” is identified as an agent.
That is, “gobou” is incorrectly analyzed as antecedents of the following nominative zero pronouns.
If such word sense ambiguity can be resolved, incorrect matching decreases, and the anaphora resolution system will improve.
Word sense disambiguation is a basic issue of NLP.
Recently, the evaluation exercises for word sense disambiguation such as SENSEVAL-1 (Kilgarriff and Palmer, 2000) and SENSEVAL-2 (Yarowsky, 2001) have been held, but word sense disambiguation has rarely been incorporated into deep analyses like anaphora resolution.
This paper proposes unsupervised word sense disambiguation based on automatically constructed case frames and its incorporation into the zero pronoun resolution system.
The word sense disambiguation is applied to verbs† and nouns.
We consider that case frames define verb senses and semantic features in the thesaurus define noun senses, respectively.
A verb is disambiguated by selecting a corresponding case frame to its context, and a noun is disambiguated by selecting an appropriate semantic ∗In this paper, <> means a semantic feature.
†In this paper, we use ‘verb’ instead of ‘verb, adjective and noun+copula’ for simplicity.
NOUN CONCRETE ABSTRACT AGENT PLACE CONCRETE HUMAN ORGANIZATION ABSTRACTEVENTABSTRACT RELATION TIMEPOSITIONQUANTITY.
.. . Figure 1: The upper levels of the NTT thesaurus.
feature from the ones defined for the noun in the thesaurus.
In addition, according to the one sense per discourse heuristic, the disambiguation results are cached and applied globally to the following words in the same text.
The remainder of this paper is organized as follows.
Section2brieflydescribestheNTTthesaurus and the automatic construction method of case frames.
Section 3 outlines our zero pronoun resolution system.
Section 4 describes the method of word sense disambiguation and its integration into the zero pronoun resolution system.
Section 5 presents the experiments of the integrated system.
Section 6 summarizes the conclusions.
2 Resources
We consider that verb and noun senses correspond to case frames and semantic features defined in the NTT thesaurus, respectively.
This section describes the NTT thesaurus and the case frames briefly.
2.1 NTT
thesaurus NTT Communication Science Laboratories constructed a semantic feature tree, whose 3,000 nodes are semantic features, and a nominal dictionary containing about 300,000 nouns, each of which is given one or more appropriate semantic features.
Figure 1 shows the upper levels of the semantic feature tree.
The similarity between two words is defined by formula (1) in Appendix A.
2.2 Automatically
constructed case frames We employ the automatically constructed case frames (Kawahara and Kurohashi, 2002) as the basic resource for zero pronoun resolution and word sense disambiguation.
This section outlines the method of constructing the case frames.
The biggest problem in automatic case frame construction is verb sense ambiguity.
Verbs which have different meanings should have different case frames, but it is hard to disambiguate verb senses precisely.
To deal with this problem, predicate-argument examples which are collected from a large corpus are distinguished by coupling a verb and its closest case component.
That is, examples are not distinguished by verbs (e.g.
“tsumu” (load/accumulate)), but by couples (e.g.
“nimotsu-wo tsumu” (load baggage) and “keiken-wo tsumu” (accumulate experience)).
This process makes separate case frames which have almost the same meaning or usage.
For example, “nimotsu-wo tsumu” (load baggage) and “busshi-wo tsumu” (load supply) are similar, but have separate case frames.
To cope with this problem, the case frames are clustered.
Example words are collected for each case marker, such as “ga”, “wo”, “ni” and “kara”.
They are case-marking postpositions in Japanese, and usually mean nominative, accusative, dative and ablative, respectively.
We call such a case marker ‘case slot’ and example words in a case slot ‘case examples’.
Case examples in a case slot are similar, but have some incorrect semantic features because of word sense ambiguity.
For instance, “nimotsu” (baggage), “busshi” (supply) and “nisemono” (imitation) are gathered in a case slot, and all of them are below the semantic feature <goods>.
On the other hand, “nisemono” belongs to <lie>.
<lie> is incorrect for this case slot, and possibly causes errors in case analysis.
We delete a semantic feature that is not similar to the other semantic features of its case slot.
To sum up, the procedure for the automatic case frame construction is as follows.
1. A large raw corpus is parsed by the Japanese parser, KNP (Kurohashi and Nagao, 1994b), and reliable predicateargument examples are extracted from the parse results.
2. The extracted examples are bundled accordingtotheverbanditsclosestcasecomponent, making initial case frames.
3. The initial case frames are clustered using a similarity measure function.
This similarity is calculated by formula (5) in Appendix B.
4. For each case slot of clustered case frames, an inappropriate semantic feature that is not similar to the other semantic features is discarded.
We constructed two sets of case frames: for newspaper and cooking domain.
The newspaper case frames are constructed from about 21,000,000 sentences of newspaper articles in 20 years (9 years of Mainichi newspaper and 11 years of Nihonkeizai newspaper).
They consist of 23,000 verbs, and the average number of case frames for a verb is 14.5.
The cooking case frames are constructed from about 5,000,000 sentences of cooking domain that are collected from WWW.
They consist of 5,600 verbs, and the average number of case frames for a verb is 6.8.
In Figure 1, some examples of the resulting case frames are shown.
In this table, ‘CS’ means a case slot.
<agent> in the table is a generalized case example, which is given to the case slot where half of the case examples belong to <agent>.
<agent> is also given to “ga” case slot that has no case examples, because “ga” case components are often omitted, but “ga” case slots usually mean nominative.
3 The
Outline of the Zero Pronoun Resolution System We have proposed a Japanese zero pronoun resolution system using the case frames, antecedent preference orders, and a machine learning technique (Kawahara and Kurohashi, 2004).
Its procedure is as follows.
1. Parse an input sentence using the Japanese parser, KNP.
2. Process each verb in the sentence from left to right by the following steps.
Table 1: Case frame examples.
CS case examples† ga <agent>, group, party, ···youritsu (1) wo <agent>, candidate, applicant(support) ni <agent>, district, election, ··· ga <agent>youritsu (2) wo <agent>, member, minister, ···(support) ni <agent>, candidate, successor ...
... ...
orosu (1) ga <agent> (grate) wo radish ga <agent>orosu (2) wo money(withdraw) kara bank, post ...
... ...
itadaku (1) ga <agent> (have) wo soup ga <agent>itadaku (2) wo advice, instruction, address(be given) kara <agent>, president, circle, ··· ...
... ...
†case examples are expressed only in English for space limitation.
2.1. Narrow case frames down to corresponding ones to the verb and its closest case component.
2.2. Perform the following processes for each case frame of the target verb.
i. Match each input case component with an appropriate case slot of the case frame.
Regard case slots that have no correspondence as zero pronouns.
ii. Estimate an antecedent of each zero pronoun.
2.3. Select a case frame which has the highest total score, and output the analysis result for the case frame.
The rest of this section describes the above steps (2.1), (2.2.i) and (2.2.ii) in detail.
3.1 Narrowing
down case frames The closest case component plays an important role to determine the usage of a verb.
In particular, when the closest case is “wo” or “ni”, this trend is clear-cut.
In addition, an expression whose nominative belongs to <agent> (e.g.
“<agent> has accomplished”), does not have enough clue to decide its usage, namely a case frame.
By considering these aspects, we impose the following conditions on narrowing down case frames.
• The closest case component exists, and must immediately precede its verb.
• The closest case component and the closest case meet one of the following conditions: – The closest case is “wo” or “ni”.
– The closest case component does not belong to the semantic marker <agent>.
• A case frame with the closest case exists, and the similarity between the closest case component and examples in the closest case exceeds a threshold.
We choose the case frames whose similarity is the highest.
If the above conditions are not satisfied, case frames are not narrowed down, and the subsequent processes are performed for each case frame of the target verb.
The similarity used here is defined as the best similarity between the closest case component and examples in the case slot.
The similarity between two examples is defined as formula (1) in Appendix A.
Let us consider “youritsu” (support) in the second sentence of Figure 2.
“youritsu” has the case frames shown in Table 1.
The input expression “kouho-wo youritsu” (support a candidate) satisfies the above two conditions, and the case frame “youritsu (1)” meets the last condition.
Accordingly, this case frame is selected.
3.2 Matching
input case components with case slots in the case frame We match case components of the target verb with case slots in the case frame (Kurohashi and Nagao, 1994a).
When a case component has a case marker, it must be assigned to the case slot with the same case marker.
When a case component is a topic marked phrase or a clausal modifiee, which does not have a case marker, it can be assigned to one of the case slots in the following table.
topic marked phrases : ga, wo, ga2 clausal modifiees : ga, wo, non-gapping The conditions above may produce multiple matching patterns.
In this case, one which has the best score is selected.
The score of a matching pattern is defined as the sum of similarities of case assignments.
This similarity is calculated as the same way described in Section 3.1. a0a2a1a4a3a6a5a4a7a9a8a4a10a11 a1a13a12 a7a6a5a13a10a7a6a1a13a14 a15a17a16a19a18 a20 a18 a11 a18a4a15a21a16a19a18 a22 a10 a14a4a7a24a23a26a25a4a11 a18 a25 a15a17a16 a5 a20 a1a13a14a27a11 a18 a25 a15 a7a9a8a26a10a11 a1a13a10a28a17a25 a7a9a8a4a10a29a30a10 a15 a7a13a25a31a28a17a25 a32a34a33 a16a19a18 a23 a18 a25a31a28a35a10a11 a7a31a25 a15 a7a31a25a31a28a17a25 a36 a18 a20 a25a30a29a21a10 a20 a18 a25a31a8 a18a4a15a17a16a19a18 a32a34a33a35a37 a5 a32a34a33 a14a26a10 a38 a7a9a8a26a10a8a26a5a4a28a39a5 a40a41a8a26a10a29a21a10 a15 a37 a5 a32a34a33a35a37 a5 a37 a5a43a42a31a44a6a14a4a10a45 a37 a5a31a46a47a44a6a14a4a10a48 a37 a5a13a48a49a44a6a14a26a10a42 a37 a5a4a45a49a44a9a14a26a10a50 a37 a5a4a50a27a44a6a14a26a10a51 a8a31a23 a18 a25a13a0a52a1a4a10 a15 a7a9a8a4a10a11 a5 a28a35a10 a20a9a20 a18 a25a31a8 a18a4a15a17a16a19a18 a32a34a33a35a37 a5 a40a41a8a26a10a29a21a10a7a6a1a4a14 a15 a8a53a1a13a14 a18 a8 a18 a25a31a7a6a8a4a10a14 a15a17a16a19a18 a20 a1a26a11a11 a1a13a10 a15 a7a6a8a4a10a11 a5 a37 a5a31a12 a54 a10 a0a52a10a14a53a11 a18 a25 a15a21a16 a5 a55a6a56 a55a13a57a35a58 a55a4a57a60a59 a55a4a57a62a61 a55a4a57a60a63 Figure 2: Analysis example.
The result of case analysis tells if the zero pronouns exist.
That is, vacant case slots in the case frame, which have no correspondence with the input case components, mean zero pronouns.
In this paper, we concentrate on three case slots: “ga”, “wo”, and “ni”.
In the case of “youritsu” (support) in Figure 2 and the selected case frame “youritsu (1)”, “wo” case slot has a corresponding case component, but “ga” and “ni” case slots are vacant.
Accordingly, two zero pronouns are identified in “ga” and “ni” case of “youritsu”.
3.3 Antecedent
estimation The antecedents of the detected zero pronouns are estimated.
Possible antecedents are examined according to the antecedent preference order (Kawahara and Kurohashi, 2004).
If a possible antecedent is classified as positive by a binary classifier and its similarity to examples in its case slot exceeds a threshold, it is determined as the antecedent.
For example, “youritsu” (support) in Figure 2 has zero pronouns in “ga” and “ni” cases.
The ordered possible antecedents for “ga” are L7:“Minsyutou”, L14:“Jimintou”(φ ga), L14:“Ishihara chiji”(φ wo), ···.
The first candidate “Minsyutou (similarity:0.73)”, which is labeled as positive by the classifier, and whose similarity to the case frame examples exceeds a threshold (0.60), is determined as the antecedent.
4 Global
Word Sense Disambiguation We integrate a global method of word sense disambiguation into the zero pronoun resolution system described in the previous section.
The word sense disambiguation is applied to verbs and nouns based on the case frames.
Furthermore, the word sense disambiguation results are cached and applied globally by the subsequent analyses based on the one sense per discourse heuristic.
In the rest of this section, we describe verb and noun sense disambiguation respectively using examples of cooking domain.
4.1 Verb
sense disambiguation The case frames are specific enough to the diversity of verb senses, because their meanings are distinguished by the couple of the verb and its closest case component (Kawahara and Kurohashi, 2002).
We regard the process of verb sense disambiguation as the case frame selection (Step (2.3) described in Section 3).
In addition, theverbsensedisambiguationresultsarecached and applied globally in the same text.
In other words, the selected case frames are cached for each verb, and only the case frames that are similar to the cache are used for the same verb following in the same text.
The similarity measure for two case frames is stated in Appendix B, and the threshold is set to 0.60 empirically.
Here is an example article that consists of three sentences.
oroshi-gane-de grater kabura-wo turnip oroshite-ikimasu.
grate (Let’s grate a turnip.) kore-wa this ookii big kabura turnip desu.
be (This is a big turnip.) konoyouni like this oroshi-masu.
grate (Grate like this.) For “oroshite” (grate) in the first sentence, the case frame “orosu (1)” (in Table 1), which means “grate radish”, is selected, because the closest case component “kabura” (turnip) exists, and is very similar to the “wo” case example “daikon” (radish).
This selected case frame is cached for the verb “orosu”.
For “oroshi” (grate) in the third sentence, case frames are not narrowed down for lack of the closest component.
The previous system performs the antecedent estimation process for all the case frames of “orosu”, and incorrectly estimates the antecedent of “wo” zero pronoun as “oroshigane” (grater)‡.
On the other hand, our proposed method deals with only the similar case frames to the cached “orosu (1)”.
That is, the case frame “orosu (2)”, which means “withdraw money from bank or post”, is not similar to “orosu (1)”, and is not used.
Accordingly, the system certainly estimates the antecedent of “wo” zero pronoun as “kabura” (turnip).
4.2 Noun
sense disambiguation We define the process of noun sense disambiguation as selecting an appropriate semantic feature from the ones given to a noun in the NTT thesaurus.
This process is performed based on the matching of the input case components and the case frame decided by the step (2.3) described in Section 3.
For each input case component, its semantic features are matched against those of case examples of its corresponding case slot, and the best matched one is selected.
In addition, this disambiguation result is applied globallyliketheverbsensedisambiguation.
The determined semantic feature is cached for each noun, and is given to the same noun following in the same text, instead of reconsidering all of its semantic features.
Here is an example article.
mazuwa first osumashi-wo clear soup itadaki-masu.
have (First, let’s have clear soup.) honkakutekina real dashi-wo stock tori-mashita.
prepare (We prepared real stock.) “itadaki” (have) in the first sentence has the closest case component “osumashi” (clear soup), and the case frame “itadaku (1)” (in Table 1) is selected, because its “wo” case example “soup” is very similar to “osumashi”.
In the NTT thesaurus, “osumashi” (clear soup) has three semantic features: <soup>, <look> and <eccentric>.
<eccentric> is located below <agent> in the thesaurus, and the previous system incorrectly estimates antecedents of “ga” zero pronouns of the following verbs as “osumashi” (because almost all the ‡In Japanese, “gane” of “oroshi-gane” (grater) exactly matches with “kane” (money), the “wo” case example of “orosu (2)”.
Table 2: Accuracy (newspaper).
precision recall F baseline 515/924 (0.557) 515/1087 (0.474) 0.512 our method 526/911 (0.577) 526/1087 (0.484) 0.527 Table 3: Accuracy (cooking).
precision recall F baseline 696/1092 (0.637) 696/1482 (0.470) 0.541 our method 713/1081 (0.660) 713/1482 (0.481) 0.556 case frames have <agent> in their “ga” case slots).
In our approach, each of the semantic features are matched against the case example “soup”, and only the best matched semantic feature <soup> is given to “osumashi”.
5 Experimental
Results and Discussion We conducted experiments of zero pronoun resolution on two different domain corpora.
One is newspaper articles of “Relevance-tagged corpus” (Kawahara et al., 2002), and the other is utterances of cooking TV programs.
These cooking utterances were handled by (Shibata et al., 2003).
They annotated various relations to closed captions of the cooking utterances based on the specification of the “Relevance-tagged corpus” (Kawahara et al., 2002).
For newspaper domain, the antecedent preference and the classifier were trained with 1,841 sentences in the newspaper corpus, and the newspaper case frames were used.
The experiment was performed on 633 sentences.
For cooking domain, we used 813 sentences (5 TV programs), and conducted 5-fold cross validation using the cooking case frames.
We evaluated “ga”, “wo” and “ni” cases that are the large majority of zero pronouns.
The experimental results are shown in Table 2 and Table 3.
The accuracies in these tables are calculated by evaluating both detection and antecedent estimation of zero pronouns together.
The baseline corresponds to our previous system without word sense disambiguation.
From Table 2 and Table 3, we can see that the system accuracy is improved by the global word sense disambiguation.
The improvement is not big, but there are no analysis result that changed for the worse.
The improvement is hardly contributed by the verb sense disambiguation, but mainly by the noun sense disambiguation.
This is because appropriate case frames are used in many cases without the verb sense disambiguation, and this process did not lead to the improvement.
The number of case frames of the verbs to which the verb sense disambiguation is applied decreased to 16%, and this indicates that the analysis efficiency improved significantly.
In addition, we evaluated randomly selected 100 nouns to which the noun sense disambiguation is applied.
91 nouns were disambiguated correctly, and quite high disambiguation accuracy was achieved.
6 Conclusion
This paper has incorporated a framework of global word sense disambiguation into a Japanese zero pronoun resolution system.
The word sense disambiguation is applied to verbs and nouns.
A verb is disambiguated by selecting a corresponding case frame to its context, and a noun is disambiguated by selecting an appropriate semantic feature.
Furthermore, the disambiguation results are cached and applied globally.
That is to say, it is utilized in the following analyses in the same text.
In the future, we will investigate the word sense disambiguation errors further, and expect to improve the system accuracy.
Appendix A Similarity between examples The similarity between two examples e1,e2 is calculated using the NTT thesaurus as follows: sim(e1,e2) = maxx∈s1,y∈s2 sim(x,y) (1) sim(x,y) = 2Ll x +ly where x,y are semantic features, and s1,s2 are sets of semantic markers of e1,e2 respectively.
lx,ly are the depths of x,y in the thesaurus, and the depth of their lowest (most specific) common node is L.
If x and y are in the same node of the thesaurus, the similarity is 1.0, the maximum score based on this criterion.
B Similarity between case frames Two case frames, F1 and F2, are first aligned according to the agreement of case markers (case slots).
Suppose the result of the case slot alignment of F1 and F2 is as follows: F1 : C11, C12, ··· C1l ··· C1m arrowbothv arrowbothv arrowbothv F2 : C21, C22, ··· C2l ··· C2n where Cxx denotes a case slot which contains several case examples.
This result means that l case slots are aligned between F1 and F2 and (m − l) and (n − l) case slots remained in F1 and F2 respectively.
The similarity between two case slots, C1i and C2i, is the sum of the similarities of case examples as follows: sim(C1i,C2i) =P e1∈C1i P e2∈C2i √ |e1||e2|·sim(e1,e2)P e1∈C1i P e2∈C2i √ |e1||e2| (2) where |e1| and |e2| represent the frequencies of e1 and e2 respectively.

