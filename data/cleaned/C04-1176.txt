Automatic Construction of Japanese KATAKANA Variant List from Large Corpus Takeshi Masuyama Information Technology Center University of Tokyo 7-3-1, Hongo, Bunkyo Tokyo 113-0023 Japan tak@r.dl.itc.u-tokyo.ac.jp Satoshi Sekine Computer Science Department New York University 715 Broadway, 7th floor New York NY 10003 USA sekine@cs.nyu.edu Hiroshi Nakagawa Information Technology Center University of Tokyo 7-3-1, Hongo, Bunkyo Tokyo 113-0023 Japan nakagawa@dl.itc.u-tokyo.ac.jp Abstract This paper presents a method to construct Japanese KATAKANA variant list from large corpus.
Our method is useful for information retrieval, information extraction, question answering, and so on, because KATAKANAwordstendtobeusedas â€œloan wordsâ€ and the transliteration causes several variations of spelling.
Our method consists of three steps.
At step 1, our system collects KATAKANA words from large corpus.
At step 2, our system collects candidate pairs of KATAKANA variants from the collected KATAKANA words using a spelling similarity which is based on the edit distance.
At step 3, our system selects variant pairs from the candidate pairs using a semantic similarity which is calculated by a vector space model of a context of each KATAKANA word.
We conducted experiments using 38 years of Japanese newspaper articles and constructed Japanese KATAKANA variant list with the performance of 97.4% recall and 89.1% precision.
Estimating from this precision, our system can extract 178,569 variant pairs from the corpus.
1 Introduction
â€œLoan wordsâ€ in Japanese are usually written by a phonogram type of Japanese character set, KATAKANA.
Because of loan words, the transliteration causes several variations of spelling.
Therefore, Japanese KATAKANA words sometimes have several diï¬€erent orthographies for each original word.
For example, we found at least six diï¬€erent spellings of â€œspaghettiâ€ in 38 years of Japanese newspaper articles, such as â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½,â€ and â€œï¿½ï¿½ï¿½ï¿½ï¿½.â€ The diï¬€erent expression causes problems when we use search engines, question answering systems, and so on (Yamamoto et al., 2003).
For example, when we input â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â€asaqueryforasearchengine or a query for a question answering system, we may not be able to find the web pages or the answers for which we are looking, if a diï¬€erent orthography for â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â€isused.
We investigated how many documents were retrieved by Google 1 when each Japanese KATAKANA variant of â€œspaghettiâ€ was used as a query.
The result is shown as Table 1.
For example, when we inputted â€œï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½â€ as a query of Google, 104,000 documents were retrieved and the percentage was 34.6%, calculated by 104,000 divided by 300,556.
From Table 1, we see that each of six variants appears frequently and thus we may not be able to find the web pages for which we are looking.
Although we can manually create Japanese KATAKANA variant list, it is a labor-intensive task.
In order to solve the problem, we propose an automatic method to construct Japanese KATAKANA variant list from large corpus.
Variant # of retrieved documents ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½104,000 (34.6%) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½25,400 (8.5%) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½1,570 (0.5%) ï¿½ï¿½ï¿½ï¿½ï¿½131,000 (43.6%) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½37,700 (12.5%) ï¿½ï¿½ï¿½ï¿½ï¿½886 (0.3%) Total 300,556 (100%) Table 1: Number of retrieved documents when we inputted each Japanese KATAKANA variant of â€œspaghettiâ€ as a query of Google.
Our method consists of three steps.
First, we collect Japanese KATAKANA words from large corpus.
Then, we collect candidate pairs of KATAKANA variants based on a spelling similarity from the collected Japanese KATAKANA words.
Finally, we select variant pairs using 1 http://www.google.co.jp/ a semantic similarity based on a vector space model of a context of each KATAKANA word.
This paper is organized as follows.
Section 2 describes related work.
Section 3 presents our method to construct Japanese KATAKANA variant list from large corpus.
Section 4 shows some experimental results using 38 years of Japanese newspaper articles, which we call â€œthe Corpusâ€ from now on, followed by evaluation and discussion.
Section 5 describes future work.
Section 6 oï¬€ers some concluding remarks.
2 Related
Work There are some related work for the problems with Japanese spelling variations.
In (Shishibori and Aoe, 1993), they have proposed a method for generating Japanese KATAKANA variants by using replacement rules, such as ï¿½(be) â†”ï¿½ï¿½(ve) andï¿½(chi) â†”ï¿½ï¿½(tsi).
Here, â€œâ†”â€ represents â€œsubstitution.â€ For example, when we apply these rules to â€œï¿½ï¿½ï¿½ï¿½ (Venezia),â€ three diï¬€erent spellings are generated as variants, such as â€œï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ ï¿½ï¿½,â€ and â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½.â€ Kubota et al.have extracted Japanese KATAKANA variants by first transforming KATAKANA words to directed graphs based on rewrite rules and by then checking whether the directed graphs contain the same labeled path or not (Kubota et al., 1993).
A part of their rewrite rules is shown in Table 2.
For example, when applying these rules to â€œï¿½ï¿½ï¿½ï¿½ï¿½ (Kuwait),â€ â€œï¿½aÎ±c,â€ â€œï¿½bÎ±c,â€ â€œï¿½ï¿½dÎ±câ€ are generated as variants.
KATAKANA String â†’ Symbol ï¿½ï¿½(we),ï¿½(e) â†’ a ï¿½ï¿½(we),ï¿½ï¿½(ue) â†’ b ï¿½ï¿½(twu),ï¿½(to),ï¿½(tsu) â†’ c ï¿½(macron) â†’ Î± ï¿½(small e),ï¿½(e) â†’ d Table 2: A part of rewrite rules.
In (Shishibori and Aoe, 1993) and (Kubota et al., 1993), they only paid attention to applying their replacement or rewrite rules to words themselves and didnâ€™t pay attention to their contexts.
Therefore, they wrongly decide that â€œï¿½ï¿½ï¿½ï¿½â€isavariantofâ€œï¿½ï¿½ï¿½.â€ Here, â€œï¿½ ï¿½ï¿½ï¿½â€representsâ€œwaveâ€andâ€œï¿½ï¿½ï¿½â€represents â€œweb.â€ In our method, we will decide if â€œ ï¿½ï¿½ï¿½ï¿½â€andâ€œï¿½ï¿½ï¿½â€ convey the same meaning or not using a semantic similarity based on their contexts.
3 Construct
Japanese KATAKANA Variant List from Large Corpus Our method consists of the following three steps.
1. Collect Japanese KATAKANA words from large corpus.
2. Collect candidate pairs of KATAKANA variants from the collected KATAKANA words using a spelling similarity.
3. Select variant pairs from the candidate pairs based on a semantic similarity.
3.1 Collect
KATAKANA Words from Large Corpus At the first step, we collected Japanese KATAKANA words which consist of a KATAKANA character,~(bullet),ï¿½ (macron-1), andï¿½(macron-2), which are commonly used as a part of KATAKANA words, using pattern matching.
For example, our system collects three KATAKANA words â€œ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½(Ludwig Erhard-1),â€ â€œï¿½(Soviet),â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ (Ludwig Erhard-2),â€ â€œï¿½ï¿½ï¿½(Germany)â€ from the following sentences.
Note that two mentions of â€œLudwig Erhardâ€ have diï¬€erent orthographies.
â€¢ â€œ{w&Aï¿½ï¿½wï¿½â€qMï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½{(Defunct Ludwig Erhard-1 is called â€œFather of The Miraculous Economic Revival.â€) â€¢ï¿½`ï¿½ï¿½ï¿½ f$ ~U w Mï¿½ï¿½ï¿½ï¿½ozï¿½ ï¿½ï¿½@ ï¿½t b ï¿½wï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ ï¿½Uqlhï¿½Os&Awï¿½=ï¿½q ï¿½V  ï¿½yz bï¿½ï¿½ï¿½wï¿½Ot{wï¿½ï¿½ï¿½ 1[ ï¿½Tï¿½`ï¿½sM{(If Soviet and East European countries give up their controlling concepts and pursue the economic deregulation which Ludwig Erhard-2 of West Germany did in 1948, they may achieve the miraculous revival like West Germany.) 3.2 Spelling Similarity At the second step, our system collects candidate pairs of two KATAKANA words, which are similar in spelling, from the collected KATAKANA words described in Section 3.1.
We used â€œstring penaltyâ€ to collect candidate pairs.
String penalty is based on the edit distance (Hall and DOWLING, 1980) which is a similarity measure between two strings.
We used the following three types of operations.
â€¢ Substitution Replace a character with another character.
â€¢ Deletion Delete a character.
â€¢ Insertion Insert a character.
We also added some scoring heuristics to the operations based on a pronunciation similarity between characters.
The rules are tuned by hand using randomly selected training data.
Some examples are shown in Table 3.
Here, â€œâ†”â€ represents â€œsubstitutionâ€ and lines without â†” represent â€œdeletionâ€ or â€œinsertion.â€ Note that â€œPenaltyâ€ represents a score of the string penalty from now on.
For example, we give penalty 1 between â€œï¿½ ï¿½ï¿½ï¿½ï¿½â€andâ€œï¿½ï¿½ï¿½ï¿½ï¿½,â€ because the strings become the same when we replace â€œï¿½â€withâ€œ ï¿½â€ and its penalty is 1 as shown in Table 3.
Rules Penalty ï¿½(a) â†”ï¿½(small a) 1 ï¿½(zi) â†”ï¿½(di) 1 ï¿½(macron) 1 ï¿½(ha) â†”ï¿½(ba) 2 ï¿½(u) â†”ï¿½(vu) 2 ï¿½(a) â†”ï¿½(ya) 3 ï¿½(tsu) â†”ï¿½(small tsu) 3 Table 3: A part of our string penalty rules.
We analyzed hundreds of candidate pairs of training data and figured out that most KATAKANA variations occur when the string penalties were less than a certain threshold.
In this paper, we set 4 for the threshold and regard KATAKANA pairs as candidate pairs when the string penalties are less than 4.
The threshold was tuned by hand using randomly selected training data.
For example, from the collected KATAKANA words described in Section 3.1, our system collects the pair ofï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½and ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½, since the string penalty is 3.
3.3 Context
Similarity At the final step, our system selects variant pairs from the candidate pairs described in Section 3.2 based on a semantic similarity.
We used a vector space model as a semantic similarity.
In the vector space model, we treated 10 randomly selected articles from the Corpus as a context of each KATAKANA word.
We divided sentences of the articles into words using JUMAN 2 (Kurohashi and Nagao, 1999) which is the Japanese morphological analyzer, and then extracted content words which consist of nouns, verbs, adjectives, adverbs, and unknown words except stopwords.
Stopwords are composed of Japanese HIRAGANA characters, punctuations, numerals, common words, and so on.
We used a cosine measure to calculate a semantic similarity of two KATAKANA words.
Suppose that one KATAKANA word makes a context vector a and the other one makes b.
The semantic similarity between two vectors a and b is calculated as follows.
sim(a,b)=cosÎ¸ = aÂ·b |a||b| (1) The cosine measure tends to overscore frequently appeared words.
Therefore, in order to avoid the problem, we treated log(N +1)asa score of a word appeared in a context.
Here, N represents the frequency of a word in a context.
We set 0.05 for the threshold of the semantic similarity, i.e. we regard candidate pairs as variant pairs when the semantic similarities are more than 0.05.
The threshold was tuned by hand using randomly selected training data.
In the case of â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½(Ludwig Erhard-1)â€ and â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ ï¿½(Ludwig Erhard-2)â€, the semantic similarity becomes 0.17 as shown in Table 4.
Therefore, we regard them as a variant pair.
Note that in Table 4, a decimal number represents a score of a word appeared in a context calculated by log(N+1).
For example, the score of{(miracle) in the first context is 0.7. 4 Experiments 4.1 Data Preprocessing and Performance Measures We conducted the experiments using the Corpus.
The number of documents in the Cor2 http://www.kc.t.u-tokyo.ac.jp/nlresource/juman.html Wordï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ {(miracle):0.7 &A(economy):1.9 Contextï¿½(father):0.7 ï¿½ï¿½(revival):0.7 Â·Â·Â· Wordï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½ {(miracle):1.1 ï¿½=(liberalization):1.4 Context&A(economy):2.4 ï¿½ï¿½(revival):1.1 Â·Â·Â· Similarity 0.17 Table 4: Semantic similarity between â€œï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½â€andâ€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ ï¿½ï¿½ï¿½.â€ pus was 4,678,040 and the distinct number of KATAKANA words in the Corpus was 1,102,108.
As for a test set, we collected candidate pairs whose string penalties range from 1 to 12.
The number of collected candidate pairs was 2,590,240.
In order to create sample correct KATAKANA variant data, 500 out of 2,590,240 were randomly selected and we evaluated them manually by checking their contexts.
Through the evaluation, we found that no correct variant pairs appeared from 10 to 12.
Thus, we think that treating candidate pairs whose string penalties range from 1 to 12 can cover almost all of correct variant pairs.
To evaluate our method, we used recall (Re), precision (Pr), and F measure (F).
These performance measures are calculated by the following formulas: Re = number of pairs found and correct total number of pairscorrect, Pr = number of pairs found and correct total number of pairs found, F = 2RePr Re + Pr. 4.2 Experiment-1 We conducted the first experiment based on two settings; one method uses only the spelling similarity and the other method uses both the spelling similarity and the semantic similarity.
Henceforth, we use â€œMethod p,â€ â€œMethod p&s,â€ â€œExt,â€ and â€œCorâ€ as the following meanings.
Method p : The method using only the spelling similarity Method p&s : The method using both the spelling similarity and the semantic similarity Ext: The number of extracted candidate pairs Cor: The number of correct variant pairs among the extracted candidate pairs Note that in Method p&s, we ignored candidate pairs whose string penalties ranged from 4 to 12, since we set 4 for the threshold of the string penalty as described in Section 3.2.
The result is shown in Table 5.
For example, when the penalty was 2, 81 out of 117 were selected as correct variant pairs in Method p and the precision was 69.2%.
Also, 80 out of 98 were selected as correct variant pairs in Method p&s and the precision was 81.6%.
As for Penalty 1-12 of Method p, i.e. we focused on the string penalties between 1 and 12, the recall was 100%, because we regarded 269 out of 500 as correct variant pairs and Method p extracted all of them.
Also, the precision was 53.8%, calculated by 269 divided by 500.
Comparing Method p&s to Method p, the recall and the precision of Method p&s were well-balanced, since the recall was 97.4% and the precision was 89.1%.
In the same way, for Penalty 1-3, i.e. the string penalties between 1 and 3, the recall of Method p was 98.1%, since five correct variant pairs between 4 and 12 were ignored and the remaining 264 out of 269 were found.
The precision of Method p was 77.2%.
It was 23.4% higher than the one of Penalty 1-12.
Thus, F measure also improved 16.4%.
This result indicates that setting 4 for the threshold works well to improve overall performance.
Now, comparing Method p&s to Method p when the string penalties ranged from 1 to 3, the recall of Method p&s was0.7%lower.
Thiswas because Method p&s couldnâ€™t select two correct variant pairs when the penalties were 1 and 2.
However, the precision of Method p&s was 16.2% higher.
Thus, F measure of Method p&s improved 6.7% compared to the one of Method p . From this result, we think that taking the semantic similarity into account is a better strategy to construct Japanese KATAKANA variant list.
Penalty Method p Method p&s Cor/Ext (%) Cor/Ext (%) 1 130/134 (97.0) 129/129 (100) 2 81/117 (69.2) 80/98 (81.6) 3 53/91 (58.2) 53/67 (79.1) 4 2/14 (14.3) 5 0/30 (0.0) 6 1/14 (7.1) 7 1/20 (5.0) 8 0/14 (0.0) 9 1/12 (8.3) 10 0/16 (0.0) 11 0/17 (0.0) 12 0/21 (0.0) Re 264/269 (98.1) 262/269 (97.4) 1-3 Pr 264/342 (77.2) 262/294 (89.1) F 86.4% 93.1% Re 269/269 (100) 1-12 Pr 269/500 (53.8) F 70.0% Table 5: Comparison of Method p and Method p&s . 4.3 Experiment-2 We investigated how many variant pairs were extracted in the case of six diï¬€erent spellings of â€œspaghettiâ€ described in Section 1.
Table 6 shows the result of all combination pairs when we applied Method p&s . For example, when the penalty was 1, Method p&s selected seven candidate pairs and all of them were correct.
Thus, the recall was 100%.
From Table 6, we see that the string penalties of all combination pairs ranged from 1 to 3 and our system selected all of them by the semantic similarity.
Penalty Method p&s 1 7/7 (100%) 2 6/6 (100%) 3 2/2 (100%) Total 15/15 (100%) Table 6: A result of six diï¬€erent spellings of â€œspaghettiâ€ described in Section 1.
4.4 Estimation
of expected correct variant pairs We estimated how many correct variant pairs could be selected from the Corpus based on the precision of Method p&s as shown in Table 5.
The result is shown in Table 7.
We find that the number of candidate pairs in the Corpus was 100,746 for the penalty of 1, and 56,569 for the penalty of 2, and 40,004 for the penalty of 3.
For example, when the penalty was 2, we estimate that 46,178 out of 56,569 could be selected as correct variant pairs, since the precision was 81.6% as shown in Table 5.
In total, we estimate that 178,569 out of 197,319 could be selected as correct variant pairs from the Corpus.
Penalty # of expected variant pairs 1 100,746/100,746 (100%) 2 46,178/56,569 (81.6%) 3 31,645/40,004 (79.1%) Total 178,569/197,319 (90.5%) Table 7: Estimation of expected correct variant pairs.
4.5 Error
Analysis-1 As shown in Table 5, our system couldnâ€™t select two correct variant pairs using semantic similarity when the penalties were 1 and 2.
We investigated the reason from the training data.
The problem was caused because the contexts of the pairs were diï¬€rent.
For example, in the case of â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â€andâ€œï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ ï¿½,â€ which represent the same building material company â€œAroc Sanwaâ€ of Fukui prefecture in Japan, their contexts were completely diï¬€erent because of the following reason.
â€¢ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½(Aroc Sanwa): This word appeared with the name of an athlete who took part in the national athletic meet held in Toyama prefecture in Japan, and the company sponsored the athlete.
ï¿½ï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½(Aroc~Sanwa): This word was used to introduce the company in the article.
Note that each context of these words was composed of only one article.
4.6 Error
Analysis-2 FromTable5,weseethatthenumbersofincorrect variant pairs selected by Method p&s were 18 and 14 for each penalty of 2 and 3.
We investigated such cases in the training data.
The example of â€œï¿½ï¿½ï¿½(Cart, Kart)â€ and â€œï¿½ï¿½ï¿½ (Card)â€ is shown as follows.
â€¢ï¿½ï¿½ï¿½,ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½(Cart, Kart): This word was used as the abbreviation of â€œShopping Cart,â€ â€œRacing Kart,â€ or â€œSport Kart.â€ ï¿½ï¿½ï¿½(Card): This word was used as the abbreviation of â€œCredit Cardâ€ or â€œCash Cardâ€ and was also used as the meaning of â€œSchedule of Games.â€ Although these were not a variant pair, our system regarded the pair as the variant pair, because their contexts were similar.
In both contexts, â€œb;(utilization),â€ â€œGï¿½(record),â€ â€œl(guest),â€ â€œï¿½ï¿½b(aim),â€ â€œï¿½ï¿½ï¿½(team),â€ â€œ ï¿½(victory),â€ â€œï¿½M(high, expensive),â€ â€œï¿½ (success),â€ â€œ Z ï¿½(entry),â€ and so on were appeared frequently and therefore the semantic similarity became high.
5 Future
Work In this paper, we have used newspaper articles to construct Japanese KATAKANA variant list.
We are planning to apply our method on diï¬€erent types of corpus, such as patent documents and Web data.
We think that more variations can be found from Web data.
In the case of â€œspaghettiâ€ described in Section 1, we found at least seven more diï¬€erent spellings, such as â€œ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â€â€œï¿½ï¿½ï¿½ï¿½ï¿½,â€ â€œï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½,â€ and â€œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½.â€ Although we have manually tuned scoring rules of the string penalty using training data, we are planning to introduce an automatic method for learning the rules.
We will also have to consider other character types of Japanese, i.e.
KANJI variations and HIRAGANA variations, though we have focused on only KATAKANA variations in this paper.
For example, both â€œï¿½ï¿½`â€andâ€œï¿½l \`â€ mean â€œmoveâ€ in Japanese.
6Conclusion We have described the method to construct Japanese KATAKANA variant list from large corpus.
Unlike the previous work, we focused not only on the similarity in spelling but also on the semantic similarity.
From the experiments, we found that Method p&s performs better than Method p, since it constructed Japanese KATAKANA variant list with high performance of 97.4% recall and 89.1% precision.
Estimating from the precision, we found that 178,569 out of 197,319 could be selected as correct variant pairs from the Corpus.
The result could be helpful to solve the variant problems of information retrieval, information extraction, question answering, and so on.

