Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 505â€“513,
Honolulu, October 2008. cÂ©2008 Association for Computational Linguistics
Improved Sentence Alignment on Parallel Web Pages Using a  
Stochastic T ree Alignment Model 
Lei Shi 
Microsoft Research Asia 
5F Sigma Center, 49 Zhichun Road, Beijing 
100190, P. R. China 
leishi@microsoft.comÂ 
Ming Zhou 
Microsoft Research Asia 
5F Sigma Center, 49 Zhichun Road, Beijing 
100190, P. R. China 
mingzhou@microsoft.comÂ 
 
 
 
 
Abstract 
Parallel web pages are important source 
of training data for statistical machine 
translation. In this paper, we present a 
new approach to sentence alignment on 
parallel web pages. Parallel web pages 
tend to have parallel structuresï¼Œand the 
structural correspondence can be indica-
tive information for identifying parallel 
sentences. In our approach, the web page 
is represented as a tree, and a stochastic 
tree alignment model is used to exploit 
the structural correspondence for sentence 
alignment. Experiments show that this 
method significantly enhances alignment 
accuracy and robustness for parallel web 
pages which are much more diverse and 
noisy than standard parallel corpora such 
as â€œHansardâ€. With improved sentence 
alignment performance, web mining sys-
tems are able to acquire parallel sentences 
of higher quality from the web. 
1 Introduction

Sentence-aligned parallel bilingual corpora have 
been essential resources for statistical machine 
translation (Brown et al. 1993), and many other 
multi-lingual natural language processing applica-
tions. The task of aligning parallel sentences has 
received considerable attention since the renais-
sance of data driven machine translation in late 
1980s.  
During the past decades, a number of methods 
have been proposed to address the sentence align-
ment problem. Although excellent performance 
was reported on clean corpora, they are less robust 
with presence of noise. A recent study by (Singh 
and Husain 2005) completed a systematic evalua-
tion on different sentence aligners under various 
conditions. Their experiments showed that the per-
formance of sentence aligners are sensitive to 
properties of the text, such as format complexity 
(presence of elements other than text), structural 
distance (a scale from literal to free translation), 
the amount of noise (text deletions or preprocess-
ing errors) and typological distance between lan-
guages. Their performance varies on different type 
of texts and they all demonstrate marked perfor-
mance degradation over noisy data. The results 
suggest that there is currently no universal solution 
to sentence alignment under all conditions, and 
different methods should be applied to different 
types of texts. 
In this paper, we specifically address sentence 
alignment on parallel web pages. It has come to 
attention with the increasing trend of acquiring 
large-scale parallel data from the web. Currently, 
large-scale parallel data are not readily available 
for most language pairs and domains. But due to a 
sharply increasing number of bilingual web sites, 
web mining shows great promise as a solution to 
this knowledge bottleneck problem. Many systems 
(Ma 1999; Chen 2000; Yang 2002; Resnik 2003; 
Chen 2004) have been developed to discover paral-
lel web pages, and sentence aligners are used to 
extract parallel sentences from the mined web cor-
pora. Sentence alignment performance on parallel 
web pages, therefore, becomes an increasingly im-
portant issue for large-scale high-quality parallel 
data acquisition.  
Compared with clean parallel corpora such as 
"Hansard" (Brown et al. 1993), which consists of 
505
French-English translations of political debates in 
the Canadian parliament, texts from the web are far 
more diverse and noisy. They are from many dif-
ferent domains and of various genres. Their trans-
lation may be non-literal or written in disparate 
language pairs. Noise is abundant with frequent 
insertions, deletions or non-translations. And there 
are many very short sentences of 1-3 words. Due 
to the characteristics of web corpora, direct appli-
cation of conventional alignment methods without 
exploiting additional web document information 
yields unsatisfactory alignment results. 
Our approach to this problem is to make use of 
the structural parallelism between parallel web 
pages. Structural parallelism is the phenomenon, 
that when representing the same content in two 
different languages, authors have a very strong 
tendency to use the same document structure. As is 
shown in Figure 1, sentences located in similar 
position on both pages are more likely to be trans-
lations. Hence, correspondence in the web page 
structure is an informative indication of parallel 
sentences. In our approach, the web page is 
represented as a tree, and a stochastic tree align-
ment model is used to find the most probable 
alignment of the tree pair based on their structure 
and the texts in tree nodes. The tree alignment then 
acts as useful information to constrain the scope of 
search for parallel sentences.  
The paper is organized as follows: In section 2, 
we briefly survey previous approaches to sentence 
alignment. In section 3, we present the stochastic 
tree alignment model, including parameter estima-
tion and decoding. Then in section 4, we describe 
how to use the tree alignment model in sentence 
alignment. Benchmarks are shown in section 5, 
and the paper is concluded in section 6. 
2 Sentence
Alignment Models 
Sentence alignment methods can be categorized 
into three major categories: the length-based, lex-
icon-based and hybrid method which combines the 
length-based model and lexicon-based model as 
complement to each other.  
The length model was based on the intuition that 
the length of a translated sentence is likely to be 
similar to that of the source sentence. (Brown et. at. 
1991) used word count as the sentence length, 
whereas (Gale and Church 1993) used character 
count. Dynamic programming is used to search the 
optimal sentence alignment. Both algorithms have 
achieved remarkably good results for language 
pairs like English-French and English-German 
 
Figure 1. Example of parallel web pages 
506
with an error rate of 4% on average. But they are 
not robust with respect to non-literal translations, 
deletions and disparate language pairs.   
Unlike the length-based model, which totally 
ignores word identity, lexicon-based methods use 
lexical information to align parallel sentences. 
Kayâ€™sÂ  (Kay and Roscheisen 1993) approach is 
based on the idea that words that are translations of 
each other will have similar distribution in source 
and target texts. By adopting the IBM model 1, 
(Chen 1993) used word translation probabilities, 
which he showed gives better accuracy than the 
sentence length based method. Melamed (Me-
lamed 1996) rather used word correspondence 
from a different perspective as geometric corres-
pondence for sentence alignment.  
The hybrid method combines the length model 
with the lexical method. (Simard and Plamondon 
1996) used a two-pass approach, where the first 
pass performs length-based alignment at the cha-
racter level as in (Gale and Church 1993) and the 
second pass uses IBM Model 1, following (Chen 
1993). Mooreâ€™sÂ (Moore 2002) approach is similar 
to Simardâ€™s. The difference is that Moore used the 
data obtained in the first pass to train the IBM 
model in the second pass, so that his approach does 
not require a priori knowledge about the language 
pair. Instead of using a two-pass approach, (Zhao 
and Vogel 2002) combines the length model and 
the IBM model 1 in a unified framework under a 
maximum likelihood criterion. To make it more 
robust on noisy text, they developed a background 
model to handle text deletions.  
To further improve sentence alignment accuracy 
and robustness, methods that make use of addi-
tional language or corpus specific information 
were developed. In Brown andÂ  Churchâ€™s length-
based aligner, they assume prior alignment on 
some corpus specific anchor points to constrain 
and keep the Viterbi search on track. (Wu 1994) 
implemented a length-based model for Chinese-
English with language specific lexical clues to im-
prove accuracy. (Simard et al. 1992) used cognates, 
which only exists in closely related language pairs. 
(Chuang and Yeh 2005) exploited the statistically 
ordered matching of punctuation marks in two lan-
guages to achieve high accuracy sentence align-
ment. In their web parallel data mining system, 
(Chen and Nie 2000) used HTML tags in the same 
way as cognates in (Simard et al. 1992) for align-
ing Chinese-English parallel sentences. Tree based 
alignment models have been successfully applied 
in machine translation (Wu 1997, Yamada & 
Knight 2001, Gildea 2003).  
3 The
Stochastic T ree Alignment Model 
The structure of the HTML document is recursive, 
with HTML markup tags embedded within other 
markup tags. While converting an HTML docu-
ment into the tree representation, such hierarchical 
order is maintained. Each node of the tree is la-
beled with their corresponding HTML tag (e.g. 
body, title, img etc.) and in labeling tree nodes, 
only markup tags are used and attribute value pairs 
are dropped. Among all markup tags in the HTML 
file, those of our most interest are tags containing 
content text, which is what we want to align. These 
tags are those surrounding a text chunk or have the 
attribute of â€œALTâ€. Comments, scripts and style 
specifications are not regarded as content text and 
hence are eliminated. Figure 2 illustrates the tree 
representation of an example HTML document. 
html
head body
a
#text2
div
title
#text1
Img
#text3
. . .
<html>
<head><title>text1</title></head>
<body>
<a href=â€.htmlâ€>text2</a>
<div> â€¦Â </div>
<img src=â€.jpgâ€,alt=text3>
</body>
</html>
 
Figure. 2 An example HTML document and its 
tree representation 
 
3.1 T
ree Alignment Model 
Given two trees, the tree alignment is the non-
directional alignments of their nodes. A node in 
one tree can be aligned with at most one node in 
the other tree. It is valid for a node to be aligned 
with nothing (NULL) and such case is regarded as 
node deletion in tree alignment. To comply with 
the tree hierarchical structure, we constrain that the 
alignments keep the tree hierarchy invariant i.e. if 
node A is aligned with node B, then the children of 
A are either deleted or aligned with the children of 
B. Besides, to simplify the model training and de-
coding, the tree alignment model also keeps the 
507
sequential order invariant, i.e. if node A is aligned 
with node B, then the left sibling nodes of A cannot 
be aligned with the right sibling nodes of B.  
The stochastic tree alignment model assigns 
probabilities to tree alignments, based on the par-
ticular configuration of the alignment and model 
parameters. Then, the decoder is able to find the 
most probable (optimal) alignment of two trees. To 
facilitate the presentation of the tree alignment 
model, the following symbols are introduced: giv-
en a HTML document D, ğ‘‡
ğ·
denotes the corres-
ponding tree; ğ‘
ğ‘–
ğ·
denotes the i
th
 node of Â ğ‘‡
ğ·, 
andÂ ğ‘‡
ğ‘–
ğ·
Â denotes the sub-tree rooted atÂ ğ‘
ğ‘–
ğ·
. Espe-
cially, ğ‘‡
1
ğ·
Â is the root of the treeÂ ğ‘‡
ğ·
. ğ‘‡
[ğ‘–,ğ‘—]
ğ·
Â denotes 
the forest consisting of the sub-trees rooted at sibl-
ing nodes from ğ‘‡
ğ‘–
ğ·
 toÂ ğ‘‡
ğ‘—
ğ·
. ğ‘
ğ‘–
ğ·
.ğ‘¡ denotes the text in 
the node ğ‘
ğ‘–
ğ·, and ğ‘
ğ‘–
ğ·
.ğ‘¡  denotes the label (i.e. 
HTML tag) of the nodeÂ ğ‘
ğ‘–
ğ·
; ğ‘
ğ‘–
ğ·
.ğ¶
ğ‘–
 denotes the j
th
 
child of the node Â ğ‘
ğ‘–
ğ·
; ğ‘
ğ‘–
ğ·
.ğ¶
[ğ‘š,ğ‘›]
 denotes the con-
secutive sequence of Â ğ‘
ğ‘–
ğ·
â€™sÂ  childrenÂ  nodesÂ  fromÂ 
ğ‘
ğ‘–
ğ·
.ğ¶
ğ‘š
 toÂ ğ‘
ğ‘–
ğ·
.ğ¶
ğ‘›
; the sub-tree rooted at ğ‘
ğ‘–
ğ·
.ğ¶
ğ‘–
 is 
represented as ğ‘
ğ‘–
ğ·
.ğ¶ğ‘‡
ğ‘–
  and the forest of the sub-
trees rooted at Â ğ‘
ğ‘–
ğ·
â€™sÂ  childrenÂ  isÂ  representedÂ  as 
Â ğ‘
ğ‘–
ğ·
.ğ¶ğ¹. To accommodate node deletion, NULL is 
introduced to denote the empty node. Finally, the 
tree alignment is referred as A. 
Given two HTML documents F (in French) and 
E (in English) represented as trees ğ‘‡
ğ¹
andÂ ğ‘‡
ğ¸, the 
tree alignment task is defined as finding the align-
ment A that maximizes the conditional 
probability Â Pr(ğ´|ğ‘‡
ğ¹,ğ‘‡
ğ¸
) . Based on the Bayesâ€™ 
Rule, Pr(ğ´|ğ‘‡
ğ¹,ğ‘‡
ğ¸
) âˆ Â Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
|ğ´)Pr(ğ´) , where 
Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
|ğ´) is the probability of synchronously 
generating ğ‘‡
ğ¹
and ğ‘‡
ğ¸
given the alignment A, and 
Pr(ğ´) is the prior knowledge of the tree alignment. 
To simplify computation, we assume a uniform 
prior probability Pr(ğ´). Hence, the tree alignment 
task is to find the A that maximizes the synchron-
ous probabilityÂ Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
|ğ´). 
Based on the hierarchical structure of the tree, in 
order to facilitate the presentation and computation 
of the tree alignment probabilistic model, the fol-
lowing alignment probabilities are defined in a hie-
rarchically recursive manner: 
Pr(ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
|ğ´): The probability of synchronously 
generating sub-tree pair {ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
} given the align-
ment A; 
Pr(ğ‘
ğ‘š
ğ¹,ğ‘
ğ‘–
ğ¸
|ğ´): The probability of synchronously 
generating node pairÂ {ğ‘
ğ‘š
ğ¹,ğ‘
ğ‘–
ğ¸
};  
Pr(ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
|ğ´): The probability of synchron-
ously generating forest pairs {ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
} given 
the alignment A.  
From the definition, the tree pair generative 
probabilityÂ Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
|ğ´) equals to the root sub-
tree pair generative probabilityÂ Pr(ğ‘‡
1
ğ¹,ğ‘‡
1
ğ¸
|ğ´). The 
alignment of the sub-tree pair ğ‘‡
ğ‘—
ğ¹
and ğ‘‡
ğ‘–
ğ¸
 may have 
the following configurations, based on which the 
tree pair generative probability Pr(ğ‘‡
ğ‘—
ğ¹,ğ‘‡
ğ‘–
ğ¸
|ğ´) can 
be calculated: 
(1) IfÂ ğ‘
ğ‘š
ğ¹
Â is aligned with ğ‘
ğ‘–
ğ¸, and the children of 
ğ‘
ğ‘š
ğ¹
Â  are aligned with children of ğ‘
ğ‘–
ğ¸
(as is 
shown in Fig. 3a), then we have 
 
Â Pr.ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
/ğ´0 = Pr(ğ‘
ğ‘š
ğ¹,ğ‘
ğ‘–
ğ¸
)Pr(ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹,ğ‘
ğ‘–
ğ¸
.ğ¶ğ¹|ğ´) 
 
(2) If Â ğ‘
ğ‘š
ğ¹
is deleted, and the children of ğ‘
ğ‘š
ğ¹
 is 
aligned with ğ‘
ğ‘–
ğ¸
 (as shown in Fig. 3b), then we 
have 
 
Pr.ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
/ğ´0 = Pr(ğ‘
ğ‘š
ğ¹
|ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹,ğ‘‡
ğ‘–
ğ¸
|ğ´) 
 
(3) If ğ‘
ğ‘–
ğ¸
is deleted, andÂ ğ‘
ğ‘š
ğ¹
 is aligned with child-
ren of ğ‘
ğ‘–
ğ¸
 (as shown in Fig. 3c), then we have 
 
Pr(ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
|ğ´) = Pr(ğ‘‡
ğ‘š
ğ¹,ğ‘
ğ‘–
ğ¸
.ğ¶ğ¹|ğ´)Pr(ğ‘
ğ‘–
ğ¸
|ğ‘ğ‘ˆğ¿ğ¿) 
 
( a )
( b )
N U L L
( c )
N U L L
F
m
T
F
m
T
F
m
T
E
i
T
E
i
E
i
T
 
Figure. 3 
 
The above equations involve forest pair generative 
probabilities. The alignment of the forest 
ğ‘‡
[ğ‘š,ğ‘›]
ğ¹
Â and ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
 may have the following configura-
tions, based on which their forest pair generative 
probabilityÂ Pr(ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
|ğ´)Â can be calculated: 
508
(4) If ğ‘‡
ğ‘š
ğ¹
 is aligned with ğ‘‡
ğ‘–
ğ¸, and ğ‘‡
[ğ‘š+1,ğ‘›]
ğ¹
 is 
aligned with ğ‘‡
[ğ‘–+1,ğ‘—]
ğ¸
 (as is shown in Fig. 4a), 
then 
  
Pr.ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
/ğ´0
= Pr(ğ‘‡
ğ‘š
ğ¹,ğ‘‡
ğ‘–
ğ¸
|ğ´)Pr(ğ‘‡
[ğ‘š+1,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–+1,ğ‘—]
ğ¸
|ğ´) 
 
(5) IfÂ ğ‘
ğ‘š
ğ¹
 is deleted, and the forest rooted atÂ ğ‘
ğ‘š
ğ¹
â€™sÂ 
children ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹Â is combined with ğ‘‡
[ğ‘š+1,ğ‘›]
ğ¹
 for 
alignment with ğ‘‡
[ğ‘–,ğ‘—]
ğ¸, then 
 
Pr.ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
/ğ´0
= Pr(ğ‘
ğ‘š
ğ¹
|ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹Â ğ‘‡
[ğ‘š+1,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
|ğ´) 
 
(6) IfÂ ğ‘
ğ‘–
ğ¸
 is deleted, and the forest rooted atÂ ğ‘
ğ‘–
ğ¸
â€™sÂ 
children Â ğ‘
ğ‘–
ğ¸
.ğ¶ğ¹  is combined with ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
 for 
alignment with ğ‘‡
[ğ‘š,ğ‘›]
ğ¹, then 
 
Pr.ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘‡
[ğ‘–,ğ‘—]
ğ¸
/ğ´0
= Pr(ğ‘
ğ‘–
ğ¸
|ğ‘ğ‘ˆğ¿ğ¿)Pr(ğ‘‡
[ğ‘š,ğ‘›]
ğ¹,ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹Â ğ‘‡
[ğ‘–+1,ğ‘—]
ğ¸
|ğ´) 
      
(a )
E
j]1,[i
T
ï€«
i
Î¤
F
n]1,[m
T
ï€«
m
Î¤
(b )
E
j][i,
F
n]1,[m
T
ï€«
F
.CF
F
m
(c )
E
i
Î¤
F
n][m,
T
E
j]1,[i
T
ï€«
.CFT
E
i
N U L L
N U L L
 
Figure. 4 
 
Finally, the node pair probability is modeled 
as Â Pr(ğ‘
ğ‘š
ğ¹,ğ‘
ğ‘–
ğ¸
) = Pr(ğ‘
ğ‘š
ğ¹
.ğ‘¡,ğ‘
ğ‘–
ğ¸
.ğ‘¡)Pr(ğ‘
ğ‘š
ğ¹
.ğ‘™,ğ‘
ğ‘–
ğ¸
.ğ‘™) , 
where Pr(ğ‘
ğ‘š
ğ¹
.ğ‘¡,ğ‘
ğ‘–
ğ¸
.ğ‘¡)Â is the generative probability 
of the translationally equivalent text chunks 
inÂ ğ‘
ğ‘š
ğ¹
Â andÂ ğ‘
ğ‘–
ğ¸, and Pr(ğ‘
ğ‘š
ğ¹
.ğ‘™,ğ‘
ğ‘–
ğ¸
.ğ‘™)Â  is their HTML 
tag pair probability. The text chunk generative 
probability Pr(ğ‘
ğ‘š
ğ¹
.ğ‘¡,ğ‘
ğ‘–
ğ¸
.ğ‘¡) can be modeled in a 
variety of ways. The conventional length-based, 
lexicon-based or hybrid methods used for sentence 
alignment can be applied here. In the next sub-
section, we focus on how to estimate the tag pair 
probabilityÂ Pr(ğ‘
ğ‘š
ğ¹
.ğ‘™,ğ‘
ğ‘–
ğ¸
.ğ‘™)Â  from a set of parallel 
web pages. We expect pairs of the same or similar 
HTML tags to have high probabilities and the 
probabilities for pairs of disparate tags to be low. 
3.2 Parameter
Estimation Using Expectation-
Maximization 
One way to estimate the tag pair generative proba-
bility Pr(ğ‘™,ğ‘™â€²)Â  is to manually align nodes between 
parallel trees, and use the manually aligned trees as 
the training data for maximum likelihood estima-
tion. However, this is a time-consuming and error-
prone procedure. Instead, the Expectation Maximi-
zation (EM) (Dempster, Laird and Rubin 1977) 
algorithm is used to estimate the 
parameters Â Pr(ğ‘™,ğ‘™â€²)Â  on 5615 manually verified 
parallel web page pairs from 45 different bilingual 
web sites. The parameter estimation proceeds as 
follows:  
 
1. Start with initial parameter values. 
2. Expectation: estimate count
:::::::(
ğ‘™,ğ‘™
â€²
)Â which is 
the expectation of aligning tag l with 'l . 
3. Maximization: update the parameters based 
to maximum likelihood estimation 
ï€¨ ï€©
ï€¨ ï€©
ï€¨ ï€©
ïƒ¥
ï€½
'
'
'
',,,Pr
l
llcount
llcount
ll
  and 
ï€¨ ï€© ï€¨ ï€©
ï€¨ ï€© ï€¨ ï€©
ïƒ¥
ï€«
ï€«
ï€½
'
],,[,,
)Pr(
''
l
NULLlcountlNULLcount
NULLlcountlNULLcount
NULLl
 
4. Repeat step 2 and 3 until the parameters 
stabilize  
 
In step 2, count
:::::::(
ğ‘™,ğ‘™
â€²
) is the expected count of l  
being aligned with 
'
l  in the training corpus. By 
definition, count
:::::::(
ğ‘™,ğ‘™
â€²
) is calculated as  
count
:::::::(
ğ‘™,ğ‘™
â€²
) = ;Pr(ğ´|ğ‘‡
ğ¹
ğ´,ğ‘‡
ğ¸
)count(ğ‘™,ğ‘™
â€²
) 
where  count(ğ‘™,ğ‘™
â€²
) is the number of occurrence of l 
being aligned with lâ€™ in the tree alignment A. 
To efficiently compute count
:::::::(
ğ‘™,ğ‘™
â€²
)  without 
enumeratingÂ theÂ exponentialÂ numberÂ ofÂ Aâ€™sÂ inÂ theÂ 
above equation, we extended the inside-outside 
algorithm presented in (Lari and Young, 1990). 
The inside probability ğ›¼(ğ‘
ğ‘—
ğ¹,ğ‘
ğ‘–
ğ¸
) is defined as the 
509
probability of generating sub-tree pair {ğ‘‡
ğ‘—
ğ¹,ğ‘‡
ğ‘–
ğ¸
} 
when ğ‘
ğ‘–
ğ¸
 is aligned withÂ ğ‘
ğ‘—
ğ¹
. It is estimated as: 
 
ï€¨ ï€© ï€¨ ï€© ï€¨ ï€©CFNCFNNNNN
E
i
F
m
E
i
F
m
E
i
F
m
.,.,Pr, ï¡ï¡ ï€½  
 
where ğ›¼(ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹,ğ‘
ğ‘–
ğ¸
.ğ¶ğ¹) is the inside probability 
for the forest pairÂ (ğ‘
ğ‘š
ğ¹
.ğ¶ğ¹,ğ‘
ğ‘–
ğ¸
.ğ¶ğ¹)  
 
ï€¨ ï€© ï€¨ ï€©
ïƒ¥
ï€½
A
E
i
F
m
E
i
F
m
ACFNCFNCFNCFN .,.Pr.,.ï¡
.  
The inside probability can be estimated recursively 
according to the various alignment configurations 
presented in Figure 3 and Figure 4.  The outside 
probabilityÂ ğ›½(ğ‘
ğ‘—
ğ¹,ğ‘
ğ‘–
ğ¸
) is defined as the probability 
of generating the part of ğ‘‡
ğ¸
and ğ‘‡
ğ¹
Â excluding the 
sub-trees ğ‘‡
ğ‘—
ğ¹
andÂ ğ‘‡
ğ‘–
ğ¸, when ğ‘
ğ‘–
ğ¸
 is aligned withÂ ğ‘
ğ‘—
ğ¹
. 
It is estimated as: 
 
ï€¨ ï€© ï€¨ ï€©
ï€¨ ï€© ï€¨ ï€©ï€¨ ï€©
ï€¨ ï€© ï€¨ ï€©ï€¨ ï€©
ïƒ• ïƒ•
ïƒ¥
ï€¼ ï€¼
ï‚´
ï‚´
ï‚´
ï€½
qk pk
E
ki
F
km
E
i
E
pi
F
m
F
qm
E
i
E
pi
F
m
F
qm
qp
E
pi
F
qm
E
i
F
m
NULLaNULLa
NRCFaNRCFa
NLCFaNLCFa
aaNN
])|Pr()|Pr(
.,.
.,.,[,,,,,,,,,,
ï¡
ï¡
ï¢ï¢
 
where ğ‘
ğ‘š,ğ‘
ğ¹
 is the q
th
  ancestor of ğ‘
ğ‘š
ğ¹, and ğ‘
ğ‘–,ğ‘
ğ¸
 is 
the p
th
 ancestor of ğ‘
ğ‘–
ğ¸
. ğ‘
ğ‘š,ğ‘˜
ğ¹
(ğ‘˜ < ğ‘) is an ancestor 
of ğ‘
ğ‘š
ğ¹
Â and a decedent of Â ğ‘
ğ‘š,ğ‘
ğ¹
. Similarly ğ‘
ğ‘–,ğ‘˜
ğ¸
(ğ‘˜ <
ğ‘Â  is an ancestor of ğ‘ğ‘–ğ¸, and a decedent of ğ‘ğ‘–,ğ‘ğ¸. 
a.LC F(N) is the forest rooted at a and to the left of 
N, and a.RC F(N). a.RC F(N) is the forest rooted as 
a and to the right of N. Once inside and outside 
probabilities are computed, the expected counts 
can be calculated as 
ï€¨ ï€©
ï€¨ ï€© ï€¨ ï€©
ï» ï½
ïƒ¥ ïƒ¥
ï€½
ï€½
ï€½
EF
F
m
E
i
TT
llN
llN
EF
E
i
F
m
E
i
F
m
TT
NNNN
llcount,
.
.
'
' ),Pr(,,,
ï¢ï¡
 
where Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
)Â is the generative probability of 
the tree pair {ğ‘‡
ğ¹,ğ‘‡
ğ¸
} over all possible alignment 
configurations. Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
)Â can be estimated using 
dynamic programming techniques that will be pre-
sented in the next sub-section. Furthermore, the 
expected count of tag deletion is estimated as: 
count
:::::::(
ğ‘™,ğ‘ğ‘ˆğ¿ğ¿) = ;count(ğ‘™,ğ‘™
â€²
)
ğ‘–
âˆ’ ; count
:::::::(
ğ‘™,ğ‘™
â€²
)
ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿
 
count
:::::::(
ğ‘ğ‘ˆğ¿ğ¿,ğ‘™) = ;count(ğ‘™
â€²,ğ‘™)
ğ‘–
âˆ’ ; count
:::::::(
ğ‘™
â€²,ğ‘™)
ğ‘–â‰ ğ‘ğ‘ˆğ¿ğ¿
 
3.3 Dynamic
Programming for Decoding 
An intuitive way to find the optimal tree alignment 
is to enumerate all alignments and pick the one 
with the highest probability. But it is intractable 
since the total number of alignments is exponential. 
Based on the observation that if two trees are op-
timally aligned, the alignment of their sub-trees 
must also be optimal, dynamic programming can 
be applied to find the optimal tree alignment using 
that of the sub-trees in a bottom-up manner. That is 
we first compute the optimal alignment probabili-
ties of small trees and use them to compute that of 
the bigger tree by trying different alignment confi-
gurations. This procedure is recursive until the op-
timal alignment probability of the whole tree is 
obtained. The following is the pseudo-code of the 
bottom-up decoding algorithm:  
 
where |ğ‘‡
ğ¹
| and |ğ‘‡
ğ¸
| are the number of nodes in 
ğ‘‡
ğ¹
and ğ‘‡
ğ¸
. The decoding algorithm finds the op-
timal alignment and its probability for every sub-
trees and forests. By replacing the selection opera-
tion with summing probabilities of all configura-
tions, the sub-tree pair generative probability 
Pr(ğ‘‡
ğ¹,ğ‘‡
ğ¸
) can be calculated along the way. The 
worst-case time complexity of the algorithm 
is Â ğ‘‚(|ğ‘‡
ğ¹
||ğ‘‡
ğ¸
|.ğ‘‘ğ‘’ğ‘”ğ‘Ÿ(ğ‘‡
ğ¹
)+ ğ‘‘ğ‘’ğ‘”ğ‘Ÿ(ğ‘‡
ğ¸
)0
2
) , where 
the degree of a tree is defined as the largest degree 
of its nodes.  
4 Sentence
Alignment with T ree Align-
ment Model 
Since the tree alignment model aligns parallel web 
pages at the tree node level instead of the sentence 
level, we integrate the tree alignment model with 
the sentence alignment model in a cascaded mode, 
in which the whole sentence alignment process is 
divided into two steps. In the first step, the tree 
alignment decoder finds the optimal alignment of 
the two trees. Nodes having texts should be aligned 
with nodes containing their translations. Then in 
the second step, the conventional sentence aligner 
is used to align sentences within text chunks in the 
for i=|ğ‘‡
ğ¸
| to 1 (bottom-up) { 
for j=|ğ‘‡
ğ¹
|Â to 1 (bottom-up) { 
Select and store optimal alignments of their children fo-
rests Â ğ‘‡
ğ‘š
ğ¹
.CFÂ and Â ğ‘‡
ğ‘–
ğ¸
.CF
 
by testing configurations 4-6; 
Select and store the optimal alignment of the sub-tree 
pair Â ğ‘‡
ğ‘š
ğ¹
 andÂ ğ‘‡
ğ‘–
ğ¸
Â by testing configurations 1-3; 
Store the optimal configuration}} 
510
aligned nodes. In this step, various sentence align-
ment models can be applied, including the length-
based model, the lexicon-based model and the hy-
brid model. Language or corpus specific informa-
tion may also be used to further improve sentence 
alignment accuracy. The tree alignment acts as 
constraints that confine the scope of the search of 
sentence aligners.  
5 Evaluation

To evaluate the effectiveness of exploiting web 
page document structure with the tree alignment 
model for improving sentence alignment accuracy, 
we compared the performance of three types of 
sentence alignment methods on parallel web pages.  
The first type is to simply discard web page 
layout information. Web pages are converted to 
plain texts, and HTML tags are removed prior to 
performing sentence alignment. The second type is 
the baseline method of using web page document 
information. Instead of exploiting full HTML doc-
ument structure, it follows Chenâ€™sÂ approachÂ (Chen 
and Nie 2000) which uses HTML tags in the same 
way as cognates used in (Simard et al. 1992). The 
third type is the combination of tree alignment 
model and conventional sentence models.  
Each type of the web page sentence aligner 
makes use of three conventional sentence align-
ment models, one is the length based model fol-
lowing (Brown 1991), one is the lexicon based 
model following (Chen 1993), and the other one is 
the hybrid model presented in (Zhao 2002). To be 
fair in performance comparisons, the text genera-
tive probability Pr(ğ‘
ğ¹
.ğ‘¡,ğ‘
ğ¸
.ğ‘¡)  in tree node 
alignment is modeled in accordance with that in 
the sentence alignment model. All these sentence 
aligners are implemented to handle sentence bead 
typesÂ ofÂ â€œ1-0â€,Â â€œ0-1â€,â€œ1-1â€,Â â€œ1-2â€,â€1-3â€,â€2-1â€Â andÂ 
â€œ3-1â€. 
The test corpus is 150 parallel web page pairs 
randomly drawn from 20 Chinese-English bilin-
gual web sites on topics related to politics, sports, 
computer and literature. By manual annotation, 
9,824 parallel sentence pairs are found. All sen-
tence aligners run through the test parallel web 
pages, and each extracts a set of sentence pairs that 
it regards as parallel. The output pairs are matched 
with the annotated parallel sentences from the test 
corpus. Only exact matches of the sentence pairs 
are counted as correct. 
Our evaluation metrics are precision (P), recall 
(R) and F-measure (F) defined as: 
 
pairsoutput   totalof #
pairs sentence alignedcorrectly  of #
P ï€½  
pairs parallel  trueof #
pairs sentence alignedcorrectly  of #
R ï€½  
RP
R*P*2
F
ï€«
ï€½  
 
Based on the results in table 1, we can see that 
both Type 2 and Type 3 aligners outperform con-
ventional sentence alignment models. Leveraging 
HTML document information can enhance sen-
tence alignment quality. Especially, by using the 
tree alignment model, Type 3 aligners achieve a 
significant increase of around 7% on both preci-
sion and recall. Compared with the tree alignment 
model, the improvement by the Type 2 aligners is 
marginal. A reason for this is that the tree align-
ment model not only exploits HTML tag similari-
ties as in the Type 2 method, but also takes into 
account location of texts. In the tree alignment 
model, texts at similar locations in the tree hierar-
chical structure are more probable to be transla-
tions than those in disparate locations, even though 
they all have the same tag.  
We also evaluate the performance of the tree 
aligner. Since sentence alignment is performed 
within the text chunks of aligned nodes, tree 
alignment accuracy is very important for correct 
sentence alignment. We measure the alignment 
 Length Lexicon Hybrid 
P R F P R F P R F 
Type I 85.6% 72.8% 78.7% 83.1% 75.2% 78.9% 87.3% 76.4% 81.5% 
Type II 86.3% 74.8% 80.1% 85.7% 77.0% 81.1% 88.1% 78.6% 83.1% 
Type III 93.2% 79.3% 85.7% 92.9% 80.4% 86.2% 94.3% 83.1% 88.3% 
Table 1. Performance comparison between different types of sentence alignment methods 
 
511
accuracy on all nodes as well as that specifically 
on text nodes on the test corpus. The evaluation 
result is shown in table 2. 
 
Benchmarks in Table 2 show that the tree 
alignment model yields very reliable results with 
high accuracy in aligning both text nodes and non-
text nodes. After an analysis on text node align-
ment errors, we find that 79.7% of them have texts 
of very short length (no more than 4 words), which 
may not contain sufficient information to be identi-
fied as parallel. 
6 Conclusions

In this paper, we present a new approach to sen-
tence alignment on parallel web pages. Due to the 
diversity and noisy nature of web corpora, a sto-
chastic tree alignment model is employed to ex-
ploit document structure in parallel web pages as 
useful information for identifying parallel sen-
tences. The tree alignment model can be combined 
with various conventional sentence alignment 
models to extract parallel sentences from parallel 
web pages. Experimental results show that exploit-
ing structural parallelism inherent in parallel web 
pages provides superior alignment performance 
over conventional sentence alignment methods and 
significant improvement (around 7% in both preci-
sion and recall) is achieved by using the stochastic 
tree alignment model. With improved sentence 
alignment performance, web parallel data mining 
systems are able to acquire parallel sentences of 
higher quality and quantity from the web.  
References: 
Brown, P. F., J. C. Lai and R. L. Mercer. 1991. Aligning 
Sentences in Parallel Corpora. Proceedings of ACL 
1991.  
Brown, P. E., S. A. D. Pietra, V. J. D. Pietra, and R. L. 
Mercer. 1993. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation, Computa-
tional Linguistics V19(2), 1993  
Chen Jisong., Chau R. and C.-H. Yeh. 2004. Discover-
ing Parallel Text from the World Wide Web, Proceed-
ings of the second workshop on Australasian Infor-
mation Security, Data Mining and Web Intelligence, 
and Software Internationalization. 
Chen Jiang and Nie Jianyun. 2000. Automatic construc-
tion of parallel English-Chinese corpus for cross-
language information retrieval. Proceedings of the 
sixth conference on applied natural language 
processing 
Chen Stanley. 1993. Aligning Sentences in Bilingual 
Corpora Using Lexical Information. Proceedings of 
ACL 1993 
Chuang T.C. and Yeh.K.C. 2005. Aligning Parallel Bi-
lingual Corpora Statistically with Punctuation Crite-
ria. Computational Linguistics and Chinese Lan-
guage Processing. Vol. 10, 2005, pp. 95-122 
Dempster, A., Laird, N., and Rubin, D. 1977. Maximum 
likelihood from incomplete data via the EM algo-
rithm.  Journal of the Royal Statistical Society, Series 
B, 39(1):1â€“38. 
Gale W. A. and K. Church. 1993. A Program for Align-
ing Sentences in Parallel Corpora, Computational 
Linguistics, 19(1):75â€”102 
Gildea. D. 2003. Loosely Tree-Based Alignment for 
Machine Translation. In Proceedings of ACL 2003 
Kay Martin and Roscheisen Martin 1993. Text Transla-
tion Alignment. Computational Linguistics 
19(1):121--142. 
Lari K. and S. J. Young. 1990. The estimation of sto-
chastic context free grammars using the Inside-
Outside algorithm, Computer Speech and Language, 
4:35â€”56 
Ma, Xiaoyi and M. Liberman. 1999. Bits: A Method for 
Bilingual Text Search over the Web. Proceedings of 
Machine Translation Summit VII. 
Melamed. I. Dan. 1996. A Geometric Approach to 
Mapping Bitext Correspondence. Proceedings of 
EMNLP 96 
Moore Robert. C. 2002. Fast and Accurate Sentence 
Alignment of Bilingual Corpora. Proceedings of 5th 
Conference of the Association for Machine Transla-
tion in the Americas, pp. 135-244 
Resnik, P. and N.A. Smith. 2003. The Web as a Parallel 
Corpus.Computational Linguistics, 29(3)  
Simard, M. and Plamondon, P. 1996 Bilingual Sentence 
Alignment: Balancing Robustness and Accuracy. 
Proceedings of AMTA-96, Canada. 
Simard, M., Foster, G. and Isabelle, P. 1992, Using 
Cognates to Align Sentences in Bilingual Corpora. 
Proceedings of the Fourth International Conference 
 total correct accuracy 
all node alignment 18492 17966 97.2% 
text node alignment 3646 3577 98.1% 
Table 2. Tree Alignment Metrics 
512
on Theoretical and Methodological Issues in Ma-
chine translation (TMI92)  
Singh, A. K. and Husain, S. (2005). Comparison, selec-
tion and use of sentence alignment algorithms for 
new language pairs. Proceedings of the ACL Work-
shop on Building and Using Parallel Texts.  
Wu. Dekai. 1994. Aligning a parallel English-Chinese 
corpus statistically with lexical criterias. Proceedings 
of ACL 1994.  
Wu.Â Dekai.Â â€œStochastic Inversion Transduction Gram-
mar and Bilingual Parsing of Parallel Corporaâ€Â 
Computational Linguistics, 23(3):374(1997) 
Yamada H. and Knight K. 2001 A Syntax based statis-
tical translation model. In Proceedings of ACL-01 
Yang C. C., and Li K. W., Mining English/Chinese Pa-
rallel Documents from the World Wide Web, Pro-
ceedings of the International World Wide Web Con-
ference, Honolulu, Hawaii, 2002. 
Zhao Bin. and Stephan. Vogel. 2002. Adaptive Parallel 
Sentences Mining From Web Bilingual News Collec-
tion. 2002 IEEE International Conference on Data 
Mining. 745-748 
513

