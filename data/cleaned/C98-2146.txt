Automatic Text Summarization Based on 
the Global Document Annotation 
Katashi Nagao 
Sony Computer Science Laboratory Inc. 
3-14-13 Higashi-gotanda, Shinagawa-ku, 
Tokyo 141-0022, Japan 
nagao@csl.sony.co.jp 
K6iti Hasida 
Electrotechnical Laboratory 
1-1-4 Ulnezono, Tukuba, 
Ibaraki 305-8568, Japan 
hasida@etl.go.jp 
Abstract 
The GDA (Glol)al Do(:ument Annotation) t)roject 
t)roposes a tag set which allows machines to auto
matically infer the underlying semantic/pragmatic 
structure of documents. Its objectives are to pro
mote development and spread of NLP/AI at)plica
tions to render GDA-tagged do(:uments versatile and 
intelligent (:ontents, wld(:h shouhl motiwtte WWW 
(World Wide Web) users to tag their doemnents a~s 
l)art of content authoring. This 1)aper discusses au
tomatic text sunnnariz~tion based on GDA. Its mifin 
features are a domain/style-fi'ee algorithm and per
sonalization on SUlmnarization whi(:h reflects read
ers' interests and preferences. In order to calcu
late the iml)ort~m(:e score of a text element, the 
algorithm uses st)re;uting aetiwttion on an intra
doeulnent network whi(:h conm'.(:ts text elements via 
thematic, rhetorical, and corefere.ntial re.lations. The 
i)roi)osed method is flexible enough to dynami(:ally 
gen(,rate sllnllllaries of wLrious sizes, i Slllll111ary 
t)rowse.r SUl)porting I)ersonalization is reported ~m 
well. 
1, Introduction 
The WWW hiLs opened up all era in which an un
restricted nunfl)er of people i)ut)lish their messages 
(dectronically through their online do(:mnents. How
ever, it is still very hard to automatically process 
(:ontents of those documents. The reasons include 
the following: 
1. HTML (HyperText Markup Language) tags 
mainly specify the physical layout of docu
ments. They address very fe.w (:on~,ent-related 
annotations. 
2. Hypertext links cannot very nmch 11(;11) readers 
recognize the content of a document. 
3. The WWW authors tend to 1)e less earefifl 
about wording and readability than in tradi
tional t)rintcd media. Currently there is no sys
tematic means for quality control in the WWW. 
Although HTML is a fle.xible tool that allows you 
to freely write and read messages on the WWW, it 
is neither very c(mvenient to readers nor suital)h: for 
automatic 1)roeessing of contents. 
We have been deveh)t)ing an integrated platfornl 
for (loeunmnt authoring, t)ul)lishing. &lid reltse by 
combining natural language and WWW teehnoh)
gies. As the first ste l) of our project, we (\[efined a 
new tag set and developed tools for editing tagged 
texts and browsing these texts. The browser has the 
functionality of summarization an(l (:ont(ult-base(l 
retrieval of tagged docmnents. 
This l)aper focuse.s on summarization t)ased on 
this system. The main features of our summariza
tion method are a dmnain/styh.~-free algorithm and 
l)ersonalization to reflect readers" interests and pref
eren(:es. This method mtturally outperfornm the tr~t
ditional summarization methods, which just pick out 
senten(:(,.s highly scored on the basis of superii(:iM 
clues such as word count, and so on. 
2 Global
Document Annotation 
GDA (Global Do(:mne.nt Almotation) is a chal
lenging t)rojeet to Inake WWW texts nl&(:hine
undel'standabh~ on the basis of a new tag set. 
and to develo l) Col~tent-t)ased presentation, retrieval, 
question-answering, summarization, and translation 
systems with mu(:h higher quality thorn before. GDA 
thus t)roposes an integrated global platform for ele(:
tronic conl;ent authoring, presentation, and reuse. 
The GDA tag se.t is based on XML (Extensibh; 
Markup Language), and designed ~us (:Oml)atible as 
possible with HTML, TEl. EAGLES, and so forth. 
An example of a GDA-tagged sentence is as follows: 
<su><np sem=t imeO>t ime</np> 
<vp><v sem=flyl>flies</v> 
<adp><ad sem=likeO>like</ad> <np>an 
<n sem=arrowO>arrow</n></np> 
</adp></vp>. </su> 
<su> means sentential unit. 
<n>. <np>. <v>. <vp>. <ad> alld <adp> lllealt 11o1111. 
917 
noun phrase, verb, verb I)hr~se, adnoun or adverb 
(including preposition and postposition), and ad
nominal or adverl)ial phrase, respectively 1. 
The GDA initiative aims at having many WWW 
authors ammtate their on-line documents with this 
common tag set so that machines can automatically 
recognize tile underlying sexnantic and pragmatic 
structures of those documents much nmre easily 
than by analyzing traditional HTML files. A huge 
amount of annotated data is expected to emerge, 
which should serve not just as tagged linguistic cor
pora but also as a worldwidc, self-extending knowl
edge base, mMnly consisting of examples showing 
how our knowledge is manifested. 
GDA has three main steps: 
1. Propose an XML tag set which allows machines 
to automatically infer the underlying structure 
of documents. 
2. Promote develoi)ment and spread of NLP/AI 
applications to turn tagged texts to versatile 
and intelligcnt contents. 
3. Motivate thereby the authors of WWW files to 
annotate their documents nsing thosc tags. 
2.1 Themantic/Rhetorical Relations 
The tel attribute encodes a relationship in wl,ieh 
the current element stands with respect to the ele
ment that it semantically deI)ends on. Its wdue is 
called a relational term. A relational ternl denotes a 
binary relation, which may be a thematic role such 
as agent, patient, reeiI)ient, etc., or a rhetorical rela
tion such as cause, concession, et(:. Thus we conflate 
thematic roles and rhetorical relations here, because 
the distinction between them is often vague. For in
stance, concession may be both intrasentential and 
intersentential relation. 
Here is an example of a rel attribute: 
<su ctyp=fd><name rel=agt>Tom</name> 
<vp>came</vp>. </su> 
ctyp=£d means that the first element 
<name rel=agt>Tom</name> deI)ends on the second 
element <vp>came</vp>. rel=agt means that Tom 
has the agent role with respect to the event denoted 
by came. 
rel is an open-class attril)ute, potentially encom
passing all the binary relations lexicalized in nat
ural languages. An exhaustive listing of thematic 
roles and rhetorical relations appears impossible. ~L~ 
widely recognized. We are not yet sure about how 
1A more detailed description of the GDA tag set can be 
found at http://www, et 1. go. jp/etl/nl/GDh/tagset, html. 
mauy tlmmatic roles and rhetorical relations are suf
ficient for engineering applications. However. the 
appropriate granularity of classification will be de
termined by the current level of technology. 
2.2 Anaphora
and Coreference 
Each element may have an identifier as the value of 
the id attribute. Anaphorie expression should have 
the ana attribute with its antecedent's id value. An 
example follows: 
<name id=:t>John</name> beats 
<adp ana=:t>his</adp> dog. 
A non-anaphoric coreference is marked by the crf 
attribute, whose usage is the same as the ana at
tribute. 
When the coreference is at the level of type (kind. 
sort, etc.) which the referents of the antecedent 
and the an~phor are tokens of, we use the cotyp 
attribute as below: 
You bought <np id=ll>a car</np>. 
I bought <np cotyp=ll>one</np>, too. 
A zero an~phora is encoded by using the appro
priate relationM term as an attribute name with the 
refi;rent's id value. Zero anaphors of colnpulsory el
ements, which describe the internal structure of the 
events represented by the verbs of adjectives are re
quired to t)e resolved. Zero mmphors of optional ele
lneltts such ms with reason and ineans roles may not. 
Here is an examI)le of a zero anal)hora concerning 
an optional thematic role ben (for beneficiary): 
Tom visited <name id=lll>Mary</name>. 
He <v ben=lll>brought</v> a present. 
3 Text
Summarization 
As an examl)ic of a basic ai)plication of GDA. we 
have developed an automatic text summarization 
system. Summarization generally requires deep se
mantic processing and a lot of background knowl
edge. However, most previous works use several su
perficial clues and heuristics on specific styles or con
figurations of doculnents to SUlnnlarize. 
For example, clues fl)r dcternlining the import;met 
of a sentence include (1) sentence length, (2) key
word count, (3) tense, (4) sentence type (such a.~ 
fact, conjecture and assertion), (5) rhetorical rela
tion (such ,~s rea.~on and example), and (6) position 
of sentence in the whole text. Most of these are ex
tracted by a shallow t)rocessing of the text. Such a 
computation is rather robust. 
Present Smnlnarization systems (Watanabe. 1996: 
Hovy and Lin, 1997) use such clues to calculate an 
importance score for each sentence, choose sentences 
918 
according to the score, and simply i)ut the selected 
sentences together in order of their occurrences in 
the original (lo(:umellt. In a sense_ these, systems are 
suceessflfl enough to I)e practical, and are based on 
reliable technologies. However, tit(.' quality of SUln
marization cannot be improved beyond this basic 
level without any dee I) content-1)a.sed processing. 
We propose a new summarization method I)~used 
on GDA. This method emt)loys a spreading activa
tion technique (Ha.si(la et al., 1987) to calculate the 
importance wdues of elements in the te.xt. Since tile 
method does not cmI)loy any heuristics det)endent on 
the domain and style of documents, it is apt)lieablc 
to any GDA-tagged do(:unmnts. The method also 
can trim sentences in the. smmnary t)ecause ilnl)or
Lance scores are assigne(t to elements smaller than 
sentences. 
A GDA-tagged document naturally defines an 
intra-do('umcnt network in which no(its corre
Sl)ond to elements and links represent tile seman
tic relations mentioned in the previous se, ctiou. 
This network consists of sentence trees (syntactic 
head-daughter hierarchies of sul)sentential elements 
such as words or t)hrases), (:oreference/anal)ll.ora 
links, doculnent/sul)division/i)aragrat)h nodes, and 
rhetorical relation links. 
Figure 1 shows a gral)hical representation of the 
intra-document network. 
document 
subdivisian F'~ /~k v 
<o0,,oo.,, /l \ 
paragraph ~ U t) '.0 U ',# " • • " 
(optional) J "%~ 
sent .... \]~ j~----I ..... 
.u..e.te,,t,.,d b\ 65 .... "°" segment 1~'%. ~ \ l\ ~ .... reference 
Figure 1: Intra-Docunw.nt Network 
The summarization algorithm is the following: 
1. Spreading activation is t)erforme(l ill such a 
way that two elements have the same activa
tion valu(', if they are coreferent or (in(." of them 
is the syntactic head of the other. 
2. The unlnarked element with the highest actiw> 
tion vMue is marked for inclusion in the sum
mary. 
3. When an element is marked, other elenmnts 
listed below are recursively lnarked ms well, mltil 
11o lnore elelllellt may \])e lnarkcd. 
* its head 
• its antc(:e, dent 
• its compulsory or a priori hnl)ortant 
daughters, the, wdues of whose relational 
attributes arc agt. pat. obj. pos, cat, cau, 
end, sbm, and so forth. 
• the antece(hmt of a zero altal)hor in it with 
some of tit(; abow', vahtes for the relational 
attribute 
4. All marked elements in the intra-docmnent net
work arc generated preserving the order of their 
positions in the original document. 
5. If a size of tit(', summary reaches the. us(:r
specified value, then terminate: otherwise go 
back to Step 2. 
The following artMe of the Wall Street Journal 
was used for testing this algorithm. 
During its cm, temfial year. TI,e Wall Street 
.lourmd will report events of the past etmtury 
that stand as milestones of Amerit:an busi
ness history. Tttl~EE COMPUTEI/S TttAT 
CHANGED tlm face. of personal eomi)uting 
were lmmched in 1977. That year the Apo 
ple II. Conml,)th)re Pet and Tandy TRS t:ame 
to market. The computers were (:rude I)y to
day's standards. Apple II owners, for exam
pie. had to use their television sets ms screens 
and stored data on audioeassettes. But Apl)le 
II was a major advalme from Apple I, which 
was built in a garage I)y Steph(m Wozniak and 
Steven Jobs for hoblwists sut:h as the Home
brew Computer Club. In addition, the, Ap
ple II was an aff(~r(lal)le $1,298. Crude a.s 
the.y we.re, these e.arly PCs triggered explosive 
product development in desktop models for the 
home and otIi(:e. Big mainframe comt)uters for 
1)usiness had 1)e.en around for years. But the 
new 1977 PCs unlike, earlier lmilt-fl'om-kit 
types such as the. Altair, Sol and IMSAI had 
keyboards and could store about two pages of 
data in their memories. Current PCs are more 
than 50 times faster and have nlenlory Cal)ac
ity 50(1 times greater than their 1977 counter
I)arts. There we.re litany pioneer PC contrib
utors. William Gates mM Paul Allen in 1975 
developed an early language-housekeeper sys
t(:m for PCs, and Gates I)e('mne an industry 
billionaire six years after IBM adapted one of 
these versions in 1981. Alan F. Shugart, cur
rently chairmalL of Seagate Technology, led the 
temn that develot)ed the disk drives for PCs. 
Demds Hayes and DMe Heatheringttm, two At
lanta engineers, were co-developers of the in
ternal modems that allow PCs to share data 
via the telephone. IBM, the worhl leader in 
comlmtcrs, didn't offer its first PC until Au
gust 1981 ~s lltally other companies entered tim 
919 
market. Today. PC shipments annually total 
some $38.3 billion world-wide. 
Here is a short, comt)uter-generated summary of 
this samlIle article: 
THREE COMPUTERS THAT 
CHANGED the face of personal COml)uting 
were launched. Crude as they were, these 
early PCs triggered explosive product (le
velopment. Current PCs are more than 50 
times faster and have memory capacity 500 
|lines greater than their countert)arts. 
The proposed method is flexible enough to dy
namically generate smnmaries of various sizes. If a 
longer SUmlnary ix needed, the user call change the 
window size of the summary browser, as described 
in Section 3.1. Then, the summary changes its size 
to fit into the new window. An example of a longer 
summary follows: 
THREE COMPUTERS THAT 
CHANGED the face of t)ersonal comput
ing were launched. The Apple II, Colll
lnodore Pet and Tan(ly TRS came to mar
ket. The comtmters were crude. Apple II 
owners had to use their television sets and 
stored data on audiocasscttes. The Ap
ple II was an ~tffordable $1.298. Crude as 
they were, these early PCs triggered explo
sive I)roduct development. The new PCs 
had keyl)oards and could store about two 
pages of data in their memories. Current 
PCs are more than 50 times faster and have 
memory caI)acity 500 times greater than 
their countert)arts. There were many pi
oneer PC contributors. William Gates and 
Pmfl Allen developed an early language
housekeel)cr system, and Gates t)eeame an 
industry billionaire afl, er IBM adapted one 
of these versions. IBM (li(tn't offer its first 
PC. 
An observation obtained fl'om this experiment is 
that tags for coreferences and thematic and rhetori
cal relations are ahnost enough to make a SUlmnary. 
In particular, coreferences and rhetorical relations 
help summarization very much. 
GDA tags allow us to apply more sophisticated 
natural language processing technologies to come up 
with better summaries. It is straightforward to in
corporate sentence generation technologies to para
phrase parts of tile document, rather than just se
lecting or pruning theln. Annotations on anaphora 
can be exploited to produce context-dependent para
phrases. Also the Sllllllllary could be itelnized to fit 
ill a slide presentation. 
3.1 Summary
Browser 
We developed a summary browser using a Java~ 
capable WWW browser. Figure 2 shows an example 
screen of the summary browser. 
! Durirlg its c~lt~lrial year, l}~e Wall Street Joulr~l ',,,'ill repel t everils of the past c~u.y that 
t stand as milestones oi' American business history. TIIREE COMPUTERS 111AT CHANGED the 
! face of personal computing were launshod in 1977. That year the Apple II, Commodore Pet 
i and Tandy TRS came to market, The computers were crude by today's standards. Apple II 
ov,~le~ s, for example, had to rise tlmir television sets as scrm:~ls and st orc~l data on 
\] audiocasset los. \[<\]klt/~=ple II was a major advat~ce h am Apple I, which was built ill a garage by 
I Stephe~ Woznlak and Steven Jobs for hobbyists such as the Homebrew Computer Club. In 
i addition, the Apple II was an affordable $ | ,298. Crude as they were, these early PCs 
! trigg*~ed explosive product dtwdopn.slt in desktop I.od~s fat tt~ home al~i office. Big 
\] illainfrallle COlllputeqs for bUsil~:;S had been afOllfMJ for y~lls. El|It t|~ ~ 1977 PCs lallike 
I eartier built-from-kit types such as theAItair, Sol and IMSA\] had keyboards and could stole 
i about two pages of data in their memories. Cunent PCs are more than 50 times faster and 
have memory capacity 500 times greater than their 1977 counterparts. There were many 
=lm~sP(:(( ~tr ~tors ~ iamGah~a~ Pa A c~in1975(evdopedanea~y 
lar~juage-iv)osekeeper syst~)l for PCs, al.x! Gate='; |)~:ame an indu~lry bllhonalf e S~× ye.afs 
I after IBM adapted one of these versions in 1981. Alan F. Shogart, currently chairman of 
:: Seagate Terllnology, led the team that devedoped the disk drives for PCs. Dennis Ilayes and 
i Dale Heatheringt on, two Atlanta engir)eers, were co-developers of the internal moderns that 
i allow PCs to share data via the t clepharv,_ IBM, |be world leader in tampa|ors, didn't off=~ its 
I THREE COMP~JTERS THAT CHANGED t he face (If per soulal compulin(j were launcl~td. Crude as \] 
thay were, tl~ese ear ly I~s triggered eaqdosive pfodll(:t dev~opm~lt. Corr~lt l~s are rTIOle 
• than 50 times faster and have memory capacit 3, 500 times greater than their counterparts. 1 
Figure 2: Smmnary Browser 
It has the fl)llowing flmctionalities: 
1. A screen is divi(led into three parts (fl'ames). 
One frame provides a user inlmt form through 
which you Call select doctunents and type key
words. The other frames are for displaying the 
original document and its summary. 
2. The frame for tile sumlnary text is resizable 
by sliding the boundary with tile original doc
ume, nt frame. The size of the summary frame 
influences the size of tile summary itself. Thus 
you can see the summary in a preferred size and 
change the size ill an easy and intuit|w; way. 
3. The frame for the original document is mouse 
sensitive. You can select any element of text ill 
this frame. This flmction is used for the cus
tomization of the summary, as described later. 
4. HTML tags are also handled by the browser. 
So, images are viewed and hyperlinks are man
aged t)oth in tile summary. If a hyperlink 
ix clicked in the original document fl'mne, the 
linked document appears on the same Dame. 
The hyperlinks are kept in the summary. 
4 Personalization

A good sumlnary nfight depend on the background 
knowledge of its creator. It also slmuld change ac
920 
cording to the interests or t)references of its reader. 
Let us refi.,r to the adaptation of the summariza
tion l)roeess to a particular user as personalization. 
GDA-based summarization can be easily personal
ize(l l)ecause our lnethod is flexible enough to bias 
a summary toward the user's concerns. You can se
lect any eh'ments in the original document during 
summarization, to interactively provide infl)rmation 
(:oneerning your personal interests. 
We have t)een developing the following techniques 
for l)ersonalized summarization: 
* Keywor(l-b,'used customization 
Tit('. user can input any words of interest. 
The system relates those words with those in 
the do(:unlellt ltsing eooccurrence statistics ac
quired from a cort)us a~l(l a dictionary such as 
WordNet (Miller, 1995). The related words in 
tile document arc ~ussigned numeric wtlues that 
reflect closeness to the input words. These val
ues are. used in spreading activation for calcu
lating ilnportance scores. ,, Interactive customization 1)y selecting any ele
llleitts from a doculllellt 
Tile user c;m mark any words, phrases, and sen
tenets to t)e inchtde.d in tlle summary. The sun> 
mary browser alh)ws the user to select those el
ements by t)ointing devices such as mouse and 
stylus l)cn. The user can ea.sily select elements 
by clicking on theln. The click count corre
Sl)onds to the level of elements. That is, the 
first click means the word. the second the next 
larger eh'ment contailfing it. and so oil.. The se
lected elements will have higher activation val
ues in spreading activation. 
. Learning user interests by observation of WWW 
t)rowsing 
The sulnmarization system can custonfize the 
slunnlary according to the user without any ex
plicit user ini)uts. We iml)lentented a learning 
mechanism for user I)ersonMization. The mech
anism uses a weighted feature vector. The fea
ture corresponds to the category or topic of doc
uments. The category is defined according to a 
WWW directory such ~L~ YMmo. The topic is 
detected using the summarization technique. 
Learning is roughly divided into data aC(luisi
tion and nmdel n,odification. The user's behav
ioral data is acquired by detecting her informa
tion access on the WWW. This data includes 
the time and duration of that information ac
cess all(l features related to that information. 
The first step of model modification is to esti
mate the degree of relevance betwee.n the input 
fl~ature w~ctor assigned to the infl)rlnation ac
cessed by the user and the model of the user's 
interests acquired fi'mn previous data. The se(> 
ond step is to adjust the weights of features in 
the user model. 
5 Concluding
Remarks 
We have discussed the GDA project, which aims at 
supt)orting versatile and intelligent contents. Our 
focus in the t>resent I>aper is one of its ~Lppli('ations 
to autolnatic text summarization. We are ewduating 
our smnmarization method using online Japanese ar
tMes with GDA tags. We are also extending text 
summarization to that of hypertext. For example, a 
summary of a hypertext document will include re
cursively embeddillg linked documents in summary. 
which should 1)e useful for encyclopedic entries, too. 
Future work includes construction of a large-scale 
GDA corpus and system evaluation by Ol)Cn exl)er
imentation. GDA tools inclu(til,g a tagging editor 
and a browser will soon 1)e pul)licly availabh~' on the 
WWW. Our main current concern is intera(:tive mid 
intelligent t)resentatiolL as ~n extcnsiol, of text smn
marization. This may turn out to be a killer appli
cation of CDA. because it does not just 1)resuppose 
rather small mnount of tagged document but also 
makes the effect of tagging immediately visible to 
the author. We hope that our project revolutionize 
global and intercultural communications. 

References 

Kgiti Hasida. Syun Ishizaki, and Hitoshi Isahara. 
1987. A commctionist approach to the generation 
of al)stracts, in Gerard Kelnpen. editor. Natural 
Language Generation: New Results in Artificial 
Intelligence. Psych, ology, and Linguistics, pages 
149156. Martinus Nijhoff. 

E(lu;~rd ttovy and Chin Yew Lin. 1997. Automated 
text smnmarizati(m in SUMMARIST. In Proceed
ings o.f A CL Workshop on Intelligent Scalable Text 
Summarization. 

George Miller. 1995. WordNet: A lexical database. 
fi)r English. Communications of the ACM. 
38(11):39 41. 

Hideo Watanabe. 1996. A method for al)stract
ing newspat)er articles by using surface clues. In 
Proceedings of the Sixteenth, International Con
ference on Computational Linguistics (COLING
96), pages 974 979. 

