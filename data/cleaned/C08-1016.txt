Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 121â€“128
Manchester, August 2008
 
 
Other-Anaphora Resolution in Biomedical Texts with Automatically 
Mined Patterns 
 
Chen Bin#, Yang Xiaofeng$, Su Jian^ and Tan Chew Lim* 
#*School of Computing, National University of Singapore  
$^Institute for Infocomm Research, A-STAR, Singapore 
{#chenbin, *tancl}@comp.nus.edu.sg 
{$xiaofengy, ^sujian}@i2r.a-star.edu.sg 
ï€  Abstract 
This paper proposes an other-anaphora 
resolution approach in bio-medical texts. 
It utilizes automatically mined patterns to 
discover the semantic relation between an 
anaphor and a candidate antecedent. The 
knowledge from lexical patterns is incor-
porated in a machine learning framework 
to perform anaphora resolution. The ex-
periments show that machine learning 
approach combined with the auto-mined 
knowledge is effective for other-
anaphora resolution in the biomedical 
domain. Our system with auto-mined pat-
terns gives an accuracy of 56.5%., yield-
ing 16.2% improvement against the base-
line system without pattern features, and 
9% improvement against the system us-
ing manually designed patterns.  
1 Introduction

The last decade has seen an explosive growth in 
the amount of textual information in biomedi-
cine. There is a need for an effective and effi-
cient text-mining system to gather and utilize the 
knowledge encoded in the biomedical literature. 
For a correct discourse analysis, a text-mining 
system should have the capability of understand-
ing the reference relations among different ex-
pressions in texts. Hence, anaphor resolution, the 
task of resolving a given text expression to its 
referred expression in prior texts, is important for 
an intelligent text processing system. 
                                                 
Â© 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
In linguistics, an expression that points back 
to a previously mentioned expression is called an 
anaphor, and the expression being referred to by 
the anaphor is called its antecedent. Most pre-
vious work on anaphora resolution aims at identi-
ty-anaphora in which both an anaphor and its 
antecedent are mentions of the same entity. 
In this paper, we focus on a special type of 
anaphora resolution, namely, other-anaphora 
resolution, in which an anaphor to be resolved 
has a prefix modifier â€œotherâ€ or â€œanotherâ€. The 
antecedent of an other-anaphor is a complement 
expression to the anaphor in a super set. In other 
words, an other-anaphor is a set of elements ex-
cluding the element(s) specified by the antece-
dent. If the modifier â€œotherâ€ or â€œanotherâ€ is re-
moved, an anaphor becomes the super set includ-
ing the antecedent. Thus, other-anaphora in fact 
represents a â€œpart-wholeâ€ relation. Consider the 
following text  
 â€œIL-10 inhibits nuclear stimulation of nuclear 
factor kappa B (NF kappa B).  
Several other transcription factors including NF
IL-6, AP-1, AP-2, GR, CREB, Oct-1, and Sp-1 
are not affected by IL-10.â€  
Here, the expression â€œother transcription fac-
torsâ€ is an other-anaphor, while the â€œNF kappa 
Bâ€ is its antecedent. The anaphor refers to any 
transcription factors except the antecedent.  By 
removing the lexical modifier â€œotherâ€, we can 
get a supper set â€œtranscription factorsâ€ that in-
cludes the antecedent. The anaphor and antece-
dent thus have a â€œpart-wholeâ€ relation1.  
Other-anaphora resolution is an important 
sub-task in information extraction for biomedical 
                                                 
1 Other-anaphora could be also held between ex-
pressions that have subset-set or member-collection 
relations. In this paper, we treat them in a uniform 
way by using the patterned-based method. 
121
 
 
domain. It also contributes to biomedical ontolo-
gy building as it targeted at a â€œpart-wholeâ€ rela-
tion which is in the same hierarchical orders as in 
ontology. Furthermore, other-anaphora resolu-
tion is a first-step exploration in the resolution of 
bridging anaphora. Furthermore, other-anaphora 
resolution is a first-step exploration in the resolu-
tion of bridging, a special anaphora phenomenon 
in which the semantic relation between an ana-
phor and its antecedent is more complex (e.g. 
part-whole) than co-reference. 
Previous work on other-anaphora resolution 
relies on knowledge resources, for example, on-
tology like WordNet to determine the â€œpart-
wholeâ€ relation. However, in the biomedical do-
main, a document is full of technical terms which 
are usually missing in a general-purpose ontolo-
gy. To deal with this problem, pattern-based ap-
proaches have been widely employed, in which a 
pattern that represents the â€œpart-wholeâ€ relation 
is designed. Two expressions are connected with 
the specific pattern and form a query. The query 
is searched in a large corpus for the occurrence 
frequency which would indicate how likely the 
two given expressions have the part-whole rela-
tion. The solution can avoid the efforts of con-
structing the ontology knowledge for the "part-
whole" relation. However, the pattern is designed 
in an ad-hoc method, usually from linguistic in-
tuition and its effectiveness for other-anaphora 
resolution is not guaranteed. 
In this paper, we propose a method to auto-
matically mine effective patterns for other-
anaphora resolution in biomedical texts. Our me-
thod runs on a small collection of seed word 
pairs. It searches a large corpus (e.g., PubMed 
abstracts as in our system) for the texts where the 
seed pairs co-occur, and collects the surrounding 
words as the surface patterns. The automatically 
found patterns will be used in a machine learning 
framework for other-anaphora resolution. To our 
knowledge, our work is the first effort of apply-
ing the pattern-base technique to other-anaphora 
resolution in biomedical texts. 
The rest of this paper is organized as follows. 
Section 2 introduces previous related work. Sec-
tion 3 describes the machine learning framework 
for other-anaphora resolution. Section 4 presents 
in detail our method for automatically pattern 
mining. Section 5 gives experiment results and 
has some discussions. Finally, Section 6 con-
cludes the paper and shows some future work. 
2 Related
Work 
Previous work on other-anaphora resolution 
commonly depends on human engineered know-
ledge and/or deep semantic knowledge for the 
â€œpart-wholeâ€ relation, and mostly works only in 
the news domain. 
Markert et al., (2003) presented a pattern-
based algorithm for other-anaphor resolution. 
They used a manually designed pattern â€œANTE-
CEDENT and/or other ANAPHOR â€œ. Given two 
expression to be resolved, a query is formed by 
instantiating the pattern with the two given ex-
pressions. The query is searched in the Web. The 
higher the hit number returned, the more likely 
that the anaphor and the antecedent candidate 
have the â€œpart-wholeâ€ relation. The anaphor is 
resolved to the candidate with the highest hit 
number. Their work was tested on 120 other-
anaphora cases extracted from Wall Street Jour-
nal. The final accuracy was 52.5%. 
Modjeska et al., (2003) also presented a simi-
lar pattern-based method for other-anaphora res-
olution, using the same pattern â€œANTECEDENT 
and/or other ANAPHORâ€. The hit number re-
turned from the Web is used as a feature for a 
NaÃ¯ve Bayesian Classifier to resolve other-
anaphors. Other features include surface words, 
substring matching, distance, gender/number 
agreement, and semantic tag of the NP. They 
evaluated their method with 500 other-anaphor 
cases extracted from Wall Street Journal, and 
reported a result of 60.8% precision and 53.4% 
recall. 
Markert and Nissim (2005) compared three 
systems for other-anaphora resolution, using the 
same data set as in (Modjeska et al., 2003). 
The first system consults WordNet for the 
part-whole relation. The WordNet provides in-
formation on meronym/holonym (part-of rela-
tion) and hypernym/ hyponym (type-of relation). 
Their system achieves a performance of 56.8% 
for precision and 37.0% for recall. 
The second and third systems employ the pat-
tern based approach, employing the same manual 
pattern â€œANTECEDENT and/or other ANA-
PHORâ€. The second system did search in British 
Nation Corpus, giving 62.6% precision and 
26.2% recall. The third system did search in the 
Web as in (Markert et al., 2003), giving 53.8% 
precision and 51.7% recall. 
122
 
 
3 Anaphora
Resolution System 
3.1 Corpus

In our study, we used the GENIA corpus2 for our 
other-anaphora resolution in biomedical texts. 
The corpus consists of 2000 MEDLINE abstracts 
(around 440,000 words). From the GENIA cor-
pus, we extracted 598 other-anaphora cases. The 
598 cases do not contain compound prepositions 
or idiomatic uses of â€œotherâ€, like â€œon the other 
handâ€ and â€œother thanâ€. And all these anaphors 
have their antecedents found in the current and 
previous two sentences of the other-anaphor. On 
average, there are 15.33 candidate antecedents 
for each anaphor to be resolved. 
To conduct other-anaphora resolution, an in-
put document is preprocessed through a pipeline 
of NLP components, including tokenization, sen-
tence boundary detection, part-of-speech (POS) 
tagging, noun phrase (NP) chunking, and named-
entity recognition (NER). These preprocessing 
modules are aimed to determine the boundaries 
of each NP in a text, and to provide necessary 
information of an NP for subsequent processing. 
In our system, we employed the tool-kits built by 
our group for these components. The POS tagger 
was trained and tested on the GENIA corpus 
(version 2.1) and achieved an accuracy of 97.4%. 
The NP-chunking module, evaluated on UPEN 
WSJ TreeBank, produced 94% F-measure. The 
NER module, trained on GENIA corpus (version 
3.0), achieved 71.2% F-measure covering 22 ent-
ity types (e.g., Virus, Protein, Cell, DNA, etc). 
3.2 Learning
Framework 
Our other-anaphora resolution system adopts the 
common learning-based model for identity-
anaphora resolution, as employed by (Soon et al., 
2001) and (Ng and Cardie, 2002). 
In the learning framework, a training or test-
ing instance has the form of ğ‘“ ğ‘£  ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘— ,ğ‘ ğ‘› ğ‘   
where ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘—  is the ğ‘— th candidates of the antece-
dent of anaphor ğ‘ ğ‘› ğ‘ . An instance is labelled as 
positive if ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘—  is the antecedent of ğ‘ ğ‘› ğ‘ , or 
negative if ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘—  is not the antecedent of  ğ‘ ğ‘› ğ‘ . 
An instance is associated with a feature vector 
which records different properties and relations 
between ğ‘ ğ‘› ğ‘  and ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘— . The features used in 
our system will be discussed later in the paper. 
During training, for each other-anaphor, we 
consider as the candidate antecedents the preced-
ing NPs in its current and previous two sentences. 
                                                 
2 http://www-tsujii.is.s.u-tokyo.ac.jp/~genia/topics/Corpus/ 
A positive instance is formed by pairing the ana-
phor and the correct antecedent. And a set of 
negative instances is formed by pairing the ana-
phor and each of the other candidates.  
Based on these generated training instances, 
we can train a binary classifier using any dis-
criminative learning algorithm. In our work, we 
employed support vector machine (SVM) due to 
its good performance in high dimensional feature 
vector spaces. 
During the resolution process, for each other-
anaphor encountered, all of the preceding NPs in 
a three-sentence window are considered. A test 
instance is created for each of the candidate ante-
cedents. The feature vector is presented to the 
trained classifier to determine the other-
anaphoric relation. The candidate with highest 
SVM outcome value is selected as the antecedent.  
3.3 Baseline
Features 
Knowledge is usually represented as features for 
machine learning. In our system, we used the 
following groups of features for other-anaphora 
resolution 
 
ï‚· Word Distance Indicator 
This feature measures the word distance between 
an anaphor and a candidate antecedent, with the 
assumption that the candidate closer to the ana-
phor has a higher preference to be the antecedent. 
ï‚· Same Sentence Indicator 
This feature is either 0 or 1 indicating whether an 
anaphor and a candidate antecedent are in the 
same sentence. Here, the assumption is that the 
candidate in the same sentence as the anaphor is 
preferred for the antecedent. 
ï‚· Semantic Group Indicators 
A named-entity can be classified to a semantic 
category such as â€œDNAâ€, â€œRNAâ€, â€œProteinâ€ and 
so on3. Thus we use a set of features to record the 
category pair of an anaphor and a candidate ante-
cedent. For example, â€œDNA-DNAâ€ is generated 
for the case when both anaphor and candidate are 
DNAs. And â€œDNA-Proteinâ€ is generated if an 
anaphor is a DNA and a candidate is a protein. 
These features indicate whether a semantic group 
can refer to another.  
Note that an anaphor and its antecedent may 
possibly belong to different semantic categories. 
For example, in the GENIA corpus we found that 
                                                 
3 In
our study, we followed the semantic categories defined 
in the annotation scheme of the GENIA corpus.  
123
 
 
in some cases an expression of a protein name 
actually denotes the gene that encodes the pro-
tein. Thus for a given anaphor and a candidate 
under consideration, it is necessary to record the 
pair-wise semantic groups, instead of using a 
single feature indicating whether two expressions 
are of the same group. 
The semantic group for a named entity is giv-
en by our preprocessing NER. For the common 
NPs produced from the NP chunker, we classify 
the semantic group by looking for the words in-
side NPs. For example, an NP ending with 
â€œcellsâ€ is classified to â€œCellâ€ group while an NP 
ending with â€œgeneâ€ or â€œalleleâ€ is classified to 
â€œDNAâ€ group. 
ï‚· Lexical Pattern Indicators 
In some cases, the surrounding words of an ana-
phor and a candidate antecedent strongly indicate 
the â€œpart-wholeâ€ relation. For example, in 
â€œ...asthma and other hypereosinophilic diseas-
esâ€, the reference between â€œother hypereosino-
philic diseasesâ€ and â€œasthmaâ€ is clear if the in-
between words â€œand otherâ€ are taken into con-
sideration. Another example of such a hint pat-
tern is â€œoneâ€¦ the other â€¦â€ The feature is 1 if the 
specific patterns are present for the current ana-
phor and candidate pair. A candidate with such a 
feature is preferred to be the antecedent. 
ï‚· Hierarchical Name Indicator  
This feature indicates whether an antecedent 
candidate is a substring of an anaphor or vice 
versa. This feature is used to capture cases like 
â€œJunâ€ and â€œJunBâ€ (â€œJunâ€ is a family of protein 
while â€œJunBâ€ is a member of this family). In 
many cases, an expression that is a super set 
comes with certain postfix words, for example, 
â€œfamily membersâ€ in  
â€œFludarabine caused a specific depletion of 
STAT1 protein (and mRNA) but not of other 
STAT family members.â€  
This kind of phenomenon is more common in 
bio-medical texts than in news articles. 
3.4 SVM
Training and Classification 
In our system, we utilized the open-source soft-
ware SVM-Light4 for the classifier training and 
testing.  SVM is a robust statistical model which 
has been applied to many NLP tasks. SVM tries 
to learn a separating line to separate the positive 
instances from negative instances. Kernel trans-
formations are applied for non-linear separable 
                                                 
4 http://svmlight.joachims.org/ 
cases (Vapnik, 1995). In our study, we just used 
the default learning parameters provided by 
SVM-Light with the linear kernel. A more so-
phisticated kernel may further improve the per-
formance. 
4 Using
Auto-mined Pattern Features 
The baseline features listed in Section 3.3 only 
rely on shallow lexical, position and semantic 
information about an anaphor and a candidate 
antecedent. It could not, nevertheless, disclose 
the â€œpart-wholeâ€ relation between two given ex-
pressions. In section 2, we have shown some ex-
isting pattern-based solutions that mine the â€œpart-
wholeâ€ relation in a large corpus with some pat-
terns that can represent the relation. However, 
these manually designed patterns are usually se-
lected by heuristics, which may not necessarily 
lead to a high coverage with a good accuracy in 
different domains. To overcome this shortcom-
ing, we would like to use an automatic method to 
mine effective patterns from a large data set. 
First, we create a set of seed pairs of the â€œpart-
wholeâ€ relation. And then, we use the seed pairs 
to discover the patterns that encode the â€œpart-
wholeâ€ relation from a large data set (PubMed as 
in our system). Such a solution is supposed to 
improve the coverage of lexical patterns, while 
still retain the desired â€œpart-wholeâ€ relation for 
other-anaphora resolution. 
The overview of our system with the automat-
ic mined patterns is illustrated in figure 1. 
S e e d  P a i r s  
G e n e r a t i o n
P a t t e r n  M i n i n g
S V M
G E N I A  
C o r p u s
S e e d  
P a i r s
L e x i c a l  
P a t t e r n s
G E N I A
T e s t  
C a s e s
P u b M E D  
C o r p u s
 
Figure 1: System Overview 
There are three major parts in our system, 
namely, seed-pairs generation, pattern mining 
and SVM learning and classification. In the sub-
sequent subsections, we will discuss each of the 
three parts in details. 
124
 
 
4.1 Seed
Pairs Preparation 
A seed pair is a pair of phrases/words following 
â€œpart-wholeâ€ order, for example,  
â€œintegrin alphaâ€ â€œadhesion moleculesâ€ 
where â€œintegrin alphaâ€ is a kind of â€œadhesion 
moleculesâ€.  
We extracted the seed pairs automatically 
from the GENIA corpus. The auto-extracting 
procedure makes uses of some lexical clues like 
â€œA, such as B, C and Dâ€, â€œA (e.g. B and C)â€, â€œA 
including Bâ€ and etc. The capital letter A, B, C 
and D refer to a noun phrase such as â€œintegrin 
alphaâ€ and â€œadhesion moleculesâ€. For each oc-
currence of â€œA such as B, C and Dâ€, the program 
will generate seed pairs â€œB-Aâ€, â€œC-Aâ€ and â€œD-
Aâ€. 
Consider the following example, 
â€œMouse thymoma line EL-4 cells produce cyto-
kines such as interleukin (IL) -2, IL-3, IL-4, IL-
10, and granulocyte-macrophage colony-
stimulating factor in response to phorbol 12-
myristate 13-acetate (PMA).â€ 
We can extract the following seed pairs, 
â€œinterleukin (IL) -2â€ â€“ â€œcytokinesâ€ 
â€œIL -3â€ â€“ â€œcytokinesâ€ 
â€œIL -4â€ â€“ â€œcytokinesâ€ 
â€œIL -10â€ â€“ â€œcytokinesâ€ 
â€œgranulocyte-macrophage colony-stimulating 
factorâ€ â€“ â€œcytokinesâ€  
A similar action is taken for other lexical 
clues. Totally, we got 909 distinct seed pairs ex-
tracted from the GENIA corpus. 
After the seed pairs have been extracted, an 
automatic verification of the seed pairs is per-
formed. The first purpose of the verification is to 
correct chunking errors. For example, â€œHLA 
Class II Geneâ€ may likely be wrongly split into 
â€œHLA Classâ€ and â€œII Geneâ€. This kind of errors 
is repaired by several simple syntactic rules. The 
second purpose of the verification is to remove 
the inappropriate seed pairs. In our system, we 
abandoned the seed pairs containing pronouns 
like â€œthoseâ€, â€œtheyâ€, or nouns like â€œelementâ€, 
â€œmemberâ€ and â€œagentâ€. Such seed pairs may ei-
ther find no patterns, or lead to meaningless pat-
terns because â€œthoseâ€ or â€œelementsâ€ have no spe-
cific semantics and could refer to anything. 
4.2 Pattern
Mining 
Having obtained the set of seed pairs, we will use 
them to mine patterns for the â€œpart-wholeâ€ rela-
tion. For each seed pair â€œantecedent anaphorâ€ 
(anaphor represents the NP for the â€œwholeâ€, 
while antecedent represents the NP for the 
â€œpartâ€), our system will search in a large data set 
for two queries: â€œantecedent * anaphorâ€ and 
â€œanaphor * antecedentâ€ where the â€œ*â€ denotes 
any sequence of words or symbols. For a re-
turned search results, the text in between â€œante-
cedentâ€ and â€œanaphoraâ€ is extracted as a pattern. 
In our study, we used PubMed 2007 data set 
for the pattern mining. The data set contains 
about 52,000 abstracts with around 9,400,000 
words, and is an ideal large-scale resource for 
pattern mining. 
Consider, as an example, a seed pair â€œNK 
kappa B â€œ â€“ â€œtranscription factorâ€. Suppose that 
a returned sentence for the query â€œNK kappa B * 
transcription factorâ€ is  
â€œ...NK kappa B family transcription factors...â€ 
And a returned sentence for the query â€œtranscrip-
tion factor * NK kappa Bâ€ is 
â€œ...transcription factors, including NF kappa 
B...â€ 
We can extract a pattern, 
â€œANTECEDENT family ANAPHORâ€ from the 
first sentence and a pattern 
â€œANAPHOR, including ANTECEDENTâ€ from 
the second sentence.  
We restrict the patterns so that no pattern span 
across two or more sentences. In other words, the 
pattern shall not contain the symbol â€œ.â€. The vi-
olated patterns will be removed. 
The count that a pattern occurs in the PubMed 
for a seed pair is recorded. As a pattern could be 
reduced by different seed pairs, we define the 
occurrence frequency of a pattern as the sum of 
the counts of the pattern for all the seed pairs, 
using following formula: 
ğ¶ ğ‘ ğ‘ ğ‘¡ ğ‘– =  ğ‘‚ ğ‘ ğ‘ (ğ‘ ğ‘ ğ‘¡ ğ‘– ,ğ‘  ğ‘— )
ğ‘  ğ‘– âˆˆ ğ‘†
                           ğ¸ ğ‘ (1)   
where ğ¶ ğ‘ ğ‘ ğ‘¡ ğ‘–  is the frequency of pattern ğ‘ ğ‘ ğ‘¡ ğ‘– ; ğ‘  ğ‘—  is 
a seed pair; ğ‘†  is the set of all seed pairs. 
ğ‘‚ ğ‘ ğ‘ (ğ‘ ğ‘ ğ‘¡ ğ‘– ,ğ‘  ğ‘— ) is the count of the pattern ğ‘ ğ‘ ğ‘¡ ğ‘–  for 
ğ‘  ğ‘— . 
All the mined patterns are sorted according to 
its frequency as defined in ğ¸ ğ‘ (1). 
4.3 Pattern
Application 
For classifier training and testing, the patterns 
with high frequency are used as features. In our 
system, we used the top 40 patterns, while we 
also examined the influence the number of the 
patterns on the performance. (See Section 5.2) 
Given an instance ğ‘“ ğ‘£ (ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘— , ğ‘ ğ‘› ğ‘ ) and a pat-
tern feature ğ‘ ğ‘ ğ‘¡ ğ‘–  , a query is constructed by in-
125
 
 
stantiating with ğ‘ ğ‘ ğ‘› ğ‘‘ ğ‘– ğ‘—  and ğ‘ ğ‘› ğ‘ . For example, 
for an instance ğ‘“ ğ‘£ ("ğ‘ ğ¹  ğ¾ ğ‘ ğ‘ ğ‘ ğ‘  ğµ ", "ğ‘¡ ğ‘Ÿ ğ‘ ğ‘› ğ‘  ğ‘ ğ‘Ÿ  
ğ‘– ğ‘ ğ‘¡ ğ‘– ğ‘œ ğ‘›  ğ‘“ ğ‘ ğ‘ ğ‘¡ ğ‘œ ğ‘Ÿ ğ‘  ") and a pattern feature â€œANA-
PHOR, including ANTECEDENTâ€, we can get 
a query â€œtranscription factors, including NF 
kappa Bâ€. The query is searched in the PubMed 
data set. The count of the query is recorded. The 
value of the pattern feature of a candidate is cal-
culated by normalizing the occurrence frequency 
among all the candidates of the anaphor. 
For demonstration, suppose we have an ana-
phor â€œother transcription factorsâ€ with two ante-
cedent candidates â€œIL-10â€ and â€œNF kappa Bâ€. 
Given a pattern feature â€œANAPHOR, including 
ANTECEDENTâ€, the count of the query â€œtran-
scription factors, including IL-10â€ is 100 while 
that for â€œtranscription factors, including NF-
Kappa Bâ€ is 300. Then the values of the pattern 
feature for â€œIL-10â€ and â€œNF kappa Bâ€ are 0.25 
( 100100+300) and 0.75 ( 300100+300), respectively. 
The value of a pattern feature can be inter-
preted as a degree of belief that an anaphor and a 
candidate antecedent have the â€œpart-wholeâ€ rela-
tion, with regard to the specific pattern. Since the 
value of a pattern feature is normalized among 
all the candidates, it could indicate the preference 
of a candidate against other competing candi-
dates. 
5 Experiment
Results 
5.1 Experiments
Setup 
In our experiments, we conducted a 3-fold cross 
validation to evaluate the performances. The total 
598 other-anaphora cases were divided into 3 
sets of size 200, 199 and 199 respectively. For 
each experiment, two sets were used for training 
while the other set was used for testing.  
For evaluation, we used the accuracy as the 
performance metric, which is defined as the cor-
rectly resolved other-anaphors divided by all the 
testing other-anaphors, that is, 
 
ğ‘ ğ‘ ğ‘ ğ‘¢ ğ‘Ÿ ğ‘ ğ‘ ğ‘¦ = # of correctly resolved anaphors # of total anaphors  
5.2 Experiments
Results 
Table 1 shows the performance of different 
other-anaphora resolution systems. The first line 
is for the baseline system with only the normal 
features as described in Section 3.3. From the 
table, we can find that the baseline system only 
achieves around 40% accuracy. A performance is 
lower than a similar system in news domain by 
Modjeska et al., (2003) where they reported  
51.6 % precision with 40.6% recall. This differ-
ence is probably because they utilized more se-
mantic knowledge such as hypernymy and mero-
nymy acquired from WordNet. Such knowledge, 
nevertheless, is not easily available in the bio-
medical domain. 
 
Sys Fold-1 Fold-2 Fold-3 Overall 
Baseline 
No Pattern 
42.0 % 
84/200 
38.2 % 
76/199 
40.7 % 
81/199 
40.3 % 
241/598 
Manual 
Pattern 
49.0 % 
98/200 
45.7 % 
91/199 
47.7 % 
95/199 
47.5 % 
284/598 
Auto-
mined 
Pattern 
59.0 % 
118/200 
53.8 % 
107/199 
56.8 % 
113/199 
56.5 % 
338/598 
Table 1: Performance Comparisons 
In our experiments, we tested the system with 
manually designed pattern features. We tried 10 
patterns that can represent the â€œpart-wholeâ€ rela-
tion. Table 2 summaries the patterns used in the 
system. Among them, the pattern â€œAnaphor such 
as Antecedentâ€ and â€œAntecedent and other Ana-
phorâ€ are commonly used in previous pattern 
based approaches (Markert et al., 2003; Mod-
jeska et al., 2003). 
 
Pattern 
ANTECEDENT is a kind of ANAPHOR 
ANTECEDENT is a type of ANAPHOR 
ANTECEDENT is a member of ANAPHOR 
ANTECEDENT is a part of ANAPHOR 
ANAPHOR such as ANTECEDENT 
ANTECEDENT and other ANAPHOR 
ANTECEDENT within ANAPHOR 
ANTECEDENT is a component of ANAPHOR 
ANTECEDENT is a sort of ANAPHOR 
ANTECEDENT belongs to ANAPHOR 
Table 2: Manually Selected Patterns 
 
The second line of Table 1 shows the results 
of the system with the manual pattern features. 
We can find that adding these pattern features 
produces an overall accuracy of 47%, yielding an 
increase of 7% accuracy against the baseline sys-
tem without the pattern features.  
The improvement in accuracy is consistent 
with previous work using the pattern-based ap-
proaches in the news domain (Modjeska et al., 
2003). However, we found the performance in 
the biomedical domain is worse than that in the 
news domain. For example, Modjeska et al. 
(2003) reported a precision around 53%. This 
difference of performance suggests that the ma-
126
 
 
nually designed patterns may not necessarily 
work equally well in different domains.  
The last system we examined in the experi-
ment is the one with the automatically mined 
pattern features. Table 3 summarizes the top 
mined patterns ranked based on their occurrence 
frequency. Some of the patterns are intuitively 
good representation of the â€œpart-wholeâ€ relation. 
For example, â€œANAPHOR, including ANTE-
CEDENTâ€. â€œANAPHOR, such as ANTECE-
DENTâ€ and â€œANAPHOR and other ANTECE-
DENTâ€ which are in the manually designed pat-
tern list, are generated.  
The last line of Table 1 lists the result of the 
system with automatically mined pattern fea-
tures. It outperforms the baseline system (up to 
16% accuracy), and the system with manually 
selected patterns (9% accuracy). These results 
prove that our pattern features are effective for 
the other-anaphora resolution.  
 
Pattern Freq 
ANAPHOR, including ANTECEDENT 1213 
ANAPHOR including ANTECEDENT 726 
ANTECEDENT family ANAPHOR 583 
ANAPHOR such as ANTECEDENT 542 
ANTECEDENT transcription ANAPHOR 439 
ANAPHOR, such as ANTECEDENT 295 
ANTECEDENT and other ANAPHOR 270 
ANAPHOR and ANTECEDENT 250 
ANTECEDENT, dendritic ANAPHOR 246 
ANTECEDENT and ANAPHOR 238 
ANTECEDENT human ANAPHOR 223 
ANAPHOR (e.g., ANTECEDENT  213 
ANTECEDENT/rel ANAPHOR 188 
ANTECEDENT-like ANAPHOR 188 
ANAPHOR against ANTECEDENT  163 
Table 3: Auto-Mined Patterns 
To further compare the manually designed 
patterns and the automatically discovered pat-
terns. We examined the coverage rate of the two 
pattern sets. The coverage rate measures the ca-
pability that a set of patterns could lead to posi-
tive anaphor-antecedent pairs. An other-anaphor 
is said to be covered by a pattern set, if the ana-
phor and its antecedent could be hit (i.e., the cor-
responding query has a non-zero hit number) by 
at least one pattern in the list. Thus the coverage 
rate could be defined as 
ğ¶ ğ‘œ ğ‘£ ğ‘’ ğ‘Ÿ ğ‘ ğ‘” ğ‘’ (ğ‘ƒ )  
=   #anaphors covered by the pattern set P# total anaphors  
The coverage rates of the two pattern sets are 
tabulated in table 4. It is apparent that the auto-
mined patterns have a significantly higher cover-
age (more than twice) than the manually de-
signed patterns. 
 
Patterns Coverage Rate 
Manually Designed 36.0 % 
Auto-Mined 92.1 % 
Table 4: Coverage Comparison 
In our experiments we were also concerned 
about the usefulness of each individual pattern. 
For this purpose, we examined the loss of the 
accuracy when withdrawing a pattern feature 
from the feature list. The top 10 patterns with the 
largest accuracy loss are summarized in table 5. 
 
Pattern Acc Loss 
ANAPHOR, including ANTECEDENT 4.18% 
ANAPHOR including ANTECEDENT 3.18% 
ANAPHOR such as ANTECEDENT 2.84% 
ANTECEDENT transcription ANAPHOR 2.17% 
ANTECEDENT and other ANAPHOR 2.01% 
ANAPHOR, such as ANTECEDENT 1.84% 
ANTECEDENT family ANAPHOR 1.84% 
ANAPHOR (e.g., ANTECEDENT 1.51% 
ANTECEDENT-like ANAPHOR 1.17% 
ANTECEDENT/rel ANAPHOR 1.17% 
Table 5: Usefulness of Each Pattern 
The process of automatic pattern mining 
would generate numerous surface patterns. It is 
not reasonable to use all the patterns as features. 
As mentioned in section 4.3, we rank the pattern 
based on their occurrence frequency and select 
the top ones as the features. It would be interest-
ing to see how the number of patterns influences 
the performance of anaphora resolution. In figure 
2, we plot the accuracy under different number 
top pattern features. We can find by using more 
patterns, the coverage keeps increasing. The ac-
curacy also increases, but it reaches the peak 
with around 40 patterns. With more patterns, the 
accuracy remains at the same level. This is be-
cause the low frequency patterns usually are not 
that indicative of the â€œpart-wholeâ€ relation. In-
cluding these pattern features would bring noises 
but not help the performance. The flat curve after 
the peak point suggests that the machine learning 
algorithm can effectively identify the importance 
of the pattern features for the resolution decision, 
and therefore including non-indicative patterns 
would not damage the performance. 
In our experiment, we also interested to com-
pare the utility of PubMed with other general 
data sets. Thus, we tested pattern mining by us-
127
 
 
ing the Google-5-grams corpus5 which lists the 
hit number of all the queries of five words or less 
in the Web. Unfortunately, we found that the per-
formance is worse than using PubMed. The pat-
terns mined from the Web corpus only gives an 
accuracy of around 41%, almost the same as the 
baseline system without using any pattern fea-
tures. The bad performance is due to the fact that 
most of bio-medical names are quite long (2~4 
words) and occur infrequently in the non-
technique data set. Consequently, a query formed 
by a biomedical seed pair usually cannot be 
found in the Web corpus (We found the coverage 
of the auto-mined patterns mined from the corpus 
is only about 20%). 
 
Figure 2: Performance of Various No. of Patterns 
6 Conclusion
& Future Works 
In this paper, we have presented how to automat-
ically mined pattern features for learning-based 
other-anaphora resolution in bio-medical texts. 
The patterns that represent the â€œpart-wholeâ€ rela-
tions are automatically mined from a large data 
set. They are used as features for a SVM-based 
classifier learning and testing. The results of our 
experiments show a reasonably good perfor-
mance with 56.5% accuracy). It outperforms 
(16% in accuracy) the baseline system without 
the pattern features, and also beats (9%) the sys-
tem with manually designed pattern features. 
There are several directions for future work. 
We would like to employ a pattern pruning 
process to remove those less indicative patterns 
such as â€œANAPHOR, ANTECEDENTâ€. And we 
also plan to perform pattern normalization which 
integrates two similar or literally identical pat-
                                                 5
 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?  
   catalogId=LDC2006T13 
terns into a single one. By doing so, the useful 
patterns may come to the top of the pattern list. 
Also we would like to explore ontology re-
sources like MESH and Genes Ontology, which 
can provide enriched hierarchies of bio-medical 
terms and thus would benefit other-anaphora res-
olution. 
Acknowledgements  
This study on co-reference resolution is partially supported 
by a Specific Targeted Research Project (STREP) of the 
European Union's 6th Framework Programme within IST 
call 4, Bootstrapping of Ontologies and Terminologies 
STrategic REsearch Project (BOOTStrep). 
References 
Castano J, Zhang J and Pustejovsky J. Anaphora Resolution 
in Biomedical Literature. Submitted to International Sym-
posium on Reference Resolution 2002, Alicante, Spain 
Clark H. Bridging. In Thinking. Readings in Cognitive 
Science. Johnson-Laird and Wason edition. Cambridge. 
Cambridge University Press; 1977.411â€“420 
Gasperin C and Vieira R. Using Word Similarity Lists for 
Resolving Indirect Anaphora. In Proceedings of ACL 
Workshop on Reference Resolution and Its Application. 
30 June 2004; Barcelona. 2004.40-46 
Girju R, Badulescu A and Moldovan D. Automatic Discov-
ery of Part-Whole Relations. Computational Linguistics, 
2006, 32(2):83-135 
Bernauer J.. Analysis of Part-Whole Relation and Subsump-
tion in Medical Domain. Data Knowledge Enginnering 
1996, 20:405-415 
Markert K. and Nissim M. Comparing Knowledge Sources 
for Nominal Anaphora Resolution. Computational Lin-
guistics, 2005, 31(3):367-402 
Markert K, Modjeska N and Nissim M. Using the Web for 
Nominal Anaphora Resolution. In Proceedings of EACL 
Workshop on the Computational Treatment of Anaphora. 
14 April
2003; Budapest. 2003.39-46 
Mitokov R. Anaphor Resolution. The State of The Art. 
Working Paper, University of Wolverhampton, UK, 1999 
Modjeska N, Markert K and Nissim M. Using the Web in 
Machine Learning for Other-anaphor Resolution. In Pro-
ceedings of the 2003 Conference on Empirical Methods in 
Natural Language Processing. July2003,Sapporo.176-183 
Soon WM, Ng HT and Lim CY. A Machine Learning Ap-
proach to Coreference Resolution of Noun Phrases. Com-
putational Linguistics, 2001, 27(4).521-544 
Vapnik, V. Chapter 5 Methods of Pattern Recognition. In 
The Nature of Statistical Learning Theory. New York. 
Springer-Verlag, 1995.123-167 
Varzi C.  Parts, Wholes, and Part-whole Relation. The Pros-
pects of the Mereotopology. Data & Knowledge Engi-
neering, 1996, 20.259-286 
Vieira R, Bick E, Coelho J, Muller V, Collovini S, Souza J 
and Rino L. Semantic Tagging for Resolution of Indirect 
Anaphora. In Proceedings of 7th SIGdial Workshop on 
Discourse and Dialogue. July 2006; Sydney.76-79 
Burges C. A Tutorial on Supporting Vector Machines for 
Pattern Recognition. Data Mining and Knowledge Dis-
covery 1998, 2:121-167 
Ng V. and Cardie C. Improving machine learning ap-
proaches to coreference resolution. In Proceedings of An-
nual Conference for Association of Computational Lin-
guistics 2002, Philadelphia.104-111 
128

