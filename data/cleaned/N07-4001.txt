NAACL HLT Demonstration Program, pages 1–2, Rochester, New York, USA, April 2007.
c©2007 Association for Computational Linguistics Demonstration of PLOW: A Dialogue System for One-Shot Task Learning James Allen, Nathanael Chambers, George Ferguson *, Lucian Galescu, Hyuckchul Jung, Mary Swift * and William Taysom Florida Institute for Human and Machine Cognition, Pensacola, FL 32502 *Computer Science Department, University of Rochester, Rochester, NY 14627 Introduction We describe a system that can learn new procedure models effectively from one demonstration by the user.
Previous work to learn tasks through observing a demonstration (e.g., Lent & Laird, 2001) has required observing many examples of the same task.
One-shot learning of tasks presents a significant challenge because the observed sequence is inherently incomplete – the user only performs the steps required for the current situation.
Furthermore, their decisionmaking processes, which reflect the control structures in the procedure, are not revealed.
We will demonstrate a system called PLOW (Procedural Learning on the Web) that learns task knowledge through observation accompanied by a natural language “play-by-play”.
Natural language (NL) alleviates many task learning problems by identifying (i) a useful level of abstraction of observed actions; (ii) parameter dependencies; (iii) hierarchical structure; (iv) semantic relationships between the task and the items involved in the actions; and (v) control constructs not otherwise observable.
Various specialized reasoning modules in the system communicate and collaborate with each other to interpret the user’s intentions, build a task model based on the interpretation, and check consistency between the learned task and prior knowledge.
The play-by-play approach in NL enables our task learning system to build a task with highlevel constructs that are not inferable from observed actions alone.
In addition to the knowledge about task structure, NL also provides critical information to transform the observed actions into more robust and reliable executable forms.
Our system learns how to find objects used in the task, unifying the linguistic information of the objects with the semantic representations of the user’s NL descriptions about them.
The objects can then be reliably found in dynamic and complex environments.
See Jung et al (2006) and Chambers et al (2006) for more details on the PLOW system.
The PLOW System PLOW learns tasks executable on the web involving actions such as navigation, information extraction and form filling, and can learn iterative steps that operate over lists of objects on pages.
Figure 1 shows the system during learning a task to find publications for a specified author.
Upper left is the Mozilla browser, in which the user can demonstrate action and the system can execute actions in a mixed-initiative fashion.
The user may speak or type to the system (SR output is lower right), and PLOW combines knowledge from the language and the demonstrated actions to produce a parameterized procedure (described in generated natural language in the upper right corner).
Figure 2 shows a complete training dialogue in which PLOW learns how to find article titles.
To save space, simple acknowledgments by the system are not shown.
Figure 1: PLOW learning a task1 Evaluation The PLOW system was evaluated by independent evaluators who considered four task learning systems developed in the CALO project.
There were 16 human subjects who received training on each of the systems and who worked through a number of successful scripted training sessions with each.
They were then given ten new problems, ranging from slight variations to problems they had seen to problems that were substantially new.
They were free to choose which problems to work on and which system to use and the resulting tasks learned were tested with different settings of the parameters and scored out of a total of 4 points based on a complex predefined evaluation criteria (not known to the developers).
The PLOW system did well in the test, not only receiving the highest average score on tasks learned by a system (figure 3) but also was strongly preferred by the users and selected more than half the time (figure 4).
The Demonstration If we are allowed a presentation we will demonstrate PLOW live on a task selected by the audience.
In addition, we would like to have the system available for an extended period of time during the conference so that attendees can spend time using the system to teach it simple tasks.
The system runs on a laptop and all that is needed for a demo is internet access.
Acknowledgements & References This work was supported by DARPA grant NBCHD-03-0010 under a subcontract from SRI International, ONR grant N000140510314, and NSF grant5-28096.
References Chambers, N.
et al.(2006). Using Semantics to Identify Web Objects.
Proceedings AAAI.
Jung, H., J.
Allen, et al.(2006). One-Shot Proce-dure Learning from Instruction and Observation.
FLAIRS, Melbourne, FL.
Lent, M.
and Laird, J.
(2001) Learning Procedural Knowledge through Observation, Proc.
of the Intl Conf.
on Knowledge Capture.

