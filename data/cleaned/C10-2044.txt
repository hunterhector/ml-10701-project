Coling 2010: Poster Volume, pages 383â€“390,
Beijing, August 2010
Learning Phrase Boundaries
for Hierarchical Phrase-based Translation
Zhongjun HE Yao MENG Hao YU
Fujitsu R&D Center CO., LTD.
{hezhongjun, mengyao, yu}@cn.fujitsu.com
Abstract
Hierarchical phrase-based models pro-
vide a powerful mechanism to capture
non-local phrase reorderings for statis-
tical machine translation (SMT). How-
ever, many phrase reorderings are arbi-
trary because the models are weak on de-
termining phrase boundaries for pattern-
matching. This paper presents a novel
approach to learn phrase boundaries di-
rectly from word-aligned corpus without
using any syntactical information. We use
phrase boundaries, which indicate the be-
ginning/ending of phrase reordering, as
soft constraints for decoding. Experi-
mental results and analysis show that the
approach yields significant improvements
over the baseline on large-scale Chinese-
to-English translation.
1 Introduction
The hierarchial phrase-based (HPB) model (Chi-
ang, 2005) outperformed previous phrase-based
models (Koehn et al., 2003; Och and Ney, 2004)
by utilizing hierarchical phrases consisting of both
words and variables. Thus the HPB model has
generalization ability: a translation rule learned
from a phrase pair can be used for other phrase
pairs with the same pattern, e.g. reordering infor-
mation of a short span can be applied for a large
span during decoding. Therefore, the model cap-
tures both short and long distance phrase reorder-
ings.
However, one shortcoming of the HPB model is
that it is difficult to determine phrase boundaries
for pattern-matching. Therefore, during decod-
ing, a rule may be applied for all possible source
phrases with the same pattern. However, incorrect
pattern-matching will cause wrong translation.
Consider the following rule that is used to trans-
late the Chinese sentence in Figure 1 into English:
X â†’ã€ˆXL de XR,XR in XLã€‰ (1)
The rule translates the Chinese word â€œdeâ€ into
English word â€œinâ€, and swaps the left sub-phrase
covered by XL and the right sub-phrase covered
by XR on the target side. However, XL may
pattern-match 5 spans on the left side of â€œdeâ€ and
XR may pattern-match 3 spans on the right side.
Therefore, the rule produces 15 different deriva-
tions. However, 14 of them are incorrect.
The correct derivation Sc is shown in Figure 2,
while one of the wrong derivations Si is shown in
Figure 3. We observe that the basic difference be-
tween Sc and Si is the phrase boundary matched
by â€œXRâ€. In Sc, XR matches the span [7,9] and
moves it as a whole unit. While in Si, XR matches
the span [7,8] and left the last word [9,9] be trans-
lated separately. Similarly, other incorrect deriva-
tions are caused by inadequate pattern-matching
of XL and/or XR.
Previous research showed that phrases should
be constrained to some extent for improving trans-
lation quality. Most of the existing approaches uti-
lized syntactic information to constrain phrases to
respect syntactic boundaries. Chiang (2005) in-
troduced a constituent feature to reward phrases
that match a syntactic tree but did not yield signif-
icant improvement. Marton and Resnik (2008) re-
vised this method by distinguishing different con-
stituent syntactic types, and defined features for
each type to count whether a phrase matches or
crosses the syntactic boundary. This led to a sub-
stantial improvements. Gimpel and Smith (2008)
presented rich contextual features on the source
side including constituent syntactical features for
phrase-based translation. Cherry (2008) utilized
a dependency tree as a soft constraint to detect
syntactic cohesion violations for a phrase-based
383
ï¿½ 1
ta
| 2
jiang
ï¿½ ï¿½ 3
chengwei
ï¿½  4
yindu
ï¿½ N [ 	ï¿½ 5
youshiyilai
ï¿½ 6
de
n ï¿½ 7
shouwei
o 8
nï¿½
9 d 9
zongtong
She1 will2 become3 the4 first5 female6 president7 in8 Indiaâ€™s9 history10
X[5;5]
X[4;5]
X[3;5]
X[2;5]
X[1;5]
X[7;7]
X[7;8]
X[7;9]
Figure 1: An example of Chinese-English translation. The rule X â†’ã€ˆXL de XR, XR in XLã€‰
pattern-matches 5 and 3 spans on the left and right of the Chinese word â€œdeâ€, respectively.
Sc â‡’ ã€ˆï¿½ | ï¿½ ï¿½ X, She will become Xã€‰
â‡’ ã€ˆï¿½ | ï¿½ ï¿½ X[4,5] ï¿½ X[7,9], She will become X[7,9] in X[4,5]ã€‰
â‡’ ã€ˆï¿½ | ï¿½ ï¿½ bardbl ï¿½  ï¿½ N [ 	ï¿½ bardbl ï¿½ bardbl n ï¿½ o 9 d ,
She will become the first female president in Indiaâ€™s historyã€‰
Figure 2: The correct derivation with adequate pattern-matching of XR.
Si â‡’ ã€ˆï¿½ | ï¿½ ï¿½ X 9 d , She will become X presidentã€‰
â‡’ ã€ˆï¿½ | ï¿½ ï¿½ X[4,5] ï¿½ X[7,8] 9 d , She will become X[7,8] in X[4,5] presidentã€‰
â‡’ ã€ˆï¿½ | ï¿½ ï¿½ bardbl ï¿½  ï¿½ N [ 	ï¿½ bardbl ï¿½ bardbl n ï¿½ o bardbl 9 d ,
She will become the first female in Indiaâ€™s history presidentã€‰
Figure 3: A wrong derivation with inadequate pattern-matching of XR.
system. Xiong et al. (2009) presented a syntax-
driven bracketing model to predict whether two
phrases are translated together or not, using syn-
tactic features learned from training corpus. Al-
though these approaches differ from each other,
the main basic idea is the utilization of syntactic
information.
In this paper, we present a novel approach to
learn phrase boundaries for hierarchical phrase-
based translation. A phrase boundary indicates the
beginning or ending of a phrase reordering. Moti-
vated by Ng and Low (2004) that built a classifier
to predict word boundaries for word segmenta-
tion, we build a classifier to predict phrase bound-
aries. We classify each source word into one of the
4 boundary tags: â€œbâ€ indicates the beginning of a
phrase, â€œmâ€ indicates a word appears in the mid-
dle of a phrase, â€œeâ€ indicates the end of a phrase,
â€œsâ€ indicates a single-word phrase.
We use phrase boundaries as soft constraints for
decoding. To do this, we incorporate our classifier
as a feature into the HPB model and propose an
efficient decoding algorithm.
Compared to the previous work, out approach
has the following advantages:
â€¢ Our approach maintains the strength of the
phrase-based models since it does not re-
quire any syntactical information. There-
fore, phrases do not need to respect syntactic
boundaries.
â€¢ The training instances are directly learned
from a word-aligned bilingual corpus, rather
than from manually annotated corpus.
384
â€¢ The decoder outputs phrase segmentation in-
formation as a byproduct, in addition to
translation result.
We evaluate our approach on large-scale
Chinese-to-English translation. Experimental re-
sults and analysis show that using phrase bound-
aries as soft constraints achieves significant im-
provements over the baseline system.
2 Previous
Work
2.1 Learning
Word Boundaries
In some languages, such as Chinese, words are not
demarcated. Therefore, it is a preliminary task to
determine word boundaries for a sentence, which
is the so-called word segmentation.
Ng and Low (2004) regarded word segmen-
tation as a classification problem. They labelled
each Chinese character with one of 4 possible
boundary tags: â€œbâ€, â€œmâ€, â€œeâ€ respectively indi-
cates the begin, the middle and the end of a word,
and â€œsâ€ indicates a single-character word. Their
segmenter was built within a maximum entropy
framework and trained on manually segmented
sentences.
Learning phrase boundaries is analogous to
word boundaries. The basic difference is that
the unit for learning word boundaries is charac-
ter while the unit for learning phrase boundaries
is word. In this paper, we adopt the boundary
tags presented by Ng and Low (2004) and build a
classifier to predict phrase boundaries within max-
imum entropy framework. We train it directly on a
word-aligned bilingual corpus, without any man-
ually annotation and syntactical information.
2.2 The
Hierarchical Phrase-based Model
We built a hierarchical phrase-based MT system
(Chiang, 2007) based on weighted SCFG. The
translation knowledge is represented by rewriting
rules:
X â†’ã€ˆÎ±,Î³,âˆ¼ã€‰ (2)
where X is a non-terminal, Î± and Î³ are source and
target strings, respectively. Both of them contain
words and possibly co-indexed non-terminals. âˆ¼
describes a one-to-one correspondence between
non-terminals in Î± and Î³.
Chiang (2007) used the standard log-linear
framework (Och and Ney, 2002) to combine var-
ious features:
Pr(e|f) âˆ
summationdisplay
i
Î»ihi(Î±,Î³) (3)
where hi(Î±,Î³) is a feature function and Î»i is
the weight of hi. Analogous to the previous
phrase-based model, Chiang defined the follow-
ing features: translation probabilities p(Î³|Î±) and
p(Î±|Î³), lexical weights pw(Î³|Î±) and pw(Î±|Î³),
word penalty, rule penalty, and a target n-gram
language model.
In this paper, we integrate a phrase boundary
classifier as an additional feature into the log-
linear model to provide soft constraint for pattern-
matching during decoding. The feature weights
are optimized by MERT algorithm (Och, 2003).
3 Learning
Phrase Boundaries
We build a phrase boundary classifier (PBC)
within a maximum entropy framework. The PBC
predicts a boundary tag for each source word, con-
sidering contextual features:
Ptag(t|fj,FJ1 ) =
exp(summationtexti Î»ihi(t,fj,FJ1 ))summationtext
t exp(
summationtext
i Î»ihi(t,fj,FJ1 )
(4)
where, t âˆˆ {b, m, e, s}, fj is the jth word in
source sentence FJ1 , hi is a feature function and
Î»i is the weight of hi.
To build PBC, we first present a method to rec-
ognize phrase boundaries and extract training ex-
amples from word-aligned bilingual corpus, then
we define contextual feature functions.
3.1 Phrase
Boundary
During decoding, intuitively, words within a
phrase should be translated or moved together.
Therefore, a phrase boundary should indicate re-
ordering information. We assign one of the
boundary tags (b,m,e,s) to each word in source
sentences. Thus the word with tag b, e or s is a
phrase boundary. One question is that how to as-
sign boundary tag to a word? In this paper, we
recognize the largest source span which has the
monotone translation. Then we assign boundary
385
	ï¿½ ï¿½ 	 ï¿½ ï¿½
jointly held by
(a)
  ` ï¿½
a short visit
(b)
Figure 4: Illustration for monotone span (a) and
PM span (b).
tags to each word in the source span, according to
their position.
To do this, we first introduce some notations.
Given a bilingual sentence (FJ1 ,EI1) together with
word alignment matrix A, we use L(Aj) and
H(Aj) to represent the lowest and highest tar-
get word position which links to the source word
fj, respectively. Since the word alignment for fj
maybe â€œone-to-manyâ€, all the corresponding tar-
get words will appear in the span [L(Aj),H(Aj)].
we define a source span [j1,j2] (1 â‰¤ j1 â‰¤ j2 â‰¤
J) a monotone span, iff:
1. âˆ€(j,i) âˆˆ A,j1 â‰¤ j â‰¤ j2 â†” L(Aj1) â‰¤ i â‰¤
H(Aj2)
2. âˆ€k1,k2 âˆˆ [j1,j2],k1 â‰¤ k2 â†’ H(Ak1) â‰¤
L(Ak2)
The first condition indicates that
(Fj2j1 ,EH(Aj2)L(Aj
1)
) is a phrase pair as described
previously in phrase-based SMT models. While
the second condition indicates that the lower
target bound linked to a source word cannot be
lower than any target word position linked to the
previous source word. Therefore, a monotone
span does not contain crossed links or internal
reorderings.
Considering that word alignments could be
very noisy and complex in real-world data, we de-
fine pseudo-monotone (PM) span by loosening the
second condition:
âˆ€k1,k2 âˆˆ [j1,j2],k1 â‰¤ k2 â†’ L(Ak1) â‰¤ L(Ak2)
(5)
This condition allows crossed links to some ex-
tent by loosening the bound of Ak1 from upper
to lower. Figure 4 (a) shows an example of
monotone span, in which the translation is mono-
tone. While Figure 4 (b) is not a monotone span
because there is a cross link between the upper
bound of â€œ  â€ and the lower bound of â€œ` ï¿½ â€
on the target side. However, it is a PM span ac-
cording to the definition. Note that in some cases,
a source word may not be contained in any phrase
pair, therefore we consider a single word span as
a PM span, specificly.
An interesting feature of PM span is that if two
PM spans are consecutive on both source side and
their corresponding target side, the two PM spans
can be combined as a larger PM span. Formally,
(Fjj1,Eii1)
circleplusdisplay
(Fj2j+1,Ei2i+1) = (Fj2j1 ,Ei2i1) (6)
where [j1,j] and [j+1,j2] are PM spans, [i1,i]
and [i + 1,i2] are the target spans corresponding
to [j1,j] and [j+1,j2], respectively. For example,
Figure 4 (a) shows a PM phrase pair that consists
of two small PM pairs â€œ	ï¿½ ï¿½ , jointlyâ€ and â€œ	 ï¿½
ï¿½ , held byâ€.
In this paper, we are interested in phrase re-
ordering boundaries for a source sentence. We de-
fine translation span (TS) the largest possible PM
span. A TS may consist of one or more PM spans.
According to our definition, cross links may ap-
pear within PM spans but do not appear between
PM spans within a TS. Therefore, TS is the largest
possible span that will be translated as a unit and
phrase reorderings may occur between TSs during
decoding.
To obtain phrase boundary examples from
word-aligned bilingual sentences, we first find all
possible TSs and then assign boundary tags to
each word. For a TS [j1,j2](j1 < j2) that contain
more than two words, we assign â€œbâ€ to the first
word fj1 and â€œeâ€ to the last word fj2, and â€œmâ€ to
the middle words fj (j1 < j < j2). For a single
word span TS [j,j], we assign â€œsâ€ to the word fj.
Figure 5 shows an example of labelling source
words with boundary tags. The source sentence is
segmented into 4 TSs. Using the phrase boundary
information to guide decoding, the decoder will
produce the correct derivation and translation as
shown in Figure 2.
386
ï¿½ |
ï¿½
ï¿½
ï¿½

ï¿½
N
[
	ï¿½ ï¿½
n
ï¿½ o
9
d
TAG b m e b e s b m e
She
will
become
the first
female
president
in
Indiaâ€™s
history
Figure 5: Illustration for labelling the source
words with boundary tags. The solid boxes
present word alignments. The bordered boxes are
TSs.
3.2 Feature
Definition
The features we used for the PS model are anal-
ogous to (Ng and Low, 2004). For a word W0,
we define the following contextual features with a
window of â€œnâ€:
â€¢ The word feature Wn, which denotes the left
(right) n words of the current word W0;
â€¢ The part-of-speech (POS) feature Pn, which
denotes the POS tag of the word Wn.
For example, the tag of the word â€œï¿½ ï¿½ (be-
come)â€ in Figure 5 is â€œeâ€, indicating that it is
the end of a phrase. If we set the context window
n = 2, the features of the word â€œï¿½ ï¿½ (become)â€
are:
â€¢ Wâˆ’2=ï¿½ Wâˆ’1=| W0=ï¿½ ï¿½ W1=ï¿½ 
W2=ï¿½ N [ 	ï¿½
â€¢ Pâˆ’2=r Pâˆ’1=d P0=v P1=ns P2=l
We collect TSs from bilingual sentences to-
gether with the contextual features and used a
MaxEnt toolkit (Zhang, 2004) to train a PBC.
ï¿½ | ï¿½ ï¿½
b 0.78 0.10 1.2e-5
m 6.4e-8 0.75 5.4e-5
e 2.1e-8 0.11 0.87
s 0.22 0.04 0.13
Table 1: The TPM for a source sentence. The
highest probability of each word is in bold.
4 Phrase
Boundary Constrained
Decoding
Give a source sentence, we can assign boundary
tags to each word by running the PBC. During
decoding, a rule is prohibited to pattern-match
across phrase boundaries. By doing this, the PBC
is integrated as a hard constraint. However, this
method will invalidate a large number of rules and
the decoder suffers from a risk that there are not
enough rules to cover the source sentence.
Alternatively, inspired by previous approaches,
we integrate the phrase boundary classifier as a
soft constraint by incorporating it as a feature into
the HPB model:
hpbc(FJ1 ) = log(
Jproductdisplay
j=1
Ptag(t|fj,FJ1 )) (7)
To perform translation, for each word fj in
a source sentence FJ1 , we first compute all tag
probabilities Ptag(t|fj), where t âˆˆ (b,m,e,s),
j âˆˆ [1,J], according to Equation 4. Therefore, we
build a 4Ã—J tag-word probability matrix (TPM).
TPM[i,j] indicates the probability of the word
fj labelled with the tag ti. Table 1 shows the
TPM for a source text â€œï¿½ | ï¿½ ï¿½ â€.
Then we select rule options from the rule ta-
ble that can be used for translating the source text.
Since each rule option (tildewidef,tildewidee,a) 1 can be regarded
as a bilingual sentence with word alignments, thus
we find all TS in tildewidef and assign an initial tag (IT)
for each source word. This procedure is analogous
to label phrase boundary tags for a word-aligned
bilingual sentence. For example, the following
rules are used for translating the Chinese sentence
in Table 1:
1We keep word alignments of a rule when it is extracted
from bilingual sentence.
387
X â†’ã€ˆï¿½ bXâˆ—1, She X1ã€‰ (8)
X1 â†’ã€ˆ| b ï¿½ ï¿½ e, will becomeã€‰ (9)
Since both the source sides of these two rules
are PM spans according to the word alignments,
the IT sequences for rule (8) and (9) are â€œb *â€2
and â€œb eâ€, respectively. According to Table 1,
the initial hpbc score for these two rules can be
computed as follows:
h(7)pbc = log(Ptag(b|ï¿½ )) = log(TPM[1,1]) (10)
h(8)pbc = log(Ptag(b|| ))+log(Ptag(e|ï¿½ ï¿½ ))
= log(TPM[1,2])+log(TPM[3,3]) (11)
Note that to keep the tag sequence valid, e.g.
â€œmâ€ follows â€œbâ€ rather than â€œsâ€, the ITs maybe
updated during decoding. The tag-updating
should be consistent with the definition of TS as
described in Section 3.1. Specifically, when the
non-terminal symbol X is derived from its cov-
ered span f(X), the boundary tags should be up-
dated.
When a tag of word fj is updated from tk1 to
tk2, the PBC score should also be updated accord-
ing to TPM:
âˆ†PBC = log(TPM[k2,j])âˆ’log(TPM[k1,j])
(12)
The following is a derivation of the source sen-
tence in Table 1:
S â‡’ ã€ˆï¿½ bXâˆ—1, She X1ã€‰
â‡’ ã€ˆï¿½ b| bâ†’m ï¿½ ï¿½ e, She will becomeã€‰
When X1 is derived, the tag of its left boundary
word â€œ| â€ is updated from â€œbâ€ to â€œmâ€. The reason
is that after derivation, the combined span forms
a larger PM span and the left boundary of f(X1)
should be updated.
As a result, the hpbc score is recomputed:
hpbc(F31) = h(7)pbc +h(8)pbc +âˆ†PBC (13)
where,
âˆ†PBC = log(TPM[2,2])âˆ’log(TPM[1,2])
(14)
2We use â€œ*â€ as a tag of the non-terminal symbol â€œX1â€
since it has not been derived.
The decoding algorithm is efficient since the
computing of the PBC score is a procedure of
table-lookup.
5 Experiments
5.1 Experimental
Setup
Our experiments were on Chinese-to-English
translation. The training corpus (77M+81M) we
used are from LDC 3. The evaluation metric is
BLEU (Papineni et al., 2002), as calculated by
mteval-v11b.pl with case-insensitive matching of
n-grams, where n = 4.
To obtain word alignments, we first ran
GIZA++ (Och and Ney, 2002) in both translation
directions and then refined it by â€œgrow-diag-finalâ€
method (Koehn et al., 2003).
For the language model, we used the SRI Lan-
guage Modeling Toolkit (Stolcke, 2002) to train
two 4-gram models on xinhua portion of Giga-
Word corpus and the English side of the training
corpus.
The NIST MT03 test set is used to tune the fea-
ture weights of the log-linear model by MERT
(Och, 2003). We tested our system on the NIST
MT06 and MT08 test sets.
5.2 Results
The results are shown in Table 2. We tested vari-
ous settings of the context window. It is observed
that the small values of n (n = 1,2) drop the
BLEU score, suggesting that perhaps there are not
enough contextual information. With more con-
textual information is used, the BLEU scores are
improved over all test sets. When n = 3, the most
significant improvements are obtained on MT06G
and MT08. The improvements over the baseline
are statistically significant at p < 0.01 by using
the significant test method described in (Koehn,
2004). While for MT06N, the optimized context
window size is n = 4 but the improvement is
not statistically significant. In most cases, with
n larger than 3, we do not obtain further improve-
ments because of the data sparseness for training
3LDC2002E18, LDC2002L27, LDC2002T01,
LDC2003E07, LDC2003E14, LDC2004T07, LDC2005E83,
LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E24,
LDC2006E26, LDC2006E34, LDC2006E86, LDC2006E92,
LDC2006E93, LDC2004T08(HK News, HK Hansards).
388
System MT06G MT06N MT08
baseline 14.66 34.42 26.29
+PBC (n=1) 13.78 33.20 24.58
+PBC (n=2) 14.34 34.21 25.87
+PBC (n=3) 15.19* 34.63 27.25*
+PBC (n=4) 14.76 34.73 26.70
Table 2: Results on the test sets with different con-
text window (n) of the phrase boundary classifier.
The largest BLEU score on each test set is in bold.
MT06G: MT06 GALE set. MT06N: MT06 NIST
set. *: significantly better than the baseline at
p < 0.01.
the classifier.
6 Discussion
The experimental results show that the phrase
boundary constrained method improves the BLEU
score over the baseline system. Furthermore, we
are interested in how the PBC affects the transla-
tion results? We compared the outputs generated
by the baseline and â€œ+PBC (n = 3)â€ system and
found some interesting translations. For example,
the translations of a source sentence of NIST08
are as follows 4:
â€¢ Src: 
ï¿½ b1 ï¿½ ï¿½ m2 ï¿½ m3 ï¿½ S m4 ` ï¿½ e5 bardbl ï¿½  b6
ï¿½ m7 ï¿½ 
q e8 bardbl ^ b9 1 M m10 ï¿½ ï¿½ e11
â€¢ Ref: US1 Treasury-Secretary2 Arrives-in3
China4 for-a-Visit-with5 Environment6 and7
Exchange-Rate8 as9 Focus10,11
â€¢ HPB: US1 Treasury2 in-environmental-
protection6 and7 visit5 China4 is9 key11
to-the-concern-of10 the-exchange-rate8
â€¢ +PBC: US1 Treasury2 arrived-in3 China4
for-a-visit5 environmental-protection6 and7
exchange-rate8 is9 concerned-about10 the-
key11
In the example, both â€œï¿½  â€ and â€œï¿½ 
q â€ in the
source sentence are the concern of the â€œvisitâ€.
Therefore, the source span [6,8] indicates a co-
hesive phrase, which should be translated as a
4The co-indexes of the words on the source and target
sentence indicate word alignments.
whole unit. However, the baseline translates the
spans [6,7] and [8,8] separately. It moves [6,7]
before â€œvisit Chinaâ€ and [8,8] after â€œconcernâ€.
This makes an mistake on phrase reordering. We
observe that the â€œ+PBCâ€ system produces a bet-
ter translation. After incorporating the PBC as
a soft constraint, the system assigns a boundary
tag to each source word and segments the source
sentence into three TSs. According to our defi-
nition, TSs are encouraged as pseudo-monotone
translation unit during decoding. As a result, the
â€œ+PBCâ€ system discourages some arbitrary re-
ordering rules and produces more fluent transla-
tion.
7 Conclusion
and Future Work
This paper presented a phrase boundary con-
strained method for hierarchical phrase-based
translation. A phrase boundary indicates begin
or end of a phrase reordering. We built a phrase
boundary classifier within a maximum entropy
framework and learned phrase boundary exam-
ples directly from word-aligned bilingual corpus.
We proposed an efficient decoding method to in-
tegrate the PBC into the decoder as a soft con-
straint. Experiments and analysis show that the
phrase boundary constrained method achieves sig-
nificant improvements over the baseline system.
The most advantage of the PBC is that it han-
dles both syntactic and non-syntactic phrases. In
the future, We would like to try different meth-
ods to determine more informative phrase bound-
aries, e.g. Xiong et al. (2010) proposed a method
to learn translation boundaries from a hierarchical
tree that decomposed from word alignments using
a shift-reduce algorithm. In addition, we will try
more features as described in (Chiang et al., 2008;
Chiang et al., 2009), e.g. the length of the phrases
that covered by non-terminals.
References
Cherry, Colin. 2008. Cohesive phrase-based decoding
for statistical machine translation. In Proceedings
of the 46rd Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, page 72&ï¿½ 80.
Chiang, David, Yuval Marton, and Philip Resnik.
389
2008. Online large-margin training of syntactic and
structural translation features. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, page 224&ï¿½ 233.
Chiang, David, Wei Wang, and Kevin Knight. 2009.
11,001 new features for statistical machine trans-
lation. In Proceedings of Human Language Tech-
nologies: the 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, page 218&ï¿½ 226.
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263â€“270.
Chiang, David. 2007. Hierarchical phrase-based
translation. Computational Linguistics, pages
33(2):201â€“228.
Gimpel, Kevin and Noah A. Smith. 2008. Rich
source-side context for statistical machine transla-
tion. In In Proceedings of the ACL-2008 Workshop
on Statistical Machine Translation (WMT-2008),
pages 9â€“17.
Koehn, Philipp, Franz J. Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL 2003, pages 127â€“133.
Koehn, Philipp. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 388â€“
395.
Marton, Yuval and Philip Resnik. 2008. Soft syntac-
tic constraints for hierarchical phrased-based trans-
lation. In Proceedings of the 46rd Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies, pages 1003â€“1011.
Ng, Hweetou and Jinkiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2004), pages
277â€“284.
Och, Franz Josef and Hermann Ney. 2002. Dis-
criminative training and maximum entropy models
for statistical machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 295â€“302.
Och, Franz Josef and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. 30:417â€“449.
Och, Franz Josef. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160â€“167.
Papineni, K., S. Roukos, T. Ward, and W.-J. Zhu.
2002. Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics, pages 311â€“318.
Stolcke, Andreas. 2002. SRILM â€“ An extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken language Process-
ing, volume 2, pages 901â€“904.
Xiong, Deyi, Min Zhang, Aiti Aw, and Haizhou Li.
2009. A syntax-driven bracketing model for phrase-
based translation. In ACL-IJCNLP 2009, page
315&ï¿½ 323.
Xiong, Deyi, Min Zhang, and Haizhou Li. 2010.
Learning translation boundaries for phrase-based
decoding. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the ACL, page 136&ï¿½ 144.
Zhang, Le. 2004. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/s0450736/maxent too-
lkit.html.
390

