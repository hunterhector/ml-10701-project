MULTI-INDEX SYNTACTICAL CALCULUS Hans Karlgren Introduction In our work on analyzing Swedish nominal phrases as they appear as document titles particularly titles of articles in periodicals we have primarily utilized context-free rules.
In an endeavour to reduce the cumbersomeness of such rules, we have used the notation: (1) a b ~ c for x = p, q, r and y = u, v xy xy xy as a shorthand for six substantially similar rules.
The gain is not merely that of avoiding scrivener's palsy and puncher's impatience, since the analysis program also accepts this shorthand but also that of clarifying the parallelism between the rules.
The rule schema reads Ha syntagm of type a combines with one of type b to form one of type c, each being respectively of subclass p, q or r and u or v '~.
If the subscripts are interpretable as linguistic categories, this notation seems quite natural.
We might write a fundamental rule of Latin grammar, by way of illustration, thus adJng c n°mng c ~ nOmng c which would mean that to a nominal group may be joined an adjective of the respective number gender, and case without changing the syntactical category of the group.
KVAL, Fack, Stockholm 40.
The work reported in this paper has been sponsored by The Bank of Sweden Tercentenary Fund and The Swedish Humanistic Research Council This notational little device actually often reduces the intuitive need for-context-sensitive rhles, since it performs what these rules are required to do in the domain where we have a choice, namely to bring out the common pattern and leave aside for later consideration the minor adjustments.
Now, in practice, we have for each word or syntagm not one subscript but a set of alternative subscripts.
On the initiative of Gunnar Ehrling, who wrote the analyzer, we further reduce the notation by giving a name to all such sets of alternatives and by specifying in a "multiplication table'the name of the set of alternatives forming the intersection between any pair of such sets.
Thus, in place of (1) our rules actually read --4/c. (Z) aik bjl iAj, knl where the values of iflj and kN1 are taken from the "multiplication table''.
We now ask what will happen if we generalize this index "multiplication" so that it will represent not intersection of index sets but an arbitrary binary operation on the set of index symbols.
Particularly, we are interested in the case where this multiplication is non-associative and the set of index symbols is not closed under multiplication.
This would mean that the restrictions imposed by the indexes on the sentence or part thereof could, in their turn, be written as a context-free not a finite-state grammar over the index symbols.
When the subscript multiplication rules are generalized so far, they are of the same kind as the " " ' on multlphcation" the main level, and we prefer to write a filk for aik and we define IKVAL, Interim Report No 13, Program fSr grammatisk analys av texter 2 multiplication of such index vectors as "inner" multiplication, that is, the corresponding elements are multiplied: alilk bljfl ablijTkl We note that, in general, these rules cannot be reduced to a finite list of common context-free rules, as could rules like (i) and (Z).
For if we can replace ab by c, we may well be unable to replace ij by anything shorter than ij, the multiplication table being blank for ij or even having no row i or column j, since i and j may, in turn, be strings and not elements in the index set.
And if the well-formed sequences of indexes are defined by a general context-free grammar and not by a finite-state one, we cannot remedy this by adding more symbols to the index set: the set of triples i, j, ij may then be infinite.
This paper is an attempt to investigate this problem, elaborating such a multi-index calculus a little.
First, however, we may be excused for making a summary of the background of the recognition grarnrnar problems for which such a calculus may be useful.
The reader who expects tD be bored by such a survey should turn directly to page 10 below.
Reduction We introduce some definitions.
The terms employed largely coincide with those of current generative linguistics, but some minor adaptions have been made to make the terms adequate for describing the kind of recognition grammars with which we are concerned.
~ 3 We consider ~ over an a_~phabet S = \[ a, b, c, . .\].
We write ab for the string formed by concatenation of two letters a and b, and o~\[3 for the concat@nation of two strings c~ and \[3.
Concatenation is considered a reflexive, associative but not commutative relation.
We write M for the set of all concatenations of strings in a set M: A rewriting rule......_, ex -~ \[3 is a rule which permits us to replace the string ~ in any string where it may occur by the string \[3.
A reduction rule is a rewriting rule which does not increase the number of words in the string.
A reduction s\]~stem is a set of reduction rules: R = ~ ~ B \[~c alaZ...a n, \[3~blbz...b n, ai~S, bj~S,m_<n\] By means of R we can define a deri'vability relation over S ~.
We say that c~ is reducible to 6, ~ -~ \[3, according to K, if there is a succession of applications of rules in K by which c~ can be rewritten as \[3.
We include the case where no rule is applied so ce ~ ~ for all~ . Thus, "~" is a ~eflexive and transitive relation.
We now define a reduction grammar G =,~ S, K, I, T > as a specification of a set of strings, a ~ over an input alphabet Ic S : L =L(<S, R, I, T>)={oI.EI~, o~.~ ~_ TcS" \] where T is a set of terminal or, to avoid diametrically opposite associations target symbols, We say ~ is an R-reduction of or.
Finite Rewriting Systems Constituent structure ~ramrnars an__~d ~rammar components We first consider grammars where S is a finite set.
We call these grammars constituent structure grammars.
If T contains one single element, say s for sentence, the grammar is a decision grammar, which specifies for each input string whether or not it is grammatical.
Trivially, T can be extended to include a few elements, say s for statement, q ~or question, and so on.
Naturally, we can reformulate a grammar with T = ~t 1 ..... tn\], where n is finite, into a grammar with a unique target element, merely by adding one element, say s, to S and incorporating a few rules {t i -* sli = II ..... n}to 1K.
However, allowing T to be an infinite set is not necessarily a trivial extension.
Trivial but occasionally practical is to define a language L (S, K, I, A~ where the targets are all the strings over an output alphabet A c S.
If T is some non-trivially defined subset set, L' of strings over a subset A of S, we have L = L(S, R, I, L' ) where L' must be defined by some grammar G I = <S~I~k,T> We say that G" = <S, R, I, A> is a ~rammar component and note that G" and G I together completely specify L.
We shall come back to this concept later when we describe more complex grammars as combinations of simple ones.
With the restriction imposed on the rules of R that the right hand side should never be longer than the left hand side, it is obviously always possible in a finite number of steps to decide whether or not a given finite string is reducible to some element in T, i.e., whether or not it is an element in the set L.
For if the given string o contains m symbols and $ contains n different symbols, a can be shortened at most (m1) times and after the i'-th time it has been shortened, (i = O, 1, .... m 1), it can be rewritten without shortening at most (n mi_ l) times without being rewritten as a, which can always be avoided by keeping a finite record of historical information.
Disjoint constituent ~rammars 1.
A reduction rule where the right hand side contains exactly one symbol is called a context-free rule.
If all the rules are context-free we say the grammar and the language is context-free.
If the grammar is context-free we may give it the following interpretation.
Let the letters of I be sets, "categories", of strings of linguistic signs.
Let a._.bb mean the set of strings consisting of one string contained in category a foltowed by one contained in b . Let the reduction rules mean inclusion so that, e.g., ab c c means that the set a~b is included in the set c.
A string o over I then represents a grammatical sentence of type t, if and only if, R m (yc t sT.
2. A context-free constituent grammar, then, can be adequately described as a classificational system with finer and broader terms where all classes can be written as cdncatenations interpreted as the set of concatenations of the cartesian products of a finite set S of categories.
The process of analyzing sentences of such a language can be performed as a classificational procedure and the result is adequately and exhaustively statable as the class adherence of sets of successive substrings, representable, e.g., by a tree with no crossing branches.
One may note that the character of a context-free language well conforms with what used to be defined as agglutinative languages, that is with the agglutinative languages as they were commonly defined, not as any existing natural language of any particular group.
The assumptions behind an attempt to describe a real language by a context-free grammar, therefore, are very strong.
It is not astonishing that these attempts partially fail; it is astonishing that they have carried as far as they have.
For instance, there is no convincing empirical evidence that a decision grammar for a natural language cannot be written as a context-free grammar, though there are ample theoretical reasons not to stake too much on the prediction that no practical counter-examples will turn up in the future.
3. If we add to our context-free grammar rules of the type ab .-* bc or, generally, permutation rules where the same elements recur on the right, though in different order, we broadens of course, the family of languages under considerations and the interpretation above under 2.
no more holds true.
But all what was said about the highly specialized character of the languages remains true, except that class adherence is now not confined to sets of successive substrings; the language is characterized by the existence of discontinuous constituents~ and except that the tree drawn will have crossing branches here and there.
But it is still possible to assign each substring to exactly one immediately higher order constituent and it is still possible to draw a tree.
We may summarize the constituent so far mentioned under the name ~-constituent grammars, i.e., grammars where each constituent is either disjoint from or included in another and where, accordingly, the constituents can be defined as a hierarchial set of equivalence classes over the substrings of the given input string.
Such a classification of substrings is called a p-marker.
The hope of expressing the essence of the syntactical structure of a sentence by one p-marker therefore implies strong assumptions about the language.
Overlapping constituent grammar If the rules of R do not obey the restrictions mentioned for disjoint-constituent structure grammars, that is, if rules occur of the type abc ~ de or abc -'* dc no equivalence classification of substrin~ is obvious and no tree can be drawn without further assumptions.
The most natural would be to draw a graph of the following kind: Unlike p-markers, this graph attributes one and the same substring of the input string to more than one higher constituent also when these higher constituents are disjoint.
Here abc belongs to d and to e, to k and to i.
It is by no means an unnatural description of a sentence to let one segment have more than one function, nor is it impractical to represent such structures as graphs.
On the contrary, that is what graphs are for, and in the special case where no two branches ever coalesce, the graph seems to be so utterly simple that it is, at any rate, rather a waste of paper to print drawings of it.
For a subset of the grammars now under discussion we can, with some good will, construct p-markers, although the same rules contain more than a single right handed element.
If the rules are of the type abc -~ dc or, generally, only one symbol on the right is different from the corresponding symbol to the left, we may, by convention; consider ab to be a constituent of type d, whereas c only functions as a context.
For these context-sensltive cases we therefore can agree to represent our reduction as follows: a /b c instead of a~c I d c d c It might seem as natural to draw a b c d c saying that d is a representation of C as well as of a b, since d could not have been rendered as ab unless c had been present.
m 45 Chomsky (1963) p.
294, Handbook of Mathematical Psychology, edited by Luce, Bush, and Galanter.
One would then have overlapping constituents in cases such as Swedish gott, reducible to godt: g o t t adj flexional element Nobody seems to be over-happy with this attempt to "add conditions to guarantee that a p-marker for a terminal string can be recovered uniquely from its derivation" and for this and more serious reasons linguists turn away from these types of constituent grammars altogether.
But it is characteristic that one attempts to find "unique" equivalence classifications, i.e., tree graphs of the simple kind described.
"We assume that such a tree graph must be a part of the structural description of any sentence; we refer to it as a phrasemarker p-marker.
A grammar must for adequacy provide a p-marker for each sentence".
~ In other words, rather than modify the kind of graph employed, one replaces it, in transformational grammar, by an ordered set of such simple graphs.
The multi-index notation permits an alternative mode of presentation, as will appear in the next few paragraphs.
Infinite Rewriting Systems We now consider the case where a grammar G = < S, i~, I, T> contains an infinite alphabet S.
In particular, We consider the set S of vectors over a finite set S t of indexes: S = S' U \[si'szf...
\[SnlSi6Sl \] Chomsky, op.
cit. p.
~. I0 For S we introduce the general multi-index multiplication schema: i I I I (l) (Sl SzI "'" Sn) (tl t2 "''ltm)-* ...
J. ' t if n < m (Slt|)º (szt2) I ! (Sntn)! tn÷ 1 .... m (s Itl), (szt2), ...I (Sntn) if n = m ...
i i ifn>m Is|t|) I (Sztz) I I(smtm)' Sm+ | ''' "S n that is, for i > n and j > m we consider s.
= t.
: e, where e I j is a unit element such that ae = ea = e for all a.
I~ l contains, except the general multi-index schema (|), a finite set i~ I of rules or rule schemata over $ {Z) R' = \[or "* S let a lag..a n, B = b lbz.., b m, n ~ m where a.
and b.
are elements in S or variables over $ or over x j specified subsets thereof.
T is given either explicitly or as an infinite subset of S T = \[t'xlt E AcS, xE S} i.e., as those elements in S which consist of an element in a finite set A, arbitrarily subscripted.
We note that every element s in S defines an infinite class of elements beginning with the vector s, just as a decimal number defines a class of number with the same or a greater number of digits.
The rules of R are such as i ab-~ c Z alx bly --~ clz 3 a'.x -.* b 4 a -* b'x + and so on.
To make a language decidable it is obviously sufficient by way of analogy with the reasoning above to require that the right-hand side should never contain more letJ ters out of the alphabet S I than the left-hand side, thus excluding rules like rule 4 above.
The fact that the letters are here distributed over different levels, so constituting one or more symbols of S, cannot invalidate that argument.
The conclusion obviously also remains intact if we accept rules with a longer right-hand side for rewriting symbols which never occur on the right-hand side of any rule, that is, if we make allowance for assignment rules.
In the following we shall restrict ourselves to contextfree multi-index rules, that is, the rules shall a) contain one element of~S on the right-hand side and wherever practical the rules shall also b) contain at most as many elements of S i on the right-hand side as on the left-hand side, except where the left-hand side consists exclusively of elements which occur on the right-hand side of no rule.
Though each rule is a context-free rule, such a multiindex grammar is not a disjoint-constituent grammar; constituents do overlap: Let us consider a grammar where ab -*d dc ~ s xy ~ u UZ ~ V and where slvET.
Let us consider the analysis of the string a~x bty clz: t2 The second restriction is unnecessarily severe.
One may well include, e.g., r ules which are not reductive with reference to S" but which are strictly reductive on the highest level they refer to and which do not increase the number of levels referred to by any rule.
or graphically: alx b~y cl.z dlxy clz slxyz slxu sly We see that segmentation is overlapping but that each level of: indexes represents one equivalence classification and one tree-shape graph.
In many cases, context-free multi-index rules are weakly equivalent to context-sensitive rules, as Will appear from the following few examples of languages which notoriously cannot be described with ordinary context-free rules.
Crudely, we may say that taking an index on another level into account is an implicit way of regarding context.
t3 Example 1.
The language "anbncn".
~I: a ~ xlp b ~ ylp C ~ zIq "xy ~ s xsy ~ s SZ ~ S ppq ~ e where e is the unity element.
Illustration: aabbcc x'p x'p y'p y'p z'q z'q xtp slpp ylp z'q zfq sipppp ziq zlq s°pp ziq sle = S T = s 14 Example 2.
The "reduplication" language, consisting of an arbitrary string of a'.
s and b'.
s followed by the same string ' repeated.
R : xy ~ x ry for x = a,b and y = a,b xx ~ s for x = a,b sis ~ s lllustration: abbababbab,a'(b'(b'(al-b))) al-ibl(b\[(a\[b))) s' (s' (s'(s' s))) s Example 3.
The language (anbn) m Rr : x xly ~ xl(xty) for x = a,b and for all yES ab-*t tlx tfx ~ ttx for all xES t-* s SIS "* S T = {s\] Illu s tration: aaabbbaaabbb a'(a'b) b'(b'b) al(a'a t' (t't') t' (t't) t' (t't) s ' (s's) $ b' (b'b) 15 Example 4.
The language ambncmn R' : x x'y x'(bly) for x = b,c and all yES a blx clx -blx for all xE S b ~s SIs -~ S T : {s\] Illustration: aaabbbbcccccccccccc aaab'(bi(bib))c' (b' (b'b))ci(b'(b'b))c' (b' (b'b)) aab' (b' (bib))ci(b'.(bib))ci(b' (b'b)) b'(b I (bib)) s' (~' (s' s)) S Thus, the possibility to add further index levels at option provides a rneansof performing arithmetical operations.
The context-free multi-index rules are powerful and cover many languages of what is known as the context-sensitive type.
We shall now turn to linguistic interpretations of such a calcuius.
16 Multi-index Calculus in Linguistics The multi-index calculus can be applied in linguistics above all for two purposes: to replace context-sensitive rules and to provide a means of representing p-markers.
Context-free multi-index rules derived from context-sensitive rules It is possible to replace many all? context-sensitive rules by an equivalent set of context-free multi-index rules.
Thus, the rule a ~ b/~ c can be replaced by a ~ blp, c c I q and pq ~ e or, more cautiously by the assignment rules a Alp c CI q and the reduction rules A I p ~ A ~ r Air ~ Bit rq e p ~ e q ~ e where e is the unity element.
Let us consider the following little grammar: j-i/g-hg" gh i "~ d/hgh-*c f-~ a/-c cd-~b ab'~ s i7 thu s With this grammar, the sentence ~hgj will be analyzed I '"d/ c /J\/ We have here adopted a "mixed" tree representation for context-sensitive structures, with obvious significance.
We can reduce the same sentence to s by the following set of rules: j ~ilk g ~gll lk-.
e h ~ gJ.rn g -*glt g -~hln rot-.
rn rgln ~ e i ~ dlp h ~ hlq qp-e gh~c f ~ a'-r C ~ tit rt -e cd-~ b ab~ S 18 I" Thus, f h g j f h gfl ilk f h gi' (lk) f glm hJn i f gh t (mn) i f g hfq dtp f g hd'(qp) f c d air clt d ac' (rt) d a b s Graphically, this means that we have a set of interconnected treegraphs: i!1 t9 In a transformational grammar, we interpret G" as a grammar component, adding to our grammar a component G' -< S l, R I, I i, T'> where 1 Iis the set T" of p-markers, T i is a subset thereof and R ! is a set of multi-index rewriting rules such as alx ~ a'y atx bly ~ clx a~x alx bly ~ a!x bly alx bty atx.
bly ~ bly.
alx for specified sets of values for x, y, etc., that is, substitution, reduction, expansion and permutation rules for which the conditions are not confined to one index level at a time.
Regarding the analysis as a syntactic tree, we may characterize transformational rules as such where the conditions for some symbol(s) to be rewritten in a specified way refer to the "vertical" neighbours (not to the "horizontal" neighbours as in context-sensitive rules).
We might speak about pretext and posttext sensitive rules, or generally about "kintext sensitive" rules: Obviously and notoriously, "kintext" must play a different role in generative and in recognition procedures, since pretext in one case is posttext in another.
Thus, one component may map the input strings on T" = \[ ti lxl ti 6 T; x 6 S"\] and ~a transforma-tion component may map I I.
= T" on T' = \[tlylt 6A\] and y ={a!l azla31 ...la i 6B } where B is a subset of S" and A___C T.
Or we may define the target set for each component in other ways.
Z0 Multi-index calculus in a transformational grammar Given a constituent structure grammar G = < S, R, I, T> we obtain an infinite grammar G" by replacing S by S" = SU { s I Is2 ts3, ...\[ siES"\] and R by g" = \[a,az... a n ~ b'(a,aZ.., an)l(a,az.-a n ~ b) eR\] if K is context-free and otherwise R"= \[alaz...a n ~ b,' (aiaz...an)'b z' (aiaz...a n ) ....
" bm' (alaz..: an) \[ (ala2... a n ~ blbz.., bm)ER} and replacing T = { t 1, t z ..... tk} by T" = {ti'x\[tiETxES"\].
That is, we obtain a grammar* which maps given strings on an infinite set which may be considered as a set of p-markers ~.
G" is then an interpretation grammar, corresponding to G.
j \ a decidable one, see p.
i3 above, footnote.
The number of levels does increase, but all rules refer exclusively to the uppermost level.
@* These multi-index expressions naturally contain all information that transformations operate upon.
Indeed, they will often contain too much, but superfluous indexes can easily be eliminated by multi-index rules; the point is that no side conditions for permissible transformational rewritings need be observed.
Everything needed for the calculus is in the string.
Zl Thus, one-level reduction rules suffice for a decision grammar for a constituent-structure language and multi-index reduction rules suffice for an interpretation grammar for such languages.
Multi-index rules also suffice for a decision grammar for a transformationally defined language.
~ The question remains if they suffice for an interpretation grammar for the latter.
A structural description of the sentence may be given as the sequence of p-markers obtained during the analysis.
Now, since the relative order of operations is not inherently fixed, we would like to find a representation of such sequences such that equivalence can easily,be defined.
That is, we want to find an adequate interpretative grammar corresponding to G I . Can multi-index rules serve those purposes ? The unified formalization, provided by the multi-index representation, might prove an aid to finding an effective interpretative calculus for transformationally defined languages.
Conclusion The multi-index calculus seems promising for several.
linguistic purposes, especially where restrictions can be assigned to several, weakly interacting levels.
if this is decidable.
They may also, incidentally, provide simple decidability criteria for a transformational grammar.
Cf. tile hints above (p.
13). 2Z r °~

