Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 46â€“53, Sydney, July 2006.
cÂ©2006 Association for Computational Linguistics DRT Representation of Degrees of Belief Yafa Al-Raheb National Centre for Language Technology Dublin City University Ireland yafa.alraheb@gmail.com Abstract This paper investigates the problems facing modelling agentsâ€™ beliefs in Discourse Representation Theory (DRT) and presents a viable solution in the form of a dialogue-based DRT representation of beliefs.
Integrating modelling dialogue interaction into DRT allows modelling agentsâ€™ beliefs, intentions and mutual beliefs.
Furthermore, it is one of the aims of the paper to account for the important notion of agentsâ€™ varying degrees of belief in different contexts.1 1 Introduction Heydrich et al.remark that â€˜serious description of natural dialogue seems to necessitate that we consider the mental states of the speakers involvedâ€™ (1998).2 This is a step that is by no means easy.
It is the aim of this paper to integrate previous work on beliefs in DRT and dialogue theory in order to model the mental states of agents in dialogue.
The connection between beliefs, intentions and speech or dialogue acts has been noted in the literature.
Stalnaker notes, for instance, that [i]f we understand contexts, and the speech acts made in contexts, in terms of the speakerâ€™s beliefs and intentions, we have a better chance of giving simpler and more transparent explanations of linguistic behaviour (Stalnaker 2002: 720).
The kind of agent beliefs we are concerned with here arises in dialogue interaction.
The nature of 1I gratefully acknowledge support from Science Foundation Ireland grant 04/IN/I527.
2Other names for mental state used in the literature include â€˜information stateâ€™, â€˜conversational scoreâ€™, and â€˜discourse contextâ€™ (Larsson and Traum 2000).
interaction dictates that the strength or degree of belief varies depending on contextual factors.
This can be seen from the following example: (1) A: I want to make a booking for my wife.
B: Yeah.
A: What time is the Thailand flight on Monday?
B: Itâ€™s at 2 pm.
In example (1) B does not necessarily need to believe the presupposition (given information) that A has a wife.
For the purposes of the conversation, which is providing A with information, B can simply â€˜go along withâ€™ the presupposition and not have it as a member of his beliefs (i.e.
his belief set) (Stalnaker 2002).
Similarly, let us consider the following example, (2).
The speaker is a customer in a clothing shop.
(2) S1: I want to buy a dress for my wife.
H1: Is it for a formal occasion?
S2: Yes.
H2: What is her favourite colour?
S3: She doesnâ€™t like red anymore.
H3: Does your wife like black?
S4: Yes As the speaker, S, introduces the presupposition that he has a wife, the hearer, H, can come to the conclusion that S believes S has a wife.
However, when the hearer comes to refer to Sâ€™s wife, H does not necessarily have to believe S has a wife.
H can simply go along with the information that the speaker has a wife and use this form of acceptance in H2 without committing to â€˜strongly believingâ€™ it.
Indeed, the speaker may be buying a dress for his mistress rather than his wife.
By going along 46 with it, the hearer does not have to commit himself to believing that the speaker has a wife.
What is more at stake than believing that the speaker indeed has a wife and not a mistress is closing the sale.
Contrast examples (1) and (2) with example (3): (3) S1: You have to get Peterâ€™s son a Christening present.
H1: Peter has a son?
S2: Sorry I forgot to mention that before.
H2: Ok, what sort of present should I get him?
S3: A toy would be nice.
In this context, the hearer, H, is required to commit more strongly to the presupposition of Peter having a son than simply going along with it, since H is being asked to buy a Christening present.
The fact that H2 agrees to buying a present for Peterâ€™s son reflects more commitment to the presupposition than B shows in example (1).
Considerations of this kind lead to the conclusion that different contexts call for varying strengths of beliefs and belief representation.
We shall not attempt to describe all the contextual factors that can cause strength of belief to vary.
The point is, rather, that we clearly need to model strength of belief and no current model of DRT incorporates such a proposal.
This paper, thus, makes an original proposal for including a system for graded beliefs in the belief spaces (or sets) of both the speaker and the hearer.
Bearing this in mind, there is a need in DRT for representing the differing beliefs of agents in dialogue and their beliefs (meta-beliefs) about other agentsâ€™ beliefs or mental state.
By focussing on the intentions of speakers and hearers and inferring agentsâ€™ intentions in making an utterance, the approach presented in this paper aims at fulfilling this need.
It follows that, to have a â€˜fullâ€™ theory of beliefs and to have an insight into the mental states of agents in dialogue (the speaker and the hearer), it is necessary to have a representation of agentsâ€™ beliefs, degrees of beliefs, and the dialogue acts expressed by their utterances (Asher 1986).
This is also in order to strengthen the link between utterances and agentsâ€™ intentions in dialogue.
The dialogue act or function performed by the utterance tells us something about the speakerâ€™s beliefs.
Furthermore, what is also needed is a representation of beliefs that are shared between, or are common to, the two agents.
The question is: how can DRT best model beliefs?
The following section, 2, outlines the problems facing modelling beliefs in DRT.
Section 3 presents a graded view of agentsâ€™ beliefs in dialogue as a solution to these problems.
This is followed by a description of the relationship between belief and mutual belief, section 4, and then of the relationship between belief and dialogue acts, section 5.
2 Problems
Facing Modelling Beliefs in DRT According to Heydrich et al.(1998), paradigms of dynamic semantics (DRT, Situation Semantics and Dynamic Predicate Logic) face three obstacles in modelling dialogue.
First, there is the problem of adapting the paradigm, originally made to model monological discourse, to the description of dialogue with different agents.
The second problem is the description of mental states and the beliefs of the agents.
The third problem is in explaining how the mental states are related to overt linguistic behaviour.
With respect to the first problem, DRT has gradually attempted to address problems of belief representation in dialogue.
For example, in Prolegomena, Kamp introduces a simple model of verbal communication (Kamp 1990: 71), which consists of two agents, A and B, and their mental states K(A) and K(B).
Later work by Kamp et al.(2005) introduces agent modelling for singlesentence discourse, namely the hearer.
The treatment presented in this paper allows the representation of dialogue with different agents, thus, addressing the first problem identified by Heydrich et al.(1998). With regard to the second problem, however, DRT has been primarily concerned with representing utterances containing propositional attitudes such as â€˜believeâ€™, rather than the beliefs and meta-beliefs of agents.
Segmented-DRT (SDRT) has mainly focused on belief update and revision (Asher and Lascarides 2003).
The treatment in this paper takes previous work on beliefs in dynamic semantics as a starting point and extends it to reach a richer representation of the interaction between mental states and the linguistic content of utterances.
For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance.
As a semantic theory, DRT tells us which discourse referents are needed in context.
However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to agentsâ€™ intentions.
Kamp et al.â€™s (2005) expansion of the original, also known as â€˜vanillaâ€™, DRT (Poesio and Traum 1997a), deal minimally with intentions.
To deal with the third problem mentioned by Heydrich et al., Al-Raheb (2005) has already outlined a pragmatic extension to DRT that makes it appropriate for linking the current utterance and agentsâ€™ intentions.
The present paper aims to show how that link can be strengthened through modelling agentsâ€™ intentions and relating them to the dialogue acts communicated via utterances.
In relation to this link, the significance of degrees of belief is explained in the following section.
drs1: i you m drs2: s c1: buy(you,c2) c2: newShoes(s) attitude(you, â€˜ACCEPTâ€™, drs3) drs3: attitude(i, â€˜ACCEPTâ€™, drs2) attitude(i, â€˜BELâ€™, drs4) drs4: y b1: mary(m) b2: party(y) b3: has(m,y) attitude(you, â€˜BELâ€™, drs5) drs5: s b4: mary(m) b5: party(y) b6: has(m,y) b7: buy(you,b8) b8: newShoes(s) attitude(you, â€˜INTâ€™, drs6) drs6: y s p1: mary(m) p2:party(y) p3: has(m,y) a1: buy(you,a2) a2: newShoes(s) inform(you, i, a1) Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, there is no account in DRT that accommodates strengths or degrees of belief of agents in dialogue.
This section addresses this gap and proposes initially two strengths of belief involved in dialogue to be expanded in future research to include further degrees of belief.
Modal expressions, including words such as â€˜possiblyâ€™ and â€˜mightâ€™, are evidence that there exist more degrees of belief than the ones discussed in this paper.
The beliefs of an agent are â€˜her model of how things areâ€™ (Traum 1994: 15).
The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true.
There is an important philosophical background to the discussion of â€˜beliefâ€™ and â€˜knowledgeâ€™.
It is outside the scope of this paper to review all the literature here.
Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative.
The term â€˜beliefâ€™ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but also communicates to the hearer that she, the speaker, believes those proposition to be true.
Another degree of belief called acceptance is accounted for in this model.
Acceptance consists of the agentâ€™s weakly believed propositions.
The agent may be going along with what the speaker is saying or has acquired a new proposition based on the speakerâ€™s utterance which has not yet been confirmed into a stronger belief.
To illustrate what is meant by the distinction between belief and acceptance, let us look at: (4) S1: I need to buy new shoes for Maryâ€™s party.
H1: Try Next on Henry Street.
The speaker tells the hearer that she has to buy new shoes for Maryâ€™s party.
In this example, the hearer already (strongly) believes there is a party and he suggests a place where the speaker can buy them.
Figure 1 demonstrates the hearerâ€™s mental state after hearing the speakerâ€™s utterance, S1.
The hearerâ€™s mental state is represented by a Discourse Representation Structure (DRS), which contains three sub-DRSs, one for intention (referred to by â€˜attitude(you, â€˜INTâ€™, drs6)â€™ and the label for the intention DRS, drs6), another for the belief DRS containing strong beliefs (referred to by â€˜attitude(i, â€˜BELâ€™, drs4)â€™ and the the label for the belief DRS, drs4), and finally the acceptance DRS containing weak beliefs (referred to by â€˜attitude(i, â€˜ACCEPTâ€™, drs2)â€™ and the the label for the acceptance 48 DRS, drs2).3 If we change example (4) so that the hearer does not actually hold the belief that there is a party, as in: (5) S1: I need to buy new shoes for Maryâ€™s party.
H1: I didnâ€™t realize Mary is throwing a party.
S2: Yeah she is.
Itâ€™s next Tuesday.
H2: You can probably buy them at Next.
The hearer does not necessarily need to strongly believe that Mary is throwing a party.
He can â€˜go along withâ€™ or accept it and even suggest a place where the speaker can buy the shoes.
The existence of a party does not affect the hearer personally or directly, i.e. he does not need to act on it.
However, let us now consider the effect if we change the example again so that the hearer does not know about Maryâ€™s party, nor that he is required to buy new shoes, as in: (6) S1: You need to buy new shoes for Maryâ€™s party.
H1: I didnâ€™t realize Mary is throwing a party.
S2: Yeah she is.
You should try Next on Henry Street.
H2: I will.
This time, for the hearer to commit to buying something for a party (in H2) that he did not even know existed suggests a stronger degree of belief than that of â€˜going along withâ€™ the speaker having to buy it.
The existence of the party affects the hearer personally and directly.
Therefore, agreeing to buy new shoes justifies the inference that he believes rather than just accepts there is a party.
This is what the paper describes as belief, or a strong degree of belief.
Contrast Figure 1 with the figure representing the speakerâ€™s mental state after hearing H2 in example 6, Figure 2.
4 Beliefs
and Mutual Beliefs The treatment of beliefs that we are developing here requires an explicit account of how the belief spaces or DRSs of two agents can interact.
3Inside the agentâ€™s DRS, â€˜iâ€™ is used to refer to the agent and â€˜youâ€™ is used to refer to the other agent.
Assertions are marked by â€˜anâ€™, presuppositions by â€˜pnâ€™, believed information by â€˜bnâ€™ and accepted information by â€˜cnâ€™.
drs1: i you m drs2: attitude(you, â€˜ACCEPTâ€™, drs3) drs4: attitude(i, â€˜ACCEPTâ€™, drs2) attitude(i, â€˜BELâ€™, drs4) drs4: s n b1: mary(m) b2:party(y) b3: has(m,y) b4: buy(you,b5) b5: newShoes(s) b6: try(you,b7) b7: next(n) attitude(you, â€˜BELâ€™, drs5) drs5: b8: mary(m) b9:party(y) b10: has(m,y) b11: buy(you,b12) b12: newShoes(s) b13: try(you,b13) b14: next(n) attitude(you, â€˜INTâ€™, drs7) drs7: s n p1: newShoes(s) p2: next(n) a1: buy(you,p1) a2: try(you,p2) inform(you,i,a1) inform(you,i,a2) Figure 2: Speaker Recognition of H2 â€˜Mutual beliefâ€™, also referred to as â€˜mutual knowledgeâ€™, is the term used by Traum (1994) among others, where a group of individuals may believe X, where X may or may not be true.
Stalnakerâ€™s (2002) â€˜common beliefâ€™ is comparable to what others call mutual belief.
For X to be a mutual belief, it has to be accessible to a group; all believe X and all believe that all believe X, and all believe that all believe that all believe X.
In face-to-face communication, the hearer believes that the speaker believes what she, the speaker, is communicating.
On the other hand, unless the hearer indicates doubt or objects to what the speaker is saying, the speaker assumes that the hearer believes what the speaker has said â€“ which is consistent with expectations under Gricean cooperativeness assumptions (1989).
The speaker also assumes that the hearer now has the belief that the speaker believes what she just said.
This assumption is what leads to â€˜mutualâ€™ beliefs (Kamp 1990: 79).
However, mutual belief can be viewed as the process of establishing that the speaker and the hearer hold the same belief.
One way in which this process may occur is when the speaker holds a belief and communicates that belief to the hearer.
49 This belief may then be adopted by the hearer who can provide feedback to the speaker that the information communicated has now acquired the status of belief in an ideal situation with a cooperative hearer.
When both participants reach the conclusion that S bel(ieves) X, H bel X, H bel S bel X, and S bel H bel X, then mutual belief is established.
The speaker in example (7) believes her neighbour is a weirdo.
Whether the utterance is informative (new) or not depends on the context.
In this example, (7), the speaker may not already have the belief that the hearer believes her neighbour is a weirdo.
(7) Speaker: My neighbour is such a weirdo.
Hearer: Yeah, he is.
I saw him peeping through your window the other day.
However, after the hearer makes his utterance, the speaker can now strongly believe that the hearer believes her neighbour is a weirdo, that he believes she believes her neighbour is a weirdo, and now she believes he believes her neighbour is a weirdo.
Figure 3 shows the level of nesting to accommodate the mutual belief that the speakerâ€™s neighbour is a weirdo.
It is possible when this level of nesting is reached to have a separate DRS or space for mutual beliefs, called â€˜mutual belief DRSâ€™.
In which case, the propositions held in drs6, can now be removed from drs6 and added to the â€˜mutual belief DRSâ€™.
Figure 3 represents the speakerâ€™s mental state after the hearer makes his utterance.
For the purposes of this example, the DRT represented in Figure 3 will mainly focus on the speakerâ€™s belief DRT.
Achieving mutual belief is immensely helped by dialogue acts.
For example, when a hearer provides strong feedback about a new proposition (cf.
drs7 in Figure 3), the speaker can come to believe the hearer believes that proposition.
Section 5 shows the importance of considering the dialogue acts expressed by an assertion (new information) and their relationship to degrees of belief and strengthening of beliefs.
5 Beliefs
and Dialogue Acts When someone makes an assertion, they communicate not only information they assume to be new to the hearer, but also communicate to the hearer information about their own beliefs.
In order to drs1: i you drs2: attitude(you, â€˜ACCEPTâ€™, drs3) drs3: attitude(i, â€˜ACCEPTâ€™, drs2) attitude(i, â€˜BELâ€™, drs4) drs4: x y b1: neighbour(x) b2: have(i,x) b3: weirdo(x) b4: window(y) b5: have(i,y) b6: peeping-through(x,y) b7: saw(you,b6) attitude(you, â€˜BELâ€™, drs5) drs5: b8: neighbour(x) b9: have(i,x) b10: weirdo(x) b11: window(y) b12: have(i,y) b13: peeping-through(x,y) b14: saw(you,b13) attitude(i, â€˜BELâ€™, drs6) drs6: b15: neighbour(x) b16: have(i,x) b17: weirdo(x) b18: window(y) b19: have(i,y) b20: peeping-through(x,y) b21: saw(you,b20) attitude(you, â€˜INTâ€™, drs7) drs7: x y p1: neighbour(x) p2: weirdo(x) p3: window(y) p4: have(i,y) a1: peeping-through(x,y) a2: saw(you,a1) strongPosFeedback(you,i,p2) inform(you,i,a2) Figure 3: Speaker Recognition model beliefs in dialogue, it is necessary to understand what the representation of dialogue involves.
A dialogue is â€˜a cooperative undertaking of agents engaged in developing and transforming their common situationâ€™, involving verbal and non-verbal action (Heydrich et al.1998: 21).
In a dialogue, utterances give rise to dialogue acts (cf.
agentsâ€™ intention DRSs in Figures 1, 2 and 3), named speech acts by some, and conversation acts by others (Traum 1994).
One of the features of dialogue acts is how they affect the agentsâ€™ mental states.
As Traum points out, â€˜... speech acts are a good link between the mental states of agents and purposeful communicationâ€™ (Traum 1999: 30).
Each agent in dialogue needs to have a representation of their beliefs and the other agentâ€™s beliefs or cognitive state in order for a dialogue act to be felicitous in Austinâ€™s and Searleâ€™s sense (Asher 1986).
That is to say, dialogue acts depend on agentsâ€™ beliefs for interpretation.
50 Each assertion made has one â€˜functionâ€™ or more.
For example, the function of a statement could be to make a claim about the world.
Traum (1997) divides statements into â€˜assertâ€™, â€˜re-assertâ€™, and â€˜informâ€™.
â€˜Assertâ€™ is trying to â€˜changeâ€™ the belief of the addressee.
The result of assert is that the hearer now assumes that the speaker is trying to get the hearer to believe the assertion.
â€˜Re-assertâ€™ can be used when participants try to verify old information, and not necessarily inform of something new.
â€˜Informâ€™ means that the speaker is trying to provide the hearer with information that the hearer did not have before.
However, Traum does not go further to discuss cases where agents believe their utterances (Traum 1994: 14).
It is one of the claims of this paper that agents in dialogue either strongly or weakly believe their utterances in order to be cooperative.
It is possible to extend this approach in order to include cases where agents are purposefully deceitful.
However, this is left for future research.
The adapted dialogue acts, or functions, in thiss paperâ€™s treatment of beliefs in DRT are mainly â€˜informâ€™, â€˜change beliefâ€™ and â€˜otherâ€™.
â€˜Informâ€™ is used to communicate new information to the hearer, whereas â€˜change beliefâ€™ (or to use Poesio and Traumâ€™s (1997b) dialogue act term â€˜assertâ€™) is used to change the hearerâ€™s beliefs about some proposition.
The importance of the representation introduced in section 3 in relation to dialogue acts transpires in allowing us to make the distinction between the dialogue acts â€˜informâ€™ and â€˜change beliefâ€™ (â€˜assertâ€™).
To â€˜informâ€™ the hearer of X, the speaker needs to have the belief in her beliefs that the hearer does not believe X, i.e. bel(S,Â¬ bel(H, X)).
This is a constraint to making an informative utterance.
Figure 4 shows the speakerâ€™s beliefs before making the utterance in example (8).
(8) The X-Files DVD is on sale on Amazon.
The speaker believes the hearer does not already believe that the X-Files DVD is on sale on Amazon, drs3.
This is demonstrated by the missing propositions representing â€˜on sale on Amazonâ€™ â€˜onSale(x, b4)â€™ and â€˜at(a)â€™ from drs3 in Figure 4.
On the other hand, to make a â€˜change beliefâ€™ or an â€˜assertâ€™, the speaker would have reason to believe that the hearer believes something different or the opposite of what the speaker believes, bel(S, bel(H, Â¬ X)).
The DRT treatment of beliefs proposed in this paper allows us to reflect this in drs1: i you x a attitude(i, â€˜BELâ€™, drs2) drs2: b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, â€˜BELâ€™, drs3) drs3: b5: xFilesDVD(x) Figure 4: Inform: Speakerâ€™s utterance drs1: i you x a attitude(i, â€˜BELâ€™, drs2) drs2: b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, â€˜BELâ€™, drs3) drs3: b5: xFilesDVD(x) b6: not(onSale(x)) Figure 5: Change belief Figure 5, drs3, in which the speaker believes the hearer believes the X-Files DVD is not on sale, â€˜not(onSale(x))â€™.
The category â€˜Otherâ€™ embraces any dialogue act other than â€˜informâ€™ and â€˜change beliefâ€™, whose recognition involves the same process explained for others, e.g. â€˜suggestâ€™, â€˜clarifyâ€™, and â€˜explainâ€™.4 The dialogue acts â€˜acceptâ€™ and â€˜rejectâ€™ come under the umbrella of feedback as they can be in response to, for instance, a â€˜suggestâ€™ dialogue act.
The dialogue act â€˜clarifyâ€™ is used when a hearer is having difficulty recognizing the speakerâ€™s utterance.5 On the other hand, â€˜explainâ€™ is when the speaker responds to the hearerâ€™s clarification request and provides a clarifying utterance.
The hearer can accept, believe, or reject that explanation.
The dialogue act â€˜suggestâ€™ also instigates one of three reactions: the hearer can accept, believe or reject that suggestion and may provide feedback to indicate which is his reaction.
It is of more interest to this paper to examine the effects of dialogue acts on the hearerâ€™s beliefs, and what dialogue acts suggest about the speakerâ€™s beliefs.
4It is possible for this category to be expanded to include more dialogue acts such as â€˜questionâ€™, â€˜answerâ€™, â€˜selfcorrectâ€™ and â€˜offerâ€™.
5Clarification is a form of feedback.
â€˜I didnâ€™t hear what you saidâ€™ is both â€˜feedbackâ€™ act and an â€˜informâ€™ (Schegloff et al.1977). 51                         Figure 6: Feedback 5.1 Feedback and Agentsâ€™ Beliefs Traum (1994) suggests that when an assertion is made, the hearer has an obligation to produce an â€˜understanding actâ€™.
In general, acknowledgement is expected in Traumâ€™s treatment of speech acts.
This means that when a hearer responds with â€˜okayâ€™, the hearer can be taken to be providing an acknowledgement and an acceptance.
However, the hearer does not always provide feedback.
Grounding often happens as a result of implicit rather than overt feedback and acknowledgement (Bunt 1995).6 In fact, the treatment outlined in this paper maintains that the lack of feedback is to be considered a form of â€˜weak positive feedbackâ€™, an extension to Dynamic Interpretation Theoryâ€™s (DIT) positive feedback (Bunt 1995).
The hearer does not object to the speakerâ€™s utterance by not providing feedback, since if the hearer did object, he would explicitly do so.
When the speaker makes an assertion, the hearer may indicate that the message has been received (weak positive feedback), example (9.b).
Weak positive feedback may indicate understanding, continued attention, or acknowledgement, such as â€˜uh huhâ€™, and â€˜yeahâ€™ (Clark and Schaefer 1989).
Another case of weak positive feedback is provided by example (9.a) where the hearer does not say anything.
It is assumed that the hearer did not have any problems and has received the assertion, A.
In the case of weak feedback, it can be argued that this represents the â€˜acceptanceâ€™ of A.7 Another response for the hearer is â€˜strong posi6Grounding is a term adapted by Traum (1994) from Clark and Schaeferâ€™s (1989) work on establishing common ground.
7This does not cancel cases where for social reasons, such as politeness, the hearer does not necessarily agree with the speaker, but does not wish to indicate it.
The speaker can wrongly or rightly come to the conclusion that the hearer accepts the assertion.
tive feedbackâ€™ (another extension to DITâ€™s positive feedback), where the hearer not only indicates reception of A, but also that she agrees that A (cf.
drs7 Figure 3).
This is where confirming adoption of new beliefs takes place, example (9.c).
Rejecting A is another way of giving feedback, negative feedback, as in example (9.d).
(9) Speaker: Mary loves John.
a. Hearer: b.
Hearer: aha.
c. Hearer: I couldnâ€™t agree more! d.
Hearer: No, Mary is besotted with Tom!
There are also degrees of belief that can be expressed according to the speech act used, firm versus â€˜tentativeâ€™.
Poesio and Traum pay less attention to â€˜the attitudes expressed by the actsâ€™ (Poesio and Traum 1998: 221).
Unlike Traumâ€™s model, the effects of the dialogue actsâ€™ employed in agentsâ€™ DRSs on agentsâ€™ beliefs are considered in this paper.
Figure 6 demonstrates the link between feedback dialogue acts and agentsâ€™ beliefs.
6 Conclusion
As this paper has demonstrated, beliefs vary in strength according to context.
Beliefs also change with the coming of new information.
The DRT treatment discussed here allows for the representation of strong beliefs and weaker beliefs as well as changes to beliefs.
Agents in a dialogue may form stronger beliefs as the dialogue progresses, requiring moving the content of their weaker beliefs to the stronger belief space.
In sum, there is no account in standard DRT that accommodates degrees of belief of agents in dialogue.
This paper has addressed this omission and suggested two degrees of belief involved in dialogue, namely â€˜beliefâ€™ and â€˜acceptanceâ€™.
It is sug52 gested that this is the initial step in representing agentsâ€™ mental states in dialogue-oriented DRT.
However, this paper does not deal with words which introduce more degrees of belief than the two addressed in the model.
It would be interesting to see more degrees of belief represented in a DRT dialogue model of agents in future research.
It is possible that such modal expressions can be arranged on a scale corresponding to degrees of belief (cf.
Werth 1999).
Moreover, this paper has accounted for agentâ€™s mutual beliefs and linked agentsâ€™ beliefs and intentions to the dialogue acts of their utterances, in order to address the problematic nature of accounting for belief in DRT.
References Al-Raheb, Y.
2005. Speaker/Hearer Representation in a Discourse Representation Theory Model of Presupposition: A Computational-Linguistic Approach.
Phd. University of East Anglia.
Asher, N.
1986. â€˜Belief in Discourse Representation Theoryâ€™.
Journal of Philosophical Logic 15, pp.
127â€“189. Asher, N.
and Lascarides, A.
2003. Logics of Conversation.
Cambridge: Cambridge University Press.
Bunt, H.
1995. â€˜Dynamic Interpretation and Dialogue Theoryâ€™.
In: M.
Taylor, F.
Neel, and D.
Bouwhuis (Eds.).
The Structure of Multimodal Dialogue, Volume 2.
pp. 139â€“166.
Amsterdam: John Benjamins 2000.
Clark, H.
and Schaefer, E.
1989. â€˜Contributing to Discourseâ€™.
Cognitive Science 13, pp.
259â€“294. Davidson, D.
1983. â€˜A Coherence Theory of Truth and Knowledgeâ€™.
In: D.
Henrich (Ed.).
Kant oder Hegel.
pp. 433â€“438.
Stuttgart: Klett-Cotta Buchhandlung.
Gazdar, G.
1979. â€˜A Solution to the Projection Problemâ€™.
In: C.
Oh and D.
Dineen (Eds.).
Syntax and Semantics II: Presupposition.
New York: Academic Press.
Grice, P.
1989. Studies in the Way of Words.
Cambridge, MA: Harvard University Press.
Heydrich, W., Kuhnlein, P., and Rieser, H.
1998. â€˜A DRTStyle Modelling of Agentsâ€™ Mental States in Construction Dialogueâ€™.
In: Proceedings of Workshop on Language Technology 13 (Twendial â€™98), TWLT.
Faculty of Informatics, the University of Twente: The Netherlands.
Hintikka, J.
1962. Knowledge and Belief: An Introduction to the Logic of the Two Notions.
Mimeo: Indiana University Linguisitics Club.
Horton, D.
and Hirst, G.
1988. â€˜Presuppositions as Beliefsâ€™.
In: Coling-88: Proceedings of the 12th International Conference on Computational Linguistics.
pp. 255â€“260.
Budapest: Hungary.
Kamp, H.
1990. â€˜Prolegomena to a Structural Account of Belief and Other Attitudesâ€™.
In: C.
Anderson and J.
Owens (Eds.).
Propositional Attitudes: The Role of Content in Logic, Language, and Mind.
Stanford, CA: CSLI Publications.
Kamp, H., van Genabith, J., and Reyle, U.
2005. The Handbook of Logic.
Unpublished Manuscript.
http://www.ims.uni-stuttgart.de/Ëœhans/. Larsson, S.
and Traum, D.
2000. â€˜Information State and Dialogue Management in the TRINDI Dialogue Move Engine Toolkitâ€™.
In: Natural Language Engineering.
Special Issue on Spoken Language Dialogue System Engineering.
pp. 323â€“340.
Lewis, D.
1969. Convention: A Philosophical Study.
Harvard University Press.
Lewis, D.
1979. â€˜Attitudes de dicto and de reâ€™.
Philosophical Review 88, pp.
513â€“543. Poesio, M.
and Traum, D.
1997a. â€˜Conversational Actions and Discourse Situationsâ€™.
Computational Intelligence 13, pp.
309â€“347. Poesio, M.
and Traum, D.
1997b. â€˜Representing Conversation Acts in a Unified Semantic/Pragmatic Frameworkâ€™.
In: Working Notes of AAAI Fall Symposium on Communicative Action in Humans and Machines.
pp. 67â€“74.
Cambridge, MA: MIT Press.
Poesio, M.
and Traum, D.
1998. â€˜Towards an Axiomatization of Dialogue Actsâ€™.
In: J.
Hulstijn and A.
Nijholt (Eds.).
Formal Semantics and Pragmatics of Dialogue, Proceedings of Twendialâ€™ 98.
pp. 207â€“221.
Universiteit Twente: Enschede.
Quine, W.
1960. Word and Object.
Cambridge MA: MIT Press.
Schegloff, E., Jefferson, G., and Sacks, H.
1977. â€˜The Preference for Self-Correction in the Organization of Repair in Conversationâ€™.
Language 53, pp.
361â€“382. Stalnaker, R.
1974. â€˜Pragmatic Presuppositionâ€™.
In: M.
Munitz and P.
Unger (Eds.).
Semantic and Philosophy.
pp. 197â€“214.
New York: New York University Press.
Stalnaker, R.
1988. â€˜Belief Attribution and Contextâ€™.
In: R.
Grimm and D.
Merrill (Eds.).
Contents of Thought.
Proceedings of the 1985 Oberlin Colloquium in Philosophy.
pp. 140â€“156.
Tucson State: The University of Arizona Press.
Stalnaker, R.
1999. Context and Content.
Oxford: Oxford University Press.
Stalnaker, R.
2002. â€˜Common groundâ€™.
Linguistics and Philosophy 25(5-6), pp.
701â€“721. Traum, D.
1994. A Computational Theory of Grounding in Natural Language Conversation.
Phd and tr 545.
Computer Science Department, Univeristy of Rochester.
Traum, D.
1997. â€˜Report on Multiparty Dialogue Sub-group on Forward-looking Communicative Functionâ€™.
In: Standards for Dialogue Coding in Natural Language Processing, Dagstuhl-Seminar Report no.
167. Traum, D.
1999. â€˜Computational Models of Grounding in Collaborative Systemsâ€™.
In: Working notes of AAAI Fall Symposium on Psychological Models of Communication.
pp. 124-131.
North Falmouth, Massachusetts.
Werth, P.
1999. Text Worlds: Representing Conceptual Space in Discourse.
New York: Longman.

