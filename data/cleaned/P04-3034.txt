Fragments and Text Categorization Jan Blaˇt´ak and Eva Mr´akov´a and Luboˇs Popel´ınsk´y Knowledge Discovery Lab Faculty of Informatics, Masaryk University 602 00 Brno, Czech Republic a0 xblatak, glum, popel a1 @fi.muni.cz Abstract We introduce two novel methods of text categorization in which documents are split into fragments.
We conducted experiments on English, French and Czech.
In all cases, the problems referred to a binary document classification.
We find that both methods increase the accuracy of text categorization.
For the Na¨ıve Bayes classifier this increase is significant.
1 Motivation
In the process of automatic classifying documents into several predefined classes – text categorization (Sebastiani, 2002) – text documents are usually seen as sets or bags of all the words that have appeared in a document, maybe after removing words in a stop-list.
In this paper we describe a novel approach to text categorization in which each documents is first split into subparts, called fragments.
Each fragment is consequently seen as a new document which shares the same label with its source document.
We introduce two variants of this approach – skip-tail and fragments.
Both of these methods are briefly described below.
We demonstrate the increased accuracy that we observed.
1.1 Skipping
the tail of a document The first method uses only the first a2 sentences of a document and is henceforth referred to as skip-tail.
The idea behind this approach is that the beginning of each document contains enough information for the classification.
In the process of learning, each document is first replaced by its initial part.
The learning algorithm then uses only these initial fragments as learning (test) examples.
We also sought the minimum length of initial fragments that preserve the accuracy of the classification.
1.2 Splitting
a document into fragments The second method splits the documents into fragments which are classified independently of each others.
This method is henceforth referred to as fragments.
Initially, the classifier is used to generate a model from these fragments.
Subsequently, the model is utilized to classify unseen documents (test set) which have also been split into fragments.
2 Data
We conducted experiments using English, French and Czech documents.
In all cases, the problems referred to a binary document classification.
The main characteristics of the data are in Table 1.
Three kinds of English documents were used: 20 Newsgroups1 (202 randomly chosen documents from each class were used.
The mail header was removed so that the text contained only the body of the message and in some cases, replies) Reuters-21578, Distribution 1.02 (only documents from money-fx, money-supply, trade classified into a single class were chosen).
All documents marked as BRIEF and UNPROC were removed.
The classification tasks involved money-fx+money-supply vs.
trade, money-fx vs.
money-supply, money-fx vs.
trade and money-supply vs.
trade. MEDLINE data3 (235 abstracts of medical papers that concerned gynecology and assisted reproduction) n docs avea3 sdeva3 20 Newsgroups 138 4040 15.79 5.99 Reuters-21578 4 1022 11.03 2.02 Medline 1 235 12.54 0.22 French cooking 36 1370 9.41 1.24 Czech newspaper 15 2545 22.04 4.22 Table 1: Data (n=number of classification tasks, docs=number of documents, ave a3 =average number of sentences per document, sdev a3 =standard deviation) 1http://www.ai.mit.edu/ jrennie/ 20Newsgroups/ 2http://www.research.att.com/ lewis 3http://www.fi.muni.cz/ zizka/medocs The French documents contained French recipes.
Examples of the classification tasks are Accompagnements vs.
Cremes, Cremes vs.
Pates-PainsCrepes, Desserts vs.
Douceurs, Entrees vs.
PlatsChauds and Pates-Pains-Crepes vs.
Sauces, among others.
We also used both methods for classifying Czech documents.
The data involved fifteen classification tasks.
The articles used had been taken from Czech newspapers.
Six tasks concerned authorship recognition, the other seven to find a document source – either a newspaper or a particular page (or column).
Topic recognition was the goal of two tasks.
The structure of the rest of this paper is as follows.
The method for computing the classification of the whole document from classifying fragments (fragments method) is described in Section 3.
Experimental settings are introduced in Section 4.
Section 5 presents the main results.
We conclude with an overview of related works and with directions for potential future research in Sections 6 and 7.
3 Classification
by means of fragments of documents The class of the whole document is determined as follows.
Let us take a document a0 which consists of fragments a1a3a2,. . ., a1a5a4 such that a0a7a6a9a8 a4a10a12a11 a2 a1 a10 and a13a15a14a17a16a3a18a20a19a21a14a23a22 a6 a18a23a24 a1 a10a15a25 a1a27a26a23a6a29a28 . The value ofa30 depends on the length of the documenta0 and on the number of sentences in the fragments.
Leta31a32a6a34a33a35a1a2a16a37a36a37a36a37a36a38a16a1a4a40a39, and a41 denotes the set of possible classes.
We than use the learned model to assign a class a42a44a43a45a1a47a46a49a48a50a41 to each of the fragments a1a51a48a52a31 . Leta53a54a43a45a1a16a42a44a43a45a1a47a46a55a46 be the confidence of the classification fragment a1 into the class a42a44a43a45a1a56a46 . This confidence measure is computed as an estimated probability of the predicted class.
Then for each fragmenta1a57a48a20a31 classified to the classa42a58a48a59a41 we define a42a44a43a45a31 a16a42a38a46a23a6a7a33a35a1a49a48a60a31a62a61a42a44a43a45a1a47a46a58a6a63a42a39 . The confidence of the classification of the whole documenta0 intoa42 is computed as follows a64 a43a45a31 a16 a42a37a46a65a6 a66a67 a67 a68 a67 a67a69 a70 a16 a42a44a43a45a31 a16 a42a38a46a71a6a52a28 a2 a72a73a75a74a77a76a79a78a73a3a80a3a72a82a81a84a83 a85a87a86a73a55a74a27a76a40a78a73a3a80 a53a54a43a45a1 a16 a42a38a46 a16a84a88a90a89a75a91a15a92a37a93a95a94a96a14a98a97a90a92 Finally, the class a42a95a43a99a0a58a46 which is assigned to a documenta0 is computed according to the following definition: a42a95a43a99a0a58a46a100a6a101a42a103a102 a61a42a44a43a45a31 a16 a42a37a46a37a61a104a6a101a105a107a106a90a108a109a33a82a61a42a44a43a45a31 a16 a42a2a46a37a61a39 a24 a64 a43a45a31 a16 a42a38a46a100a6a101a105a107a106a90a108a109a33 a64 a43a45a31 a16 a42a111a110a90a46a39 for a13 a42a2 a48a7a41 and a13 a42a112a110a101a48a113a33a35a42a112a114a52a48a7a41a115a61a71a61a42a95a43a45a31 a16a42a112a114a116a46a37a61a58a6 a105a107a106a90a108a109a33a82a61a42a44a43a45a31 a16 a42a2a46a37a61a39a44a39 . In other words, a document a0 is classified to a a42a117a48a52a41, which was assigned to the most fragments from a31 (the most frequent class).
If there are two classes with the same cardinality, the confidence measure a64 a43a45a31 a16a42a38a46 is employed.
We also tested another method that exploited the confidence of classification but the results were not satisfactory.
4 Experiments
For feature (i.e.
significant word) selection, we tested four methods (Forman, 2002; Yang and Liu, 1999) – Chi-Squared (chi), Information Gain (ig), Fa2 -measure (f1) and Probability Ratio (pr).
Eventually, we chose ig because it yielded the best results.
We utilized three learning algorithms from the Weka4 system – the decision tree learner J48, the Na¨ıve Bayes, the SVM Sequential Minimal Optimization (SMO).
All the algorithms were used with default settings.
The entire documents have been split to fragments containing 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 30, and 40 sentences.
For the skip-tail classification which uses only the beginnings of documents we also employed these values.
As an evaluation criterion we used the accuracy defined as the percentage of correctly classified documents from the test set.
All the results have been obtained by a 10-fold cross validation.
5 Results
5.1 General We observed that for both skip-tail and fragments there is always a consistent size of fragments for which the accuracy increased.
It is the most important result.
More details can be found in the next two paragraphs.
Among the learning algorithms, the highest accuracy was achieved for all the three languages with the Na¨ıve Bayes.
It is surprising because for full versions of documents it was the SMO algorithm that was even slightly better than the Na¨ıve Bayes in terms of accuracy.
On the other hand, the highest impact was observed for J48.
Thus, for instance for Czech, it was observed for fragmentsthat the accuracy was higher for 14 out of 15 tasks when J48 had been used, and for 12 out of 15 in the case of the Na¨ıve Bayes and the Support Vector Machines.
However, the performance of J48 was far inferior to that of the other algorithms.
In only three tasks J48 4http://www.cs.waikato.ac.nz/ml/weka resulted in a higher accuracy than the Na¨ıve Bayes and the Support Vector Machines.
The similar situation appeared for English and French.
5.2 skip-tail skip-tail method was successful for all the three languages (see Table 2).
It results in increased accuracy even for a very small initial fragment.
In Figure 1 there are results for skip-tail and initial fragments of the length from 40% up to 100% of the average length of documents in the learning set.
n NB stail lngth incr English 143 90.96 92.04 1.3 ++105 French 36 92.04 92.56 0.9 + 25 Czech 15 79.51 81.13 0.9 + 12 Table 2: Results for skip-tail and the Na¨ıve Bayes (n=number of classification tasks, NB=average of error rates for full documents, stail=average of error rates for skip-tail, lngth=optimal length of the fragment, incr=number of tasks with the increase of accuracy: +, ++ means significant on level 95% resp 99%, the sign test.) For example, for English, taking only the first 40% of sentences in a document results in a slightly increased accuracy.
Figure 2 displays the relative increase of accuracy for fragments of the length up to 40 sentences for different learning algorithms for English.
It is important to stress that even for the initial fragment of the length of 5 sentences, the accuracy is the same as for full documents.
When the initial fragment is longer the classification accuracy further increase until the length of 12 sentences.
We observed similar behaviour for skip-tail when employed on other languages, and also for the fragments method.
5.3 fragments This method was successful for classifying English and Czech documents (significant on level 99% for English and 95% for Czech).
In the case of French cooking recipes, a small, but not significant impact has been observed, too.
This may have been caused by the special format of recipes.
n NB frag lngth incr English 143 91.12 93.21 1.1 ++ 96 French 36 92.04 92.27 1.0 19 Czech 15 82.36 84.07 1.0 + 12 Table 3: Results for fragments (for the description see Table 2) 91 91.5 92 92.5 40 50 60 70 80 90 100 accuracy.
lentgh of the fragment skip-tail(fr) full(fr) skip-tail(eng) full(eng) Figure 1: skip-tail, Na¨ıve Bayes.
(lentgh of the fragment = percentage of the average document length) -35 -30 -25 -20 -15 -10 -5 0 5 0 5 10 15 20 25 30 35 40 accuracy.
no. of senteces NaiveBayes-bm SMO-bm J48-bm Figure 2: Relative increase of accuracy: English, skip-tail 5.4 Optimal length of fragments We also looked for the optimal length of fragments.
We found that for the lengths of fragments for the range about the average document length (in the learning set), the accuracy increased for the significant number of the data sets (the sign test 95%).
It holds for skip-tail and for all languages.
and for English and Czech in the case of fragments.
However, an increase of accuracy is observed even for 60% of the average length (see Fig.
1). Moreover, for the average length this increase is significant for Czech at a level 95% (t-test).
6 Discussion
and related work Two possible reasons may result in an accuracy increase for skip-tail.
As a rule, the beginning of a document contains the most relevant information.
The concluding part, on the other hand, often includes the author’s interpretation and crossreference to other documents which can cause confusion.
However, these statements are yet to be verified.
Additional information, namely lexical or syntactic, may result in even higher accuracy of classification.
We performed several experiments for Czech.
We observed that adding noun, verb and prepositional phrases led to a small increase in the accuracy but that increase was not significant.
Other kinds of fragments should be checked, for instance intersecting fragments or sliding fragments.
So far we have ignored the structure of the documents (titles, splitting into paragraphs) and focused only on plain text.
In the next stage, we will apply these methods to classifying HTML and XML documents.
Larkey (Larkey, 1999) employed a method similar to skip-tail for classifying patent documents.
He exploited the structure of documents – the title, the abstract, and the first twenty lines of the summary – assigning different weights to each part.
We showed that this approach can be used even for non-structured texts like newspaper articles.
Tombros et al.(Tombros et al., 2003) combined text summarization when clustering so called top-ranking sentences (TRS).
It will be interesting to check how fragments are related to the TRS.
7 Conclusion
We have introduced two methods – skip-tail and fragments – utilized for document categorization which are based on splitting documents into its subparts.
We observed that both methods resulted in significant increase of accuracy.
We also tested a method which exploited only the most confident fragments.
However, this did not result in any accuracy increase.
However, use of the most confident fragments for text summarization should also be checked.
8 Acknowledgements
We thank James Mayfield, James Thomas and Martin Dvoˇr´ak for their assistance.
This work has been partially supported by the Czech Ministry of Education under the Grant No.
143300003. References G.
Forman. 2002.
Choose your words carefully.
In T.
Elomaa, H.
Mannila, and H.
Toivonen, editors, Proceedings of the 6th Eur.
Conf. on Principles Data Mining and Knowledge Discovery (PKDD), Helsinki, 2002, LNCS vol.
2431, pages 150–162.
Springer Verlag.
L. S.
Larkey. 1999.
A patent search and classification system.
In Proceedings of the fourth ACM conference on Digital libraries, pages 179–187.
ACM Press.
F. Sebastiani.
2002. Machine learning in automated text categorization.
ACM Comput.
Surv., 34(1):1–47.
A. Tombros, J.
M. Jose, and I.
Ruthven. 2003.
Clustering top-ranking sentences for information access.
In T.
Koch and I.
Sølvberg, editors, Proceedings of the 7a0 a1 European Conference on Research and Advanced Technology for Digital Libraries (ECDL), Trondheim 2003, LNCS vl.
2769, pages 523–528.
Springer Verlag.
Y. Yang and X.
Liu. 1999.
A re-examination of text categorization methods.
In Proceedings of the 22a4a3a2 annual international ACM SIGIR conference on Research and development in information retrieval, pages 42–49.
ACM Press .

